# 计算机科学基础总结3

# TCP、UDP、KCP、HTTP(S)、QUIC

# 概述

## (1)常用概念

。处理时延:用于检查分组的头部信息决定将这个分组转发到何处所耗费的时间。
。排队时延:分组在链路上等待传输的时间
·传输时延、存储转发时延: 分组长度/链路速率，表示将分组推送到链路上所需要的时延，
。传播时延:两个路由器之间的数据传输的耗时，距离/传播速度。
。流量强度:分组到达队列的平均速度，分组长度/传播速度，设计系统时流量强度不应该超过1。
·丢包:在实际应用中，流量强度大于也不会导致排队时延增加，因为路由器的设计是由成本决定的，路由器存储空间占满以后会发送丢包。
。瞬时吞吐量:主机接受该文件的速率。吞吐量不仅取决于链路的传输速率，也取决于干扰流量。

程序一瞬间需要睿频，缓冲区满了就拒绝

。协议栈:各层所有协议的集合。
。各层数据的名称:应用层=报文，运输层=报文段，网络层=数据报/数据段，链路层=数据帧，物理层=比特.【越来越小】
MAC地址:链路层地址，长度为6字节（48位)，用于一标识网配器网)MAC地址是一个局域网有效的地址因此MA地址只要经过网关等就会发生改变，因为已经换了局域网。

**MTU，最大传输单元**: 经过两台主机之间的路径的所有网络报文段中MTU的**最小值**，通常用于避免数据分片。

木桶原理：最小的是MTU是主机间连接的最大传输单元。

网络协议三要素:语义、语法、顺序。
**【背】DHCP运行机制**:CIient使用0.0.0.0向255.255,25,255发送UDP清求（原先是BOOTP请求，UDP是更高级的封装)当DHCP服务器捕获到请求之后回ACK表示成功接受请求

**【背】PXE协议解过程**服务照启动的时BI0S或者UEFI加载烧写在ROM（只读存储器）中的PXE，然后DHCP服务请IP地址和一个pxelinux.0文件以及PXE服务IP地址，然后PXE客户端使用**TFTP协议下载pxelinux.cfg**文件，该文件指示了**Linux内核和initramfs的位置**，接下来便会加载**initramfs**，当Linux内核启动后就可以根据ks文件实现自动化部署操作系统。KickStart 是无人值守安装方式，通过人工干预生成ks.cfg文件实现自动化部署系统。 

广播风暴:**ARP**广播的时候会将一个口收到的数据包转发到其他所有端口，当交换机【使用Console线配置】互联**出现环路**以后，就会形成广播风暴，导致循环发送数据包，硬件资源耗尽（**使用生成树解决环路）**

Hub只有一个广播域和冲突域，Switch有一个广播域和多个冲突域，每一个端口在划分VLAN的情况下都是一个冲案域  【Hub（中心）就是集线器的意思】

一个交换机，它一个端口为独立一个冲突域。一个VLAN等于一个广播域。
一个集线器，它每个端口都是同**一个冲突域**，**一个广播域**（因为不能划分VLAN）。
一个路由器，一个端口就的等于一个广播域。

集线器一层，交换器二层，路由器三层

## (2)广播信道和点对点信道

### (2.1) 广播信道

广播信道主要有两种控制方法进行协调，一个是使用信道复用技术，一是使用CSMA/CD 协议
。CSMA/CD协议 (表示载波监听多点接入/碰撞检测) :
**多点接入:**说明这是**总线型网络**，许多主机以多点的方式连接到总线上。
**载波监听**:每个主机都必须**不停地监听信道**。在发送前，**如果监听到信道正在使用，就必须等待【占线了。。】**。

**碰撞检测:**在发送中，如果监听到信道已有其它主机正在发送数据，就表示发生了碰撞。虽然每个主机在发送数据之前都已经监听到信道为空闲，但是由于电磁波的**传播时延的存在，还是有可能会**
**发生碰撞【串门了，听到别人的聊天】**

### (2.2) 点对点信道

因为不会发生碰撞，因此也比较简单，使用 **PPP 协议**进行控制。
PPP协议:互联网用户通常需要连接到某个SP 之后才能接入到互联网，PPP 协议是用户计算机和SP 进行通信时所使用的数据链路层协议。【拨号】

## (3) NAT

。NAT的三种模式:

。SNAT:是指在数据包从网卡发出去的数据的时候，把数据包中的源地址部分替换为指定的IP地址，这样对方就认为数据包的来源是被替换的那个IP的主机。

。DNAT:是指数据包从网卡发送出去的时候，修改数据包中的目的IP，表现为如果你想访问A，可是因为网关NAT做了DNAT，把所有访问A的数据包更换为B的IP

。MASQUEEADE:是用发送数据的网卡上的IP替源IP，因此对于那些IP不固定的场合，比如拨号网络或者通过DHCP分配的情况下就可以使用该方式。

。NAT三种模式的区别:路由是按照目的IP来选择的，因此DNAT是在pre-routing链上进行的，而SNAT是数据包发送出去的时候才进的，因此是post-routing链上进行的。

。转发网关与NAT网关的区别:两者主要的区别在于IP地址是否改变。不改变P地址的网关，我们称为转发网关改变IP地址的网关，我们称为NAT网关。

iptables通过改数据包的头部实现NAT

硬路由和软路由【iptables】

软路由器其实是在电脑主机的基础上配合软件组合成的路由解决方案，路由的参数通过软件控制和设置。简单的说就是在电脑的硬件基础上加上路由系统来实现路由器的所有功能。硬路由就是我们普遍使用的路由器，由厂家提供整体的解决方案，包括路由器的硬件和软件。

NAT就是修改数据包的

### 



## 什么是KCP	

KCP是一种网络传输协议(A Fast and Reliable ARQ Protocol)，可以视它为TCP的代替品，但是它运行于用户空间，**它不管底层的发送与接收，只是个纯算法实现可靠传输，它的特点是牺牲带宽来降低延迟。**因为TCP协议的大公无私，经常牺牲自己速度来减少网络拥塞，它是从大局上考虑的。而**KCP是自私的，它只顾自己的传输效率，从不管整个网络的拥塞情况。举个例子，TCP检测到丢包的时候，首先想到的是网络拥塞了，要放慢自己的速度别让网络更糟，而KCP想到的赶紧重传别耽误事。**

TCP的特点是可靠传输(累积确认、超时重传、选择确认)、流量控制(滑动窗口)、拥塞控制(慢开始、拥塞避免、快重传、快恢复)、面向连接。KCP对这些参数基本都可配，也没用建立/关闭连接的过程。

其实KCP并不神秘，因为TCP的高度自治(很多东西都不可配)，满足不了如今各种速度需求。**而KCP就是基于UDP协议，再将一些TCP经典的机制移植过来，变成参数可配。**

### 使用场景

丢包率高的网络环境下KCP的优点才会显示出来。如果不丢包，那么TCP和KCP的效率不会差别很大，可能就是少了连接建立/关闭而已。一般来讲，在公网上传输的都可以使用，特别是对实时性要求较高的程序，如**LOL**。

缺点是学习成本，而且某些运营商是对UDP有限制的

### [**ARP协议**](https://zhuanlan.zhihu.com/p/370507243)

地址解析协议，即ARP（Address Resolution Protocol），是根据IP地址获取物理地址的一个TCP/IP协议。

**ARP表**

网络设备一般都有一个ARP缓存（ARP Cache），ARP缓存用来存放IP地址和MAC地址的关联信息。

ARP表项又分为动态ARP表项（会老化【过期删除】，有生命周期）和静态ARP表项（不会老化，直至重启）。

一般情况下，ARP动态执行并自动寻求IP地址到以太网MAC地址的解析，无需管理员的介入。

当希望设备和指定用户只能使用某个固定的IP地址和MAC地址通信时，可以配置短静态ARP表项，当进一步希望限定这个用户只在某VLAN内的某个特定接口上连接时就可以配置长静态ARP表项。

ARP协议是通过报文进行工作的，是一个独立的三层协议，所以ARP报文在向数据链路层传输时不需要经过IP协议的封装，而是直接生成自己的报文，其中包括ARP报头，到数据链路层后再由对应的数据链路层协议（如以太网协议）进行封装。

# 应用层

# （1）FTP协议

  FTP是基于TCP的，FTP使用20端口作为控制端口，使用21端口作为数据端口，因此控制信息是带外的。 

## （1.1）主动模式（PORT）

原理：FTP客户端随机打开一个大于1024的端口N，向服务器21端口发生连接请求，发送FTP用户名和密码，然后打开N+1端口监听，并向服务器发送PORT N+1命令，服务器接收到指令以后会使用数据端口20连接客户端的N+1端口进行数据传输。

![image-20221123224725658](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221123224725658.png)

## （1.2）被动模式

原理:FTP客户话打开两个任意的本地端口（大于1024)和N+1第一个端口连接服务器的21端口，提交PASV命令，然后，服务器会开启一个任意的端口P（大于1024)，返回"227 entering passivemode"消息，里面有FTP服务器开放的用来进行数据传输的端口。客户端收到消息取得端口号之后，会过N+1号端口连接服务器的端P，然后在两个端口之间进行数据传输。

![image-20221123225154025](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221123225154025.png)



![image-20221124201403224](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221124201403224.png)

# (2) DNS协议

## (2.1) 传统DNS

。**DNS协议使用53端口，基于UDP协议**，MX记录允许企业将自己的域名作为邮件服务器域名
 。DNS服务器分类:**根DNS服务器**，全球逻辑上有13个、标号为A-MTLD**顶级域**DNS服务器负责级域名和所有国家的解析、权威DNS服条器。公共DNS服条器。本地DNS服条器，
【背4】。**DNS记录:由Name,Value,Type,TTL构成的四元组。**
       **A记录**，type=A，name=主机名，value=主机IP
       **NS记录**，type=NS，name=主机域，value=权威DNS地址
       **CNAME记录**，type=CNAME，name=别名，value=主机名
       **MX记录**，type=MX，name=邮件服务地址，value=Web服务地址
       **SOA记录**，NS记录和SOA记录是-DN区域都不可缺的两条记录，NS录也叫名服务器记录，用于说明这个区域有聊DNS服务器负贾解折，**SOA记录负责解折的DNS服务器中一个是主服务器**。因此，任一个DNS区域都不可能少这两条记录NS记说明了在这个区域里有多少个服务来承担解析的任务，SOA叫授权机构记录，SOA记说明了在众NS记录里一台才是主要的服务器

​        **PTR记录**，指针记录，PTR记录是A记录的逆向记录，作用是把IP地址解析为域名。

​        **SRV记录**，**SRV记录是服务器资源记录的缩写**，在RFC2052中才对SRV记录进行了定义，因此很多老版本的DNS服务器并不支持SRV记录，SRV记录在微软的Actiwe Directory中有着重要地位，在NT4时代域和DNS并没有太多关系。但从Win2000开始，域就离不开DNS的帮助了，因为域内的计算机要依赖DNS的SRV记录来定位域控制器。表现形式为:

![image-20221123225956305](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221123225956305.png)

FPGA网卡很快

### 传统的DNS存在哪些问题?

（1）**域名缓存**:运营商缓存和本地缓存
（2）**域名转发**: 某些**运营商偷懒**将DNS转发到其他运营商，其他运营商返回的是自己网络内部的IP，导致网速慢
（3）**出口NAT**: 会使得运营商误判
（4）**域名更新**:权威DNS更新后其他DNS**更新漫长**，[《虎牙在全球 DNS 秒级生效上的实践》](https://zhuanlan.zhihu.com/p/67117705)。
（5）解析延迟
·对于复杂的应用，尤其是跨地域运营的大型应用，则需要更加复杂的**全局负载均衡机制**因需要专门的设备或者服务器来这件事，这就是全局负载均衡器（GSLB，Global Server Load Balance)，一般是**通过配置CNAME**的方式，然后告诉本地DNS服务器，让它请求GSLB解析这个域名，GSLB就可以在解析这个域名的过程中，通过自己的策略实现负载均衡。

 

虎牙装B（showtime）

虎牙使用的迭代

![image-20221130191742704](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221130191742704.png)

虎牙当前主要是依赖于公共的 DNS，可能会遇到的问题：

- 依赖公共 localDNS，解析不稳定，延迟大。
- 记录变更生效时间长，无法及时屏蔽线路和节点异常对业务的影响。例如，权威 DNS 全球各节点数据同步时间不可控，全局生效时间超过10分钟；localDNS 缓存过期时间不可控，部分 localDNS 不遵循TTL时间，缓存时间超过48小时。
- 内部 DNS 功能缺失，无法解决内部服务调用面临挑战。例如，时延大、解析不准、支持多种调度策略。
- 无法满足国外业务的快速发展，虽然一些海外云厂商提供了基于 DNS 的快速扩容方案，以及基于 DNS 的数据库切换方案。

![img](https://pic4.zhimg.com/v2-7c54b330962e832c1252b8a27f798d93_r.jpg)

![img](https://pic2.zhimg.com/80/v2-c0347eedc41d23dc9f386007ce433e3d_720w.webp)

整体上相对简单，只要**业务进程这边将自己内部的 DNS 缓存关掉**， 通过 **DNS-F** 进行查询的时候， 会直接到最近的 **Nacos** 集群拉取**最新的服务节点信息**， 而且**后续节点的变化也会推送到 DNS-F** 中， 后续可以直接在**缓存**中获取**最新信息**。









## (2.2) HTTP DNS

不走传统的DNS解折，而是自己搭建基于HTTP协议的DNS服务器集群 ，分布在多个地点和多个运营商，当客户端需要DNS解折的时候，直接通过**HTTP协议进行请求这个服务器集群【请求json】**，得到就近的地址使用HTTP DNS的，往往是手机应用，需要在**手机端**嵌入支持HTTP DNS的**客户端SDK。**

参照阿里云CDN HTTP DNS方式，参数是客户端IP地址和待解析的域名;然后返回多个IP地址，客户端轮询多个IP地址**【从客户端上实现负载均衡】**

## **CDN**

**全称**:Content Delivery Network或Content Ddistribute Network，即**内容分发网络**

**CDN的特点 ：**加速网站的访问【预热】

1、本地Cache加速 提高了企业站点（尤其含有大量图片和静态页面站点）的访问速度，并大大提高以上性质站点的稳定性
2、镜像服务 消除了不同运营商之间互联的瓶颈造成的影响，实现了跨运营商的网络加速，保证不同网络中的用户都能得到良好的访问质量。
3、远程加速 远程访问用户根据DNS负载均衡技术 智能自动选择Cache服务器，选择最快的Cache服务器，加快远程访问的速度
4、带宽优化 自动生成服务器的远程Mirror（镜像）cache服务器，远程用户访问时从cache服务器上读取数据，减少远程访问的带宽、分担网络流量、减轻原站点WEB服务器负载等功能。
5、集群抗攻击 广泛分布的CDN节点加上节点之间的智能冗于机制，可以有效地预防黑客入侵以及降低各种D.D.o.S攻击对网站的影响，同时保证较好的服务质量 。
CDN支持的业务类型有：
　 1、多媒体视音频点播/直播/大文件下载;
　　2、场景加速，支持渐进式点播、流媒体直播，提供高质量低时延的视听加速服务;
　　3、视频流媒体直播服务，媒资存储、切片转码、访问鉴权、内容分发加速一体化解决方案;
　　4、**视音频**渐进式点播服务，低缓冲时间，高流畅度播放体验，支持 MP4、FLV 视频格式;
　　5、支持资源链接鉴权，可自定义鉴权 KEY，保障您的媒体资源安全，免去盗链担忧。

**CDN的两种工作方式**
**边缘计算模式**:定时从源数据那里同步存储的数据，然后在边缘进行计算得到结果.【将更新结果推送到某个边缘去计算，结果好就敲定版本没问题】

**路径优化模式**:源站点生成数据分发，根据地理位置寻找最近分发点。

CDN要避免回源，类似于内存的缓存穿透

CDN：预热

CDN主要分两种，一种是静态一种是视音频。

​                                                     HTTP DNS拓扑图

![image-20221123230734845](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221123230734845.png)

健康检测相当于心跳检测Server

# (3)HTTP、HTTPS、QUIC协议

## (3.1) HTTP与邮箱协议

。**SMTP客户端运行在25端口，建立与SMTP服务端的连接。**

。**HTTP是拉协议，也是非持连接，SMTP是推协议，是持续连接**，SMTP要求报文的格式都使用7位ACSII码，发送邮件是推送，接收邮件是拉取，可以借助**IMAP（端口: 143)、POP3（端口:110)、
HTTP(端口:80) **完成。

**非持久连接可以用QPS衡量**

。SMTP 只能发送 ASCII码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCI 码的编码规则。

。POP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。但最新版本的 POP3 可以不删除邮件。

。IMAP 协议中客户端和服务器上的邮件保持同步，如果**不删除部件**，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服条器上的邮件

## (3.2) HTTP 状态码【背】

**1xx信息**
。100 Continue:表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应
**2xx成功**
。200 OK
。204 No Content;请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用

。206 Partial Content: 表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。
**3xx 重定向**【重灾区】
。301Moved Permanently: 永久性重定向
。**302** Found: 临时性重定向
。**303** See Other:和 302有着相同的功能，但是 **303 明确要求客户端应该采用 GET获取资源**。注: 虽然HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET方法，但是大多数浏览器都会在301、302和303 状态下的重定向把 POST 方法改成**GET 方法。**

。**304** Not Modfied:如果请求报文首部含-些条件，例如: 1-Match，1f-Modfed-Since,f-Nne-Match,lf-Range,fUnmodied-Since,如果不满是条件，则服务器会返回 304状态码。

。307 Temporary Redirect: **临时重定向与 302 的含义类似**，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。

**4xx 客户端错误**
。400 Bad Request: 请求报文中存在语法错误。
。401 Unauthorized:该状态码表示发送的请求需要有认证信息BASIC 认证、DIGEST 认证。如果之前已进行过一次请，则表示用户认证失败，
。403 Forbidden: 请求被拒绝。
。 404 Not Found

**5xx服务端错误**
。 500Internal Server Error: 服务器正在执行请求时发生错误。

。502 Bad Gateway是指错误[网关](https://baike.baidu.com/item/网关?fromModule=lemma_inlink)，无效网关；在互联网中表示一种网络错误。

。503 Service Unavailable: 服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。

## (3.3) HTTP1.1和2.0的区别【b】

。HTTP的报文大概分为三大部分。第一部分是**请求行（方法+URL+版本）**，第二部分是请求的**首部（键值对)**，第三部分才是请求的**正文实体**。HTTP协议是基于TCP协议的，所以它使用面向连接的方式发送请求，通过Stream二进制流的方式传给对方。当然，到了TCP层，它会把二进制流变成一个的报文段发送给服务器。

。HTTP1.1在应用层以**纯文本**的形式进行通信，每次通信都要带完整的HTTP头，而且不考虑**pipeline[串联起来、流水线]**模式的话，每次的过程总是像上面描述的那样一去一回。这样在**实时性、并发性**上都存在问题

。为了解决这些问题，HTTP 2.0会对HTTP的头进行一定的**压缩**，将原来每次都要携带的大量key value在**两端**建立一个**索引表**、对相同的头只发送索引表中的索引

。另外，HTTP2.0协议将一个TCP的连接中，**切分成多个流**，每个流都有自己的**ID**，而且流可以是客户端发往服务端，也可以是服务端发往客户端。它其实只是一个虚拟的通道。流是有优先级的

。HTTP2.0将所有的传输信息分割为**更小的消息和帧**，并对它们采用二进制格式编码。常见的帧有Heard帧，用于传输Heard内容、并且会开启一个新的流，再就是Data帧。用来传输正文实体。多个Data帧属于同一个流。

。HTTP 2.0成解决了部分HTTP1.1的**队首阻塞**问题，同时，也不需要通过HTTP 1x的pipeline机制用多条TCP连接来实现并行请与应减了P连接数对服务器性能的影响，同时将页面的多个数推css、is、ipg等合并，通过一个数据链接进行传输，能够加快页面组件的传输速度。
**HTTP2.0虽然大大增加了并发性，但还是有问题的**。因为HTTP 2.0也是基于TCP协议的，TCP协议在处理包时是有**严格顺序的**。当其中-数据包遇到问题，TCP连接需要等待这个包完成重传之后才继续进行。虽然HTTP 2.0通过多个stream，使得逻辑上一个TCP连接上的并行内容，进行多路数据的传输，然而这中间并没有关联的数据。一前一后，前面stream 2的帧没有收到，后面stream 1的帧也会因此阻塞。**于是，就又到了从TCP切换到UDP，这就是Google的QUIC协议。**

**QUIC基于UDP实现的**

## (3.4) HTTP1.1的缺陷【b】

。**高延迟**，带来页面加载速度降低，网络延迟的主要问题主要是由于**队头阻塞**，导致带宽无法被充分利用

​     。 **将同一个页面的资源分散到不同的域名下**，提升连接上限。因为Chrome有个机制就是对于同一个域名，默认允许同时建立**6个TCP持久连接**，使用持久连接可以公用一个TCP管道，但是在一个管道内只可以同时处理一个请求。
​     。**Spriting合并**多个小图片为一个大图，再从浏览器端使用JavaScript或者CSS将图片分割。
​     。将图片使用**Base64编码**，内联到CSS中，减少网络请求次数。
​     。将多个较小的JavaScript使用**WebPack**等打包工具合并为一个大体积的JavaScript文件。

。**无状态**，带来巨大的HTTP头部信息

。**明文传输，不安全**
。**不支持服务器推送消息**

## (3.5) SPDY与HTTP2.0

。SPDY:与2009年，Google公开了自行研发的SPDY协议，主要解决HTTP效率不高问题。2015年HTTP2基FSPDY协议发布、专注干性能

。HTTP2新特性

   。**二进制传输**，将请求相应数据分割为更小的数据帧，并采用二进制编码。

   。**Header压缩**，专门开发了HPACK压缩算法，在客户端和服务器端建立字典(索引表)，用索引表示重复字符串，采用哈夫曼编码来压缩整数和字符串。

   。**多路复用**，不再依赖TCP连接去实现并行多流。一个域名下的通信都在单个连接完成，单个连接可以双向传输数据，数据流以消息的形式发送，每个请求都可以携带31Bi的数据，

   。**服务端推送**，在浏览器下载HTML的时候，服务端预测将可能用到的数据提前下载。比如JS文件或者CSS文件。

   。提高了安全性，**不强制加密**，但是事实上都是加密的数据，**HTTP2定义了两个字符串表示，h2表示加密的，h2c表示明文的。**
**HTTP2.0缺陷**
。**TCP的TLS连接建立耗时**
。**TCP队头阻塞问题没有完全解决**
HTTP3新特性
。Google意识到SPDY的问题后又推出了**QUIC协议。HTTP3基于QUIC协议**

## (3.6) QUIC协议【b】

**自定义连接机制**:一条TCP连接是由**四元组标识的，分别是源 IP、源端口、目的IP、目的端口。**一旦一个元素发生变化时，就需要断开重连，重新连接。在移动互联情况下，当手机信号不稳定或者在WIFI和移动网络**切换时，都会导致重连，从而进行再次的三次握手，导致一定的时延。**这在TCP是没有办法的，但是**基于UDP**，就可以在**QUIC自己的逻辑里面维护连接的机制**，不再以四元组标识，而是以**一个64位的随机数作为ID来标识**，而且**UDP是无连接的**，所以当IP或者端口变化的时候，**只要ID不变，就不需要重新建立连接。**

**自定义重传机制**:TCP为了保证可靠性、涌过使用序号和应答机制、来能决顺序问题和丢包问题、任何一个序号的包发过去。都要在一定的时间内得到应答，否则一旦超时，就会重发这个序号的包。这个超时是通过采样往返时间RTT不断调整的。其实，在**TCP里面超时的采样存在在不准确**的问题。例如发送一个包，序号为100，发现没有返回，于是再发送一个100，过一阵返回一个ACK101。这个时候客户端知道这个包肯定收到了。但是往返时间是多少呢？ 是ACK到达的时间减去后一个100发送的时间、还是减去前一个100发送的时间呢？ 事实是，第一种算法把时间算短了，第二种算法把时间算长了。**QUIC也有序列号，是递增的**。任何一个序列号的包只发送一次、下次就要加1了。#例知，发送一个包序号是100，发现没有返回；再次发送的时候、席号就是101了:如果返回的ACK 100.就是对第一个包的响应，如果返回ACK 101就是对第二个包的响应。RTT计算相对准确。但是这里有一个问题，就是怎么知道包100和101发送的是同样的内容? **QUIC是定义了Offset概念**，**QUIC既然是面向连接的**(所谓的连接其实就是两边状态，状态如果不在UDP层维护，就可以在应用层维护），也就像TCP一样，是一个数据流，发送的数据在这个数据流里面有一个偏移量Offset，可以通过Offset查看数据发送到了哪里，这样只要这个offset的包没有来，就要重发，如果来了，按照offset拼接，还是能够拼成一个流。

**无阻塞的多路复用**:同HTTP 2.0一样，同一条QUIC连接上可以创建多个stream，来发送多个HTTP 请求，但是，QUIC是基于UDP的，一个连接上的多个stream之间没有依赖，这样，假如stream2丢了一个UDP包，后面**跟着**stream3的一个UDP包，虽然**stream2的那个包需要重传**，但是**stream3**的包**无需等待**，就可以发给用户。

**自定义流量控制:**TCP的流量控制是通过**滑动窗口协议**，QUIC的流量控制是通过Window_Update,来告诉对端它可以接受的字节数。但是QUIC的窗口是**适应自己的多路复用机制**的，不单在一个连接上控制窗口，还在一个连接中的**每个stream控制窗口。**

**窗口概念**

通过一个变量，**获取接收方**能接受的流量，**告知发送方**你需要发多少。

## (3.7) SSL的四次握手过程

。客户端请求建立SSL连接，发送支持的加密方式以及一个随机数**client random**给服务器;

。**服务器**选择其中的一种加密方式，并且再加上另外一个**随机数**server random，和**数字证书**(其中有**公钥**)，发送给客户端

。**客户端**确认这个数字证书是有效的，并且再生成一个新的随机数new client random，将这个随机数用服务器发送给它的数字证书中的**公钥进行加密**发送给服务器，

。**服务器**收到客户端的回复，利用自己的**私钥进行解密**，获得这个随机数，然后**通过将前面这三个随机数以及他们协商的加密方式，计算生成一个对称密钥。**

。至此提手阶段完成，之后的会话他们就通过这个非对称密钥进行加密传输。HTTPS以完成上述HTTP的缺陷，**通过对通信内容加密保证了内容的安全性**，并且通过**数字证书可以验证双方的身份**，因为**数字证书是由权威机构(CA)颁布的**。并且因为报文中有发送方的数字签名，所以接收方可以先验证数字签名，从而验证了数据没有被篡改，保证了完整性。

## (3.8) HTTPS的缺陷【b】

。HTTPS协议握手阶段**比较费时**，会使页面的加载时间延长近50%，增加10%到20%的**耗电**
。HTTPS连**接缓存不如HTTP高效**，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响
。**SSL证书需要钱**，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用。

[Let's Encrypt - 免费的SSL/TLS证书 (letsencrypt.org)](https://letsencrypt.org/zh-cn/)

。SSL证书通常**需要绑定IP**，不能在同一IP上绑定多个域名，IPv4资源不可能支撑这个消耗。

。HTTPS协议的**加密范围也比较有限**，在黑客攻、服务击、服务器动特等方面几平起不到什么作用。最关的，SSL 证书的信用特体系并不安全，特别是在某些国家可以控制CA根证书的情况下，中间人攻击一样可行。**【算法有限】**

最近有红三角的网站，证书都是美国发的。

## （3.9）HTTPS性能优化

TCP有个特性就是慢启动。握手协议大于窗口大小，就要分片

。**TCP性能优化：每个 TCP 连接都有一个称为拥塞窗口的速度极限**，这个窗口最初时较小，在可靠性能保证的情况下随时间增长。**这种机制被称为慢启动。【如log函数图】**因此，对于所有的 TCP 连接，启动速度很慢，对
于 TLS 连接情况则更糟糕，因为 **TLS 握手协议消耗了宝贵的初始连接字节**（当拥塞窗口较小时）。如果拥塞窗口足够大，那么慢启动不会有额外的延迟。但是，如果**较长的握手协议超过了拥塞窗口的大小**，发送方必须将它拆分为两块，先发送一块，等待确认（一个往返），增加拥塞窗口，然后再发送剩下的部分。**启动速度限制被称为 初始拥塞窗口**。RFC6928 建议初始拥塞窗口设置为10个网络段（约15KB）。早期的建议是使用2-4个网络段起步。在旧版本的Linux平台上，可以改变路由的初始拥塞窗口。慢启动可以作用于一段时间内没有任何流量的连接上，降低其速度，并且速度下降地非常快。 

**在Linux 上，可以在连接空闲时禁用慢启动。**sysctl -w net.ipv4.tcp_slow_start_after_idle=0
。**使用长连接**：大部分情况下 TLS 性能影响集中在每一个连接的开始握手阶段。一个**重要的优化技术是在连接数允许的情况下尽可能保持每个连接不断开**。长连接的缺点是在最后一个 HTTP 连接完成之后，
服务器在关闭连接之前会等待一定时间，虽然一个连接不会消耗太多的资源，但是**降低了服务器的总体伸缩性**。长连接适用于客户端突发大量请求的场景。如果 TLS 是由 OpenSSL 处理的，请确保服务器正确设置SSL_MODE_RELEASE_BUFFERS标识。
。 **尽可能的使用HTTP/2.0版本。**
。**CDN**，使用 CDN 可以实现世界级的性能，它利用地理上分散的服务器提供边缘缓存和流量优化。
。**减少秘钥交换**：使用 TLS 最大的成本除了延迟以外，就是用于安全参数协商的 CPU 密集型加密操作。这部分通讯称为密钥交换（key exchange）。密钥交换的 CPU 消耗很大程度上取决于服务器选择的私
钥算法、私钥长度和密钥交换算法。
。**证书**：一次完整的 TLS 握手期间，服务器会把它的证书链发送给客户端验证。证书链的长度和正确性对握手的性能有很大影响。
      。**使用尽可能少的证书**：证书链里的每个证书都会增大握手数据包，证书链中包含太多证书有可能导致 TCP 初始拥塞窗口溢出。
      。 **只包含必需的证书**：证书链里包含非必需证书是个常见错误，每个这样的证书会给握手协议额外增加1-2KB。
       。 **提供完整的证书链**：服务器必须提供一个被根证书信任的完整证书链。
       。 **使用椭圆曲线证书链**：因为 ECDSA 私钥长度使用更少的位，所以 ECDSA 证书会更小。
       。 **避免同一张证书绑定过多域名**：每增加一个域名都会增加证书的大小，对于大量域名来说会有明显的影响。
。**吊销检查**：虽然证书吊销状态在不断变化，并且用户代理对证书吊销的行为差异很大，但是作为服务器，要做的就是尽可能快地传递吊销信息。
。**使用 OCSP**：信息的证书 OCSP **被设计用于提供实时查询**，允许用户代理只请求访问网站的吊销信息，查询简短而快速（一个HTTP请求）。相比之下 CRL 是一个包含大量被吊销证书的列表。
。**使用具有快速且可靠的 OCSP 响应程序的 CA**：不同 CA 之间的 OCSP 响应程序性能不同，在你向 CA 提交之前先检查他们的历史 OCSP 响应程序。 另一个选择 CA 的标准是它更新 OCSP 响应程序
的速度.
。**部署 OCSP stapling**：OCSP stapling 是一种允许在 TLS 握手中包含吊销信息（整个OCSP响应）的协议功能。启用之后，通过给予用户代理进行吊销检查的全部信息以带来更好地性能，可以省去
用户代理通过独立的连接获取 CA 的 OCSP 响应程序来查询吊销信息。
。**协议兼容**：如果你的服务器与一些新版本协议的特性（例如TLS 1.2）不兼容，浏览器可能需要通过与服务器进行多次尝试，才能协商一个加密的连接。确保良好的 TLS 性能的最好方式是升级最新的
TLS 协议栈以支持较新的协议版本和扩展。
。**硬件加速**：随着 CPU 速度的不断提高，基于软件的 TLS 实现在普通 CPU 上已经运行得足够快，无需专门的加密硬件就能处理大量的 HTTPS 请求。但安装加速卡或许能够提升速度。

### OCSP-在线证书状态协议。

目的：验证SSL证书的有效性，以确保它未被吊销。



OCSP Stapling 就是为了解决 OCSP 隐私问题和性能问题而生的。其原理是：网站服务器将自行查询OCSP服务器并缓存响应结果，然后在与浏览器进行TLS连接时返回给浏览器，这样浏览器就不需要再去查询了。

OCSP装订实现了以下目标：

- 保证用户数据的安全性和机密性;
- 用户更可能下载受保护的内容，因为浏览器不需要发出多个请求；
- 保留客户端的带宽，这对于移动用户是一个优势；
- 通过提高受保护内容的交付速度来提高信心和客户满意度；

## （3.10）SSL和TLS的区别

• Secure Socket Layer，安全套接字层，**SSL位于可靠的面向连接的网络层协议和应用层协议之间的一种协议层。**SSL通过互相认证、使用数字签名确保完整性、使用加密确保私密性，以实现客户端和服务器之间的安全通讯。该协议由两层组成：**SSL记录协议和SSL握手协议，**
     。SSL记录协议（SSL Record Protocol）：它建立在可靠的传输协议（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能的支持。
     。SLL握手协议（SSL Handshake Protocol）：它建立在SSL记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等。
• Transport Layer Security，传输层安全协议，**用于两个应用程序之间提供保密性和数据完整性，**
• SSL是Netscape开发的专门用于保护Web通讯的，目前版本为3.0.最新版本的TLS 1.0是IETE（工程任务组）指定的一种新的协议，它建立在SSL 3.0协议规范之上，是SSL 3.0的后续版本。两者差别极小，可以理解为SSL 3.1，它是写入了RFC的。SSL协议
位于TCP/IP协议与各种应用层协议之间，为数据通讯提供安全支持。
•**安全传输层协议（TLS）用于在两个通信应用程序之间提供保密性和数据完整性。该协议由两成组成：TLS记录协议（TLS Record）和TLS握手协议（TLS Handshake）。**
。TLS的最大优势就在于：**TLS是独立于应用的协议。**高层协议可以透明地分布在TLS协议上面。然而，TLS标准并没有规定应用程序如何在TLS上增加安全性；它如何启动TLS握手协议以及如何解释交换的认证证书的**决定权留给协议的设计者和实施者来判断**。**TLS的主要目标是使SSL更安全，并使协议的规范更精确和完善。**

## （3.11）HTTPS 11次握手流程图

![image-20221128210514493](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221128210514493.png)

## (3.12) HTTP与Restful

• **HTTPS 采用混合的加密机制**，使用**非对称密钥加密用于传输**，**对称密钥来保证传输过程的安全性**，之后使用**对称密钥加密进行通信来保证通信过程的效率**。由于其算法复杂，而使得加密解密速度没有对称加密解密的速度快。
• **所有的安全方法也都是幂等的。POST方法为什么不是幂等的？POST所对应的URI并非创建的资源本身，而是资源的接收者。**比如：P0ST  http://www.forum.com/articles 的语义是在http://www.forum.com/articles 下创建一篇帖子，
。HTTP响应中应包含帖子的创建状态以及帖子的URI。**两次相同的POST请求会在服务器端创建两份资源，它们具有不同的URI**；所以，**POST方法不具备幂等性**。而PUT所对应的URI是要创建或更新的资源本身。HTTP DELETE方法用于删除资源，有副作用，但它应该满足幂等性。
。 **HTTP协议本身是一种面向资源的应用层协议**，但对HTTP协议的使用实际上存在着两种不同的方式：

**一种是RESTful的**，它把HTTP当成应用层协议，比较忠实地遵守了HTTP协议的各种规定；

**另一种是SOA的**，它并没有完全把HTTP当成应用层协议，而把HTTP协议作为了传输层协议，然后在HTTP之上建立了自己的应用层协议，
。在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。在使用 XMLHTTPRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。但是GET 方法 Header和 Data 会一起发送。
• **HTTPS并非是应用层的一种新协议，它只是在HTTP通信接口部分用SSL（Secure Socket Layer）和TLS（Transport Layer Security）协议代替而已。**
。**浏览器使用HTTP时，直接同TCP通信；当浏览器使用HTTPS时，浏览器会先同TLS/SSL进行通信，然后TLS/SSL再同TCP进行通信。**在使用TLS/SSL后，HTTP便拥有了加密功能。**TLS/SSL是独立于HTTP的协议**，所以其也可以同应用层的其他协议配合使用。SSL类似于TCP的三次握手，在HTTP连接建立之前进行四次握手，从而客户端喝服务端沟通好HTTP传输时对称加密的密钥。



# 运输层

# （1）概述与UDP

运输层协议是为运行在不同主机上的进程提供逻辑通信，而网络层协议是为主机提供逻辑通信。
TCP与七层OSI/RM对应关系：
应用层：应用层，表示层，会话层
传输层：运输层
网络层：网络层
网络接入层：数据两路层，物理层
TCP协议的信息分组叫做数据段，而UDP协议的信息分组叫做数据报。
进程可能有多个套接字，每个套接字都有一个唯一的标识符，其格式取决于是TCP套接字还是UDP套接字。
UDP的套接字使用(目的地址,目的端口)描述。

![image-20221126152708911](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221126152708911.png)

TCP的套接字使用（源地址，源端口，目的地址，目的端口）【四元组】

![image-20221126152924821](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221126152924821.png)

。UDP发送报文是并没有双方握手，因此UDP是面向无连接的。

。UDP使得应用层可以更好的控制数据发送的时间和要发送的数据。

。RIP的选路表就是使用的UDP，UDP的首部只有4个字段，每个字段2字节。

。简单的编码方式无法纠正错误，例如CRC或者校验和，但是他们能检测到错误，这就是校验和方法在传输领域流行的原因。

### RIP协议概述

RIP（Routing Information Protocol ，路由信息协议），是应用较早使用较为普遍的内部网关协议（Internal Gateway Protocol ， 简称IGP）。是基于UDP，端口520的应用层协议。

适用范围：小型同类网络，是典型的距离矢量协议

**距离矢量的定义**

- **距离：**[ --R1------R2------2.2.2.0/24 ] 如图，对于路由器R1来说发送数据包到达2.2.2.0/24网段，就有1跳（距离）。
- **矢量：**也就是方向的意思，也就是路由器应该往哪个方向或者说是使用哪个接口转发数据包。

距离矢量的特点

采取的**周期性**（**广播**）的方式更新整张路由表

### 距离矢量的工作原理

1. 路由器初始启动。将自己直连的网络写入路由表；
2. 进行初次的路由信息交换。这个时候就是互相交换自己的路由表学习自己不知道的网段；
3. **收敛**完成。根据网络拓的大小，经过N轮的学习最终运行RIP的路由器完成对所有位置网段的学习更新（加入自己路由表中，全网可达）。

- 判断路由器是否收敛完成的标准是：当所有路由表都包含相同的网络信息且无新信息时收敛结束。

> 注意：网路在路由器收敛结束之前是无法完成正常工作的。

每一种动态路由协议都有自己的管理距离（AD值）

正是由于RIP更新方式的特点，从而产生漏洞 —— 环路

### **RIP防环机制**

**1. 定义最大度量值以防止计数至无穷大**规定最大跳数为16，凡是达到16跳为不可达路由

**2. 水平分割**路由器从一个端口收到路由更新消息，那么在广播自己的路由表时就不会从收到更新的该接口广播

**3. 路由毒（Route Poisoning）化或毒性反转**

**4. 抑制计时器 Hold-Down Timer**

**5. 触发更新**

### CRC

CRC就是一种优秀的**检错码。**它的计算原理，说白了就是作除法。把比特流看作多项式的系数。设定一个生成多项式（generator polynomial）作为除数。数据流看作被除数。发送方需要在数据流末尾加上一段冗余码，**使得组合后的新数据流能够整除除数**。这段冗余码就是所谓的CRC

（如何计算？在数据流末尾补CRC长度的0，然后做除法得到的余数就是了。）发送方计算好CRC后，把它加到末尾。然后接收方通过传过来的数据做除法计算余数，**如果余数不为0，就说明有错误发生。**

总结一下，我们把数据流看作一个被除数，同时约定了一个除数，把通过计算获得一段对应的CRC码字。 然后呢，计算过程中的除法有点特殊，是模2除法。



# （2）TCP连接与状态

TCP连接是一种面向连接的、面向单播的协议。一个TCP连接通常分为启动、数据传输和退出三个阶段。连接时序图如下所示：

![image-20221126154623082](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221126154623082.png)



通常情况下，建立建接会频繁的发送SYN报文段，第一个SYN报文段发出后第二个仅隔3秒就会发送第二个，然后间隔6秒发送第三个、依次类推，这种方式叫做指数回退，这个发送的间隔时间是最大发送间隔时间，在实际的信息传输过程中会有所变化。一些系统可以配置初始发送SYN报文段的次数，通常选择一个较小的值，在Linux中**net.ipv4.tcp_syn_retries**表示一次主动申请打开尝试发送SYN报文段的最大次数，**net.ipv4.tcp_synack_retires**表示响应对方的一个主动打开请求发送SYN+ACK的最大次数。 

### **大量TIME_WAIT造成的影响**

在高并发短连接的TCP服务器上，当服务器处理完请求后立刻主动正常关闭连接。这个场景下会出现大量socket处于TIME_WAIT状态。如果客户端的并发量持续很高，此时部分客户端就会显示连接不上，
我来解释下这个场景。主动正常关闭TCP连接，都会出现TIMEWAIT。为什么我们要关注这个高并发短连接呢？有两个方面需要注意：
（1）高并发可以让服务器在短时间范围内同时占用大量端口，而端口有个0~65535的范围，并不是很多，刨除系统和其他服务要用的，剩下的就更少了。
（2）在这个场景中，短连接表示"业务处理+传输数据的时间 远远小于 TIMEWAIT超时的时间”的连接。

### **如何尽量处理TIMEWAIT过多？**

**编辑内核文件/etc/sysctl.conf**，加入以下内容：
**net.ipv4.tcp_syncookies = 1** 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；
**net.ipv4.tcp_tw_reuse = 1** 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
**net.ipv4.tcp_tw_recycle = 1** 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭，
net.ipv4.tcp_fin_timeout 修改系默认的 TIMEOUT 时间
简单来说，就是打开系统的TIMEWAIT重用和快速回收。

## （2.1）连接过程

（1）客户端的TCP首先向服务器端发送一个不包含应用层数据的特殊报文段，在报文段的首部中的一个**标志位SYN=1**。另外客户端会随机选择一个起始序号，并将这个编号放置在TCP SYN的序号字段中。
（2）到达服务器后将会取出TCP SYN的字段序号，为这个TCP连接分配TCP缓存和变量，并向客户端发送允许连接的字段。服务端向客户端回复的报文也会将SYN=1，**TCP SYN头部的确认字段被置为随机客户端序号+1**，最后服务端也会创建一个随机的序号放到TCP头部。这个报文段被称作**SYNACK报文段。**
• （3）一旦收到SYNACK报文段，客户端也会分配缓存和变量。客户端**读取服务端的随机序号+1**再放到TCP头部，确认连接。再次发送含有应用层数据的报文**SYN=0。**
• （4）当客户端想要**断开连接**的时候首先会发送一个特殊报文段，**FIN=1**，然后**服务端会发送ACK=1的报文段确认收到**。然后**服务端再发送SYN=1的报文段，客户端也会响应ACK=1。**

## （2.2）状态变化

。客户端状态：首先**发送SYN，客户端进入SYN_SEND状态**，服务器接受SYN，并发送SYNACK后**双方进入ESTABLISHED状态**，表示连接已经建立。当客户端应用程序想要断开的时候**发送FIN并进入FIN_WAIT_1状态，**等待**服务端回复ACK，接收到后进入FIN_WAIT_2状态**。然后服**务端发送FIN**，客户端接收到后进入**TIME_WAIT状态**，并**发送ACK确认报文。随后进入CLOSED状态。**
。服务端状态：首先**启动服务器**端程序以后，将**进入LISTEN状态**，接收到SYN并发送SYNACK后进入**SYN_RECV状态**，接收到客户端发来的**ACK后将进入ESTABLISHED状态**。当接收到客户端的**FIN后立即发送ACK并使自己进入CLOSE_WAIT状态**。然后**发送FIN，进入LAST_FIN**状态，当**收到客**
**户端的ACK后进入CLOSED状态。**

## （2.3）对于TIME_WAIT的设计意义以及持续两个MSL的作用

设计TIME_WAIT的目的在于允许任何受制于一条关闭连接的数据被丢弃，在这段时间内，等待的TCP通常不需要进行任何操作，只需要维持当前状态直到**2MSL计时结束。**客户端在完成FIN_WAIT_1和FIN_WAIT_2后会进入TIME_WAIT阶段，该阶段会等待2MSL。如果在**2MSL期间内收到其他报文段，将会导致TIME WAIT错误**，许多系统不会对TIME WAIT期间的RST报文做出响应，	
    • **可靠的关闭TCP的连接，避免ACK丢失。**比如网络拥塞，如果主动关闭方最后一个ACK没有被接收方收到的话，在此时因为持续了两个MSL而尚未关闭的TIME_WAIT就会把这些尾巴问题给处理掉，比如说，重新启动TIME_WAIT,然后重新发送给一次ACK。实际上TCP总是重传FIN，直到最后一个ACK收到，毕竟过早的进入CLOSED状态，由于延迟等其他因素的存在可能会导致另一端接收到RST报文段。
    • 防止由于没有持续TIME_WAIT的时间导致新的TCP连接建立起来，延迟的FIN重传包会干扰新的连接，**使旧的数据包在网络因过期而消失**
**在Linux中net.ipv4.tcp fin_timeout记录了2MSL状态需要的超时秒数。**

### 大量的TIME_WAIT和CLOSE_WAIT

**TIME_WAIT状态的产生是主动关闭连接产生的，CLOSE_WAIT的关闭是被动关闭连接产生的。** 大量的TIME_WAIT（常见于爬虫服务器或者Web服务器）可能会导致程序无法接收更多的连接，**解决大量TIME_WAIT快速回收的方法有三种：**
• **主动调用shutdown()函数**【socket的函数】
。**使用池化技术**
**• 设置内核参数**，主要包括：net.ipv4.tcp_tw_**reuse**（开启TIME_WAIT**重用**）、net.ipv4.tcp_tw_recycle（开启TIME_WAIT**快速回收**）、开启SYN Cookies、fin_timeout

通常大量的CLOSE_WAIT的产生是服务器程序出现Bug导致的，通过调整内核参数无法得到改善。
例如：服务器A是一台爬虫服务器，它使用简单的HttpClient去请求资源服务器B上面的Apache获取文件资源，正常情况下，如果请求成功，那么在抓取完 资源后，服务器A会主动发出关闭连接的请求，这个时候就是主动关闭连接，服务器A的连接状态我们可以看到是TIME_WAIT。如果一旦发生异常呢？假设 **请求的资源服务器B上并不存在**，那么这个时候就会**由服务器B发出关闭连接的请求，服务器A就是被动的关闭了连接**，如果**服务器A被动关闭连接之后程序员忘了 让HttpClient释放连接，那就会造成CLOSE_WAIT的状态了，**

## （2.4）半关闭模式【极为常见】

此外TCP还支持半关闭模式，因为客户端和服务器端都关闭才说明整个双向连接关闭，然而半关闭模式一般用于**通知等数据传输**。在应用程序中，**伯克利提供的Socket API通过shutdown()**函数实现而不是close()。
**Half-Open模式存在无法感知对方是否宕机的问题，**因此**TCP设计了Keepalive选项用来防止Half-Open由于对方宕机导致无法关闭，**         仓商标准不一样

eBPF是一项革命性的技术，可以在Linux内核中运行沙盒程序，而无需更改内核源代码或加载内核模块。

## （2.5）对于同时打开或者同时关闭的情况

• **同时打开，服务器始终是被动的打开者**，因此可以区分服务器与客户端，而且连接被区分为两个TCP连接。一个同时打开的情况需要交换4个报文段，比普通握手增加一个报文段
• 同时关闭，并没有太大的区别，

## （2.6）初始ISN的选择

在建立连接发送SYN之前，初始ISN会随着时间改变，RFC0793中指出**ISN应该是一个32位无符号计数器**，该计数器**每1微妙加1**，这是为了防止与其他计数器重叠。现代操作系统常用**半随机**的方法选择ISN，**Linux上选择ISN相对复杂，采用基于时钟的方案，并且针对每一个连接设置偏移量。**而且**随机偏移量是在TCP连接四元组的基础上Hash生成的**，Hash函数的输入每隔5分钟就会改变一次。高8位是保密序列号，剩余24为是由Hash函数生成，

## （2.7）FIN_WAIT_2状态死循环

在FIN_WAIT_2状态时，上一个FIN报文段已经被确认，并且对方发出的即将关闭连接的信号已经得到ACK报文段的确认，除非出现半关闭的情况，否则该TCP连接段将会一直等待自己发出FIN信号的ACK。由于第二个FIN报文段需要等待对方识别出关闭请求并且回复ACK才会进入TIME_WAIT状态，所以可能出现死循环.
**防止出现FIN_WAIT_2出现死循环的方法是设置Timer机制**，然后**超时后自动转移到CLOSE状态。**

在Linux中使用**net.ipv4.tcp_fin_timeout的数值来设置计时器的秒数**，**默认值是60s，**

## （2.8）重置报文段的作用

一般来说在TCP报文头部设置**RST字段**的场景用于当到达一个报文段相对于该**连接不正确**时，将会回应RST报文段，这将会导致**TCP连接快速卸载。**

RST字段有两大特性：
• 任何排队的数据都会被抛弃，一个RST报文不会被缓存而是立即发送出去。
• 只要发送RST报文就说明该TCP不是正常关闭，

## （2.9）连接队列

一个新的连接在没有被上层应用使用之前，操作系统会将已经摆收到**SYN的连接放入一个队列**，这个**队列的大小由net.ipv4.tcp_max_syn_backlog=1000内核参数控制**
已经完成连接进入**ESTABLISHED状态**但是没有被上层应用使用的连接放入另一个队列，这个**队列的大小由net.core.somaxconn=128内核参数控制**。当进行ESTABLISHED阶段后可能一段时间内没有被上层应用使用，操作系统会缓存接收到的数据。
当这侦听节点的队列已满时，TCP模块会延迟SYN的ACK报文发送，Linux会坚持在能力范围内不忽略进入的连接，这通过net.ipv4.tcp_abort_on_参数设置。这个参数会将在队列即将溢出的情况下对新连接发送RST报文段，通常这个参数不会被打开，因为发送RST报文段是不可取的，服务器繁忙
并不等于服务器错误.

# （3）TCP保活

理论上，中间经过的主机（路由器、中继器、代理设备）可以存在重启或者崩溃，数据线可以断开再连接，只要连接的两端的主机没有重新启动，那么可以认为是一直连接的状态。
一些情况下，**两端需要了解什么时候终止TCP连接进程**或者**两者没有数据交换但是任然需要保持最小数据流**，**TCP保活机制就是应对这两种情况设计的**。TCP的保活机制并不是TCP规范的一部分，但是TCP保活是显示世界中的需要。**TCP保活通过Timer机制实现。**但是TCP保活机制也带来的问题：
。出现短暂的网络错误会导致网络连接断开。
。 保活机制会占用不必要的带宽，
保活机制通常是**应用程序提供，**一般情况下，长时间的频繁交互式应用程序不需要保活，例如SSH连接或者远程桌面连接。

比如Xshell一直放着不用，会自动跟VM断开连接。

**服务器从ntp获取时间，ntp时间从卫星来，卫星的时间又原子钟来。**

TIKV的时间直接读寄存器

# （4）TCP传输与拥塞

TCP的传输控制和拥塞控制都采用了窗口的算法思想，其中**传输控制叫做滑动窗口，拥塞控制叫做拥塞窗口。**

对于滑动窗口协议，每个TCP连接的两端都会维护一个窗口结构，**TCP使用字节为单位**作为窗口内数据的最小管理单元。TCP的流控通过接收端的**通告窗口**实现，该窗口指示了最大可接受的数据量，当**窗口值变为0的时候可以有效阻止发送端继续发送。**当接收端重新获得可用空间时，会发送一个窗口更新通知发送端可以继续发送。**窗口更新**报文通常不含有任何数据，是一个**纯ACK报文**
如果窗口更新的**ACK丢失**，那么通信的双方将会进入一直等待状态。为了防止这种情况的发生，**TCP设计了利用Timer机制的持续计数器**来间歇性的**查询**接收端，观察接受窗口是否增长，这个过程叫做**窗口探测。**
**窗口探测通常包含1byte的数据，采用TCP传输，**因此可以**避免在传输过程中的死锁**。通常TCP会不停的发送窗口探测，由此可能会放弃执行重传操作，这种情况可能会导致某种程度上的资源耗尽，
基于窗口的流控方式可能产生**糊涂窗口综合征**，该缺陷描述为报文段**中数据部分较小但是发送频繁。**这样会导致资源讲一步快速耗尽并且影响传输效率，因此
。对于接收端来说，不应该通告较小的窗口值，
。对于发送端来说，不应该发送较小的报文段

TCP头部有一个字段时**URG**，**该字段用户紧急数据，紧急数据不会被缓存。**

在TCP中，**流量控制实现了发送方和接收方速率的调节**，但是网络中存在众多的**中间节点**，例如路由器，发送方和接收方的速率限制**不仅是参与发送的两端的处理速度**，也有可能是因为路由器无法高速处理到达的流量而被迫**丢弃数据。这种现象叫拥塞；**

针对丢包，TCP采取的手段是**超时重传和快速重传**。**造成丢包在无线网络中通常是因为传输和接受错误，有线网络通常是因为拥塞。** 拥塞是一个在传输链路中比较宏观的问题，检测新的可用带宽很难做到
**拥塞窗口是为了防止过多的数据注入到网络中**，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提：网络能够承受现有的网络负荷。**拥塞控制是一个全局性的过程**，**涉及到所有**的主机、路由器，以及与降低网络传输性能有关的所有因素，

在TCP的设计中，通过在发送端维护一个窗口变量确保发送端的发送速率不会超过网络链路的吞吐率和接收端的处理速率。 swind=min(awind， cwind)。**TCP使用了慢启动和拥塞避免两大算法**，在任**意时刻只会运行其中一个**，

TCP定义了一个丢失事件，**出现超时或者发送方接收到三个ACK**用来**感知传输链路上出现拥塞**。因为**TCP使用确认的方式来触发它的拥塞窗口长度的增大，所以TCP被称作是自定时的。**

## PCIE

**PCIe是什么东西？**

PCI-Express(peripheral component interconnect express)是一种高速串行计算机扩展总线标准。属于高速串行点对点双通道高带宽传输，所连接的设备分配独享通道带宽，不共享总线带宽。PCIe有两种存在形式M.2接口通道形式和PCIe标准插槽。

![img](https://pic2.zhimg.com/80/v2-832f8fd01e6e0410c6e969b01c2fc891_720w.webp)

PCIe可拓展性强，可以支持的设备有：显卡、固态硬盘（PCIe接口形式）、无线网卡、有线网卡、声卡、视频采集卡、PCIe转接M.2接口、PCIe转接USB接口、PCIe转接Tpye-C接口等。

M.2接口通道也是一种PCIe接口，主要插支持M.2的固态硬盘。

## 为什么需要3个ACK？【b】

TCP为了解决传输的两端出现的**信息不对称采用了重传机制**，通知接收方信息不同步，需要进行重传，由于这种依赖**外界刺激**的重传方法比超时重传更快、更及时，因此成为**快速重传**，当某个**数据包出现乱序、丢包或者重复包**时，由于**快速重传机制可以快速进行修复，因此这个修复过程叫做快速修复**。两者合在一起统称**Fast Re-transmit/Fast Restore**，没有FRR机制，TCP完全可以凭借**超时重传来完成可靠传输**，由于是**被动**地等待，所以**传输效率低下**。**FRR机制，使得TCP能够快速地通过三次重复的ACK**，推测报文有丢失的可能，进而**主动重传**，传输效率更高。**FRR增强特性机制就是发现上面三种情况就快速返回ACK，因为ACK报文中的seq代表期待接受后边的数据，多次ACK正好可以表示最新seq值没有发生变化。FRR机制的3个ACK只是重复ACK阈值的通用值。**

当一个新的TCP连接到达时，如果**检测到重传丢包，需要使用慢启动算法**，**目的在于让TCP在使用拥塞避免算法获得更多的带宽之前得到cwind值以及帮助建立ACK时钟**。 通常情况下，在**新连接建立时执行慢启动，随后出现丢包或者3个ACK时执行拥塞避免。**

## TCP Reno拥塞控制算法

**。线性增加，乘性减少**：当出现**丢包**事件的时候让发送方**降低其发送速率**。因为通过该相同的拥塞的路由器的其他TCP连接也很可能产生丢包事件，它们也可能会通过减少相同的窗口值来降低发送速率，因此，该整体作用是让所有通过这一个拥塞路由器的路径的源主机降低向该网络发送数据的速率。TCP采用乘性减少的方式来降低发送速事，**每次发生一次丢包事件都会将拥塞窗口减半**。但**最小不低于1个MSS**。当**提高发送速率的时候采用线性增加的方式**，如果检测到**没有丢包**事件，那么**TCP将会慢慢增加拥塞窗口长度，谨慎的探测可用的带宽资源。每个往返延时都会增加一个MSS。**TCP拥塞控制协议的**线性增长阶段称为避免拥塞。**这样**TCP的发送速率维持在一个锯齿状的图形中。**

![image-20221126182756620](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221126182756620.png)
。**慢启动**：**当一个TCP连接开始的时候拥塞窗口为一个MSS**，但是对于高速网络来说。速率的增长是很慢的，因此这是很遗憾的事情，所以**发送方在初始阶段不是线性增加而是指数增加**。因此在这个慢启动的初始化阶段期间，TCP发送方会以很慢的速率开始传输，但是会以**指数**方式增加传输速率.
。**对超时事件的反应**：**TCP对收到3个冗余ACK和超时事件的反应是不一样的**，当发生超时事件，会**进入慢启动**过程。**TCP通过维持一个阈值变量来管理**这些较为复杂的动态过程。该阈值用来确定慢启动将结束并且避免拥塞将开始的窗口长度。**阈值在初始化的时候被设置为一个很大的值，当发生丢包就减半**，当发生超时事件后就会进入慢启动阶段，当拥塞窗口增长到间值为止。这种**收到 ACK取消进入慢启动的过程叫做快速恢复**

# （5）总结TCP可靠数据传输的原理

**TCP是在端到端不可靠的网络层IP上实现的可靠传输**
（1）仅考虑单向数据传输的情况 下，**先认为底层信道是完全可靠的**。接受端和发送端等待上下层的函数调用发送接收数据即可。但是更为**现实的就是底层信道模型分组中的比特更有可能受损**。因此需要构建一条具有**比特差错检测**的可靠数据传输类似于我们的电话讲话，这种口述消息传递使用了肯定确认和否认机制，

（2）在计算机网络中，**基于这样的重传机制叫做自动重传请求ARQ。ARQ协议中需要使用差错检测，接收方反馈和重传实现。**那么在发送端不仅仅需要等待上层的调用了，**还需要在调用后等待ACK和NAK**。但是这样一来，ACK和NAK的分组受损后还是无法实现接收方反馈，因此，**可以通过冗余分组实现，给分组贴上序号，便可知道该次回应是否是针对该次数据传送。**贴上序号后需要等待ACK是否是0或者1。**为了实现基于时间的重传机制**，那么需要一个**重传倒计数定时器**。在每次发送一个分组以后便启动一个定时器。当**收到来自接收端的ACK=1之后便终止定时器**。但是该协议的一个问题**是性能，那就是停等**。

（3）解决该问题就要实现**流水线技术【pipeline】**，**不使用停等的方式**，允许发送放发送分组无需等待确认。但是带来的问题就是必须增加序号范围，因为每一个分组都需要一个唯一标识。还有就是协议的**发送方和接收方必须实现缓存多个分组**。所需要的**序号范围和分组缓冲大小取决于数据传输协议响应丢失，差错和过度延时分组的方式。****解决流水线技术带来的差错恢复问题有两种方案: 回退N步(GBN)和选择重传(SR)。

GBN协议核心就是在**那些已经传输但是还未被确认**的分组的许可序号范围可以看做是一个长度为N的窗口，因此，该协议也叫作滑动窗口协议。

（4）然而，GBN协议也存在性能问题，就是窗口长度和带宽时延积都很大的时候，流水线中会有很多分组。一个分组的差错就有可能导致GBN重传大量的分组。因此**选择重传**可以让**发送方重传那些可能出错的分组**。这种个别的，按需的重传要求接收方逐个确认正确的分组。再用窗口长度N来限
制流水线中未被确认的分组数。SR的接收方将确认一个正确的分组不管是否有序，失序的分组将被缓存起来，直到所有丢失的分组全都收到才向上层交付

（5）TCP协议是面向连接的，传输的双方必须先**握手**，完成一直保持连接状态，但是这种连接是松散的。**TCP协议也是一种全双工的，并且是点对点的，**

（6）一旦建立一个TCP连接，那么将这些数据引导至发送缓存，发送缓存时在三次握手之后建立的缓存。接下来TCP将会不断地在缓存中取出数据。从缓存中取出数据的多少取决于最大报文段长MSS。 该MSS通常由最初决定的最大链路层帧长度所设置，本地主机发送长度是这样的帧，也就是

• TCP给应用程序提供了**流量控制服务**，以消除发送方使接收缓存溢出的可能性。因此可以说流量控制服务是一个速度匹配服务。TCP发送方也可能因为IP网络的拥塞被遏制，这种形式的发送方的控制被称为**拥塞控制。**
• **TCP通过让发送方保留一个接收窗口的变量来提供流量控制，**



# 网络层

•网络层协议IP提供主机之间的逻辑连接。其服务模型是尽力而为的交付服务。IP是不可靠的信息服务。将主机之间的交付扩展到主机进程上称为运输层的多路复用和多路分解，
**。 一个链路层数据报能承载的最大数据量叫做最大传输单元MTU**
• 每个IP数据报封装在链路层数据报中，再从一台路由器运输到下一个路由器，链**路层协议MTU严格限制着IP数据报长度。**
• 由于不同的协议采用的MTU不同，因此IP数据报会划分成更小的片进行传输。
· 管理距离是指一种路由协议的路由可信度。每一种路由协议按可靠性从高到低，依次分配一个信任等级，这个信任等级就叫管理距离，
• 于两种不同的路由协议到一个目的地的路由信息，路由器首先根据管理距离决定相信哪一个协议。 AD值越低，则它的优先级越高。 一个管理距离是一个从0—255的整数值，0是最可信赖的，而255则意味着不会有业务量通过这个路由。 直连的 AD=0, static 静态的AD=1,EIGRP的AD=90,IGRP的AD=100 、OSPF的AD=110,RIP的 AD=120, .

## （1) RIP【了解】

**RIP是一个端口占用520的基于路由矢量的协议，基于UDP进行工作，以跳数作为度量，超过15条认为不可达，最多支持等价路径负载均衡，默认是4条。**RIP依托于时间周期进行路由表同步。RIP依赖于三个计时器实现路由数据库的维护：
• 更新定时器，30秒
• 路由失效定时器，180秒
• 刷新路由条目定时器，240秒
RIPv1不支持VLSM，属于有类路由协议，不支持认证，RIPv2有所改善，引入了MD5认证，支持VLSM，使用组播的方式发送更新报文而不是RIPv1的广播方式，RIPv2属于无类路由协议。

它是基于Bellman-Ford算法的。这种算法的基本思路是，每个路由器都保存一个路由表，包含多行，每行对应网络中的一个路由器，每一行包含两部分信息，一个是要到目标路由器，从那条线出去，另一个是到目标路由器的距离。那这个信息如何更新呢？每个路由器都知道自己和邻居之间的距离，每
过几秒，每个路由器都将自己所知的到达所有的路由器的距离告知邻居，每个路由器也能从邻居那里得到相似的信息。每个路由器根据新收集的信息，计算和其他路由器的距离，比如自己的一个邻居距离目标路由器的距离是M，而自己距离邻居是x，则自己距离目标路由器是x+M。加入路由器宣告速度
快，但是移除路由器要等到每个路由器认为这个路由器挂掉的时候才会认为是真的挂掉，而且每次需要发送完整的路由表。

RIP协议是一种分布式的基于距离向量的路由选择协议，它的最大优点就是简单。RIP协议要求网络中的每一个路由器都必须维护一个它自己到其他目的网络的距离记录，也可以说是距离向量，什么是RIP协议中的距离？

RIP协议规定从路由器可以直接到达的网络的距离为1，从路由器到其他网络，没经过一个路由器，距离就加1，这跟TTL很相似，RIP协议还规定一条路径最多只能经过15个路由器，即距离为16的网络相当于不可到达，从这里可以看出，RIP协议只能在小型互联网中使用。

**RIP不能在两个网络之间使用多个路由**，即到某个网络只能存在一条路径，而且这条路径经过的路由器，最少，RIP协议是根据距离，来判断到某一个网络的距离，所以即使存在一条高速，但是“距离”长的路径，RIP协议也不会选择它。这也是RIP协议存在的缺点。
RIP协议的特点：
• 只和相邻的路由器交换信息，不相邻的路由器不交换信息。
• 路由器交换的信息指的是当前路由器所知道的全部的信息，即路由表，RIP协议的路由表项是：到某个网络的最短路径，以及下一跳地址，
• 路由器按固定的时间交换信息，如每隔30秒交换一次信息

那么一个路由器是如何知道整个网络的路由信息的呢？RIP协议刚开始工作时，和相邻的路由器交换信息，整个网络中的路由器都是如此，在经过许多次的信息交换之后，路由信息被逐渐传递出去，最终，任何一个路由器都会知道到某一个网络的最短路径，和下一跳地址。RIP协议最重要的就是它的距
离向量算法。

对于某一个路由器来说，从它相邻的路由器X发过来的RIP报文（内容是：到某个网络N的最短路径，以及下一跳地址，），首先要做如下处理：

**距离向量算法**： 对于某一个路由器来说，从它相邻的路由器X发过来的RIP报文（内容是：到**某个网络N的最短路径，以及下一跳地址**），首先要做如下处理：
• 修改报文中的所有项目，将路由表项中的下一跳地址都改为X，然后将距离加一
• 对于修改过的报文，进行如下步步骤
        。若路由器的路由表中，不存在到N的路由，则将修改过的表项加入到自己的路由表中
        。 若路由器的路由表中，存在到N的路由，再进行如下步骤
             ● 若路由表中的下一跳地址就是X，那么将修改过的表项替换原来的路由（以最新的消息为准）。
             • 若路由表中的下一跳地址不是X，则将自己的路由的距离，与修改过的表项中的距离相比，若修改过的表项中的距离比自己的小，那么替换路由，否则什么也不做。

• 若三分钟还没有收到相邻路由器发过来的RIP报文，则将此相邻路由标记为不可到达，即把距离设置为16
·完成
**RIP报文使用UDP进行传输，即将整个报文封装成UDP数据报的数据部分，端口为520。RIP协议的缺点是坏消息传递的很慢，但是实现简单，开销较小**



## （2）OSPF【知道一下就行了】

开放式最短路径优先。广泛应用在数据中心中的协议。由于主要用在数据中心内部，用于路由决策，因而称为内部网关协议（Interior Gateway Protocol，简称IGP）。内部网关协议的重点就是找到最短的路径。在一个组织内部，路径最短往往最优。当然有时候OSPF可以发现多个最短的路径，可以在
这多个路径中进行负载均衡，这常常被称为等价路由。由于OSPF用于更大的网络区域，采用SPF算法计算到达目的地的最优路径，在SPF算法中，有两个主要概念：
• 链路：路由器接口
• 状态：描述接口及其邻居路由器之间的关系
在OSPF的算法中每个路由器都把自己当做Root，并且基于成本Cost来计算到达的目的地的最短路径，Cost=参考带宽/接口带宽，参考带宽是100M，如果实际网络中带宽超过100M，那么将会出现不理想的负载均衡，因此在实际配置的时候需要修改参考带宽。
OSPF的特征：
• 快速适应网络变化
• 在网络发生变化时,发送触发更新
• 以较低的频率(每30分钟)发送定期更新.这被称为链路状态刷新
• 支持不连续子网和CIDR
· 支持手动路由汇总
• 收敛时间知
• 采用Cost作为度量值
• 使用区域概念,这可有效的减少协议对路由器的CPU和内存的占用
• 有路由验证功能,支持等价负载均衡
运行OSPF的路由器需要一个能够唯一标示自己的Router ID，
（2.1）报文类型
Hello（发现和维护邻居关系）、DBD（链路状态数据库LSDB中LSA的描述信息）、LSR（链路状态请求，用于向邻居请求获得链路状态数据）、LSU（链路状态更新，包含多个LSA）、LSACK（对LSU中的LSA进行确认）。
可以将OSPF的工作过程理解为饭店吃饭：首先通过Hello打招呼，然后DBD表示看一下菜单，接着采用多个LSR和服务员说点哪一些菜，然后服务员通过LSU上菜，完成后通过LSACK结账，相应的LSDB就是厨房，LSU是盘子，LSA是菜，
当链路状态没有发生变化时，OSPF路由器周期性地产生与其相连的所有链路的状态信息。每个LSA都有个生存期，这个生存期的最大期限是1小时，事发路由器在发送LSA的时候会把LSA的生存期设为0，随着时间的推移，这个LSA的生存期到达1小时后就会被接收路由器从LSDB中删除。通常，路由器
每30分钟就发送链路相关的LSU来刷新旧的LSA，

## （2.2）区域

区域概念的提出使得OSPF可以适应更大的网络拓扑，这样有效解决了LSA泛洪问题，在不同的区域上通过边界路由对路由表进行汇总。在区域角色划分上，OSPF将区域分为骨干区域和常规区域，常规区域之间的报文传递必须通过骨干区域才可以，并且骨干区域只能有一个，
OSPF多区域中路由器可分为以下4种类型
• 内部路由器： 所有接口在同一区域的路由器，维护一个链路状态数据库。
•主干路由器： 连接到OSPF网络主干区域的路由器。也就是说，路由器至少有一个接口连接到区域0.
·区域边界路由器(ABR)： 具有连接多区域接口的路由器，一般作为一个区域的出口。ABR为每一个所连接的区域建立链路状态数据库，负责将所连接区域的路由摘要信息发送到主干区域，而主干区域，而主干区域上的ABR则负责将这些信息发送到各个区域。生成LSA3，
• 自治域系统边界路由器(ASBR)： 连接不同AS的路由器，它可以引入外部路由。生成LSA5、LSA7。
OSPF的区域类型：
• 标准区域： 一个标准区域可以接收链路更新信息和路由总结，泛洪LSA1，LSA2，LSA3，LSA4，LSA5，
• 主干区域： 主干区域是连接各个区域的中心实体。主干区域始终是“区域 0”，所有其他的区域都要连接到这个区域上交换路由信息。主干区域拥有标准区域的所有性质，泛洪LSA1，LSA2，LSA3，LSA4，LSA5。
·来精区域/末节区域： 末梢区域是不接受自治系统以外的路由信息的区域。如果需要自治系统以外的路由，它使用默认路由0.0.0.0，泛洪LSA1、LSA2、LSA3.
• 完全末梢区域： 不接收外部自治系统的路由及自治系统内其他区域的路由总结。需要发送到区域外的报文则使用默认路由0.0.0.0，泛洪LSA1、LSA2、(LSA3 default)。
• 非纯末梢区域(NSSA)： 类似于末梢区域，但是允许接收以LSA7发送的外部路由信息，并且把LSA7转成LSA5。泛洪LSA1、LSA2、LSA3、LSA7、(LSA7 default)。
·完非纯全末榜区域： 类似于末梢区域，但是允许接收以LSA7发送的外部路由信息，并且把LSA7转成I SA5、（5 WI S41 I SA？I S47 （ S43 default)

## （2.3）OSPF的三张表

邻居表：使用邻居机制来发现和维持路由的存在，邻居表存储了双向通信的邻居关系OSPF路由器列表的信息
拓扑表：LSDB中的结构。
路由表：对LSDB进行计算（Dijkstra），然后得出的结果。

（2.4）路由器状态
• Down： 这是OSPF建立交互关系的初始化状态，OSPF进程没有与任何邻居交换信息，等待进入Init状态。
• Init：Initialization 初始化状态，路由器的各个接口通过224.0.0.5发送Hello数据报文到其他运行OSPF的路由器，当邻居路由器收到第一个Hello数据报文，这时就进入Init状态。在该状态时，OSPF路由器已经接收到相邻路由器发来的Hello数据报文，但自身的ID并没有出现在该Hello报文内，
也就是说，双方的双向信还没有建立起来。Hello包用来发现邻居并建立邻接关系，通过组播地址224.0.0.5发送给所有路由器，通告两台路由器相邻关系所必需的参数。在以太网和帧中继网络等多路访问网络中选举指定路由器DR和备用指定路由器BDR。选举过程
。在和邻居建立双向通信之后,检查邻居的Hello包中Priority、DR和BDR字段,列出所有可以参与DR/BDR选举的邻居。所有的路由器声明它们自己就是DR/BDR(Hello包中DR字段的值就是它们自己的接口地址；BDR字段的值就是它们自己的接口地址)
。从这个有参与选举DR/BDR权的列表中,创建一组没有声明自己就是DR的路由器的子集(声明自己是DR的路由器将不会被选举为BDR)
。 如果在这个子集里,不管有没有宣称自己就是BDR,只要在Hello包中BDR字段就等于自己接口的地址,优先级最高的就被选举为BDR;如果优先级都一样，RID最高的选举为BDR
。如果在Hello包中DR字段就等于自己接口的地址,优先级最高的就被选举为DR;如果优先级都一样,RID最高的选举为DR;如果没有路由器宣称自己就是DR,那么新选举的BDR就成为DR
。当网络中已经选举了DR/BDR后,又出现了1台新的优先级更高的路由器,DR/BDR是不会重新选举的
∘ DR/BDR选举完成后,其他Rother只和DR/BDR形成邻接关系.所有的路由器将组播Hello包到224.0.0.5,以便它们能跟踪其他邻居的信息.其他Rother只组播update packet到224.0.0.6,只有DR/BDR监听这个地址 .一旦出问题,反过来,DR将使用224.0.0.5泛洪更新到其他路由器
• 2-Way： 双向状态，这个状态可以说是建立交互方式真正的开始步骤。在这个状态，路由器接收到一个Hello回应报文，这个Hello含有自己和邻居信息，路由器看到自身已经处于相邻路由器的Hello数据报内，双向通信已经建立。指定路由器及备份指定路由器的选择正是在这个状态完成的。在这
个状态，OSPF路由器还可以根据其中的一个路由器是否指定路由器或是根据链路是否点对点或虚拟链路来决定是否建立交互关系，
ExStart：启动状态，这个状态路由器之间的关系成为邻居关系，路由器和它的邻居通过相互交换DD报文(该报文称为空DD报文，它并不包含实际内容，只包含一些标志位)，来决定路由器之间的主从关系，且具有最高ID的路由将成为主设备，是唯一能够增加序号的路由器。
• Exchange：交换状态，在这个状态，路由器向相邻的OSPF路由器发送DD报文来交换链路状态信息(主路由器先发)。DD报文包含了出现在LSDB中的LSA条目头部信息，条目信息可以为一条链路(link)或者一个网络。从这个状态起，OSPF进入Flooding状态，
Flooding在点到点和多路访问型网络中有所不同：
。在一个点对点型网络中，使用多播地址224.0.0.5向邻居发送LSU；
。在一个多路访问型网络中，DR使用多播地址224.0.0.6向DR和BDR发送更新数据包。当DR接收到该数据报文并确认后，它使用多播地址224.0.0.5泛洪扩散更新的数据包到网络上的DR。
。如果OSPF数据包被封装在以太网帧内，目的MAC组播地址分别为：0100.5E00.0005，0100.5E00.0006。
OSPF的关键是通过Flooding方式发送LSA来实现数据库同步。
• Loading： 在Loading状态，OSPF路由器会就其发现的相邻路由器的新的链路状态数据，发送LSR给相邻路由器。相邻路由器收到LSR以后，以LSU作为应答，其中包含了LSR所需要的完整信息。路由器收到LSU后，发送LSACK再次做出确认。
• Full：这是两个OSPF路由器建立交互关系的最后一个状态，在这时，建立起交互关系的路由器之间已经完成了数据库同步的工作，他们的链路状态数据库已经一致，这个状态称为"全毗邻状态"，每台路由器保存着一张邻居路由器列表称为“毗邻数据库"。两个OSPF路由数据库同步时所有链路状态
路由协议的最大共性。 在OSPF路由协议中，数据库同步关系仅仅在建立交互关系的路由器之间保持。
（2.5）网络类型
根据路由器连接的物理网络不同，OSPF将网络划分为4种类型
• BMA(广播多路访问型 Broadcast MultiAccess)： 如Ethernet、Token Ring和FDDI等，需要选举DR/BDR，
• NBMA(非广播多路访问型 None Broadcast MultiAccess)： 如Frame Relay、X.25和SMDS等，多为全网状，所有接口属于同一子网，因为非共享介质，需要手动指定邻居，需要选举DR/BDR。
• P-to-P(点到点型 Point-to-Point)： 如PPP、HDLC。
• P-to-MP(点到多点型 Ponit-to-MultiPoint)： 部分网状或星型网络拓扑，所有接口属于同一子网，不需要选举DR/BDR，邻居可以动态发现。
。虚电路： 虚电路的网络类型是点到点型，

（3）其他

## (3.1）BGP

外网路由协议。每个数据中心为一个自制系统AS，AS有以下分类：
• Stub AS：对外只有一个连接。这类AS不会传输其他AS的包。例如，个人或者小公司的网络。
Multihomed AS：可能有多个连接连到其他的AS。但是大多拒绝帮其他的AS传输包。例如一些大公司的网络。
. Transit AS：有多个连接连到其他的AS。并且可以帮助其他的AS传输包。例如主干网。
**BGP分为eBGP和iBGP。自治系统间，边界路由器之间使用eBGP广播路由。边界路由器通过iBGP将学习到的路由信息导入到内部网络。BGP协议的其中一个缺点是收敛过程慢。**
路由分静态路由和动态路由，静态路由可以配置复杂的策略路由，控制转发策略。



# 链路层

适配器是一个半自治的单元。



# 生成树协议

Switch支持**STP生成树协议**，并给予**CAM表**进行数据包转发，因此可以构建出**物理有环，逻辑无环**的逻辑拓扑**避免广播风暴**。

机房会存在环路，这样能备份。机器启动之后会跑一遍STP，会标记环路，不去访问他，但如果机器存在故障就会顶替上去【路由器也有主从！】

**工作原理**
。根交换机是STP生成树中最顶层的交换机。
。指定交换机将根交换机作为顶层交换机，并且其他交换机如果通过该交换机后，其他交换机的顶层交换机也是该指定交换机的顶层交换机。
。网桥协议数据单元BPD·U是由根交换机发出去的数据包，指定交换机只能都转发该数据包。
。优先级向量是一组ID数字，[Root Bridge ID, Root Path Cost, Bridge ID, and Port ID]，依次比较，值越小优先级越高。
。STP的工作过程应该考虑根交换机相遇，同一层次的交换机相遇，不同层次的交换金相遇的情况。

# ICMP【很重要】

ICMP报文封装在IP包里边。

**ICMP的报文结构**

![image-20221127153454619](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221127153454619.png)

## ICMP的报文分类

。查询类型报文：通过ping命令发送，最常用的是主动请求为8，主动回复是0。
。差错类型报文：通过traceroute命令发送，主机不可达是3，源抑制是4，重定向是5，超时是11.
                • traceroute的工作机制：故意设置一个特殊的TTL，工作过程中不断的加1，由于只要通过一个路由器就会损失一个TTL，所以这样可以绘制出路由拓扑；**故意设置不分片**，从而确定路径的MTU，发送的数据包大小正好等于出口的MTU。
• Tracerouter发UDP，为啥出错回ICMP？正常情况下，协议栈能正常走到UDP，当然正常返回 UDP。但是，**主机不可达，是IP层的（还没到UDP）。IP层只知道回ICMP。报文分片错误也是同理。**
• 怎么知道UDP有没有到达目的主机呢？Traceroute程序会**发送一份UDP数据报**给目的主机，但它会选择**一个不可能的值作为UDP端口号**（**大于30000**）。当该数据报到达时，将使目的主机的 UDP模块产生一份 “端口不可达” 错误ICMP报文。如果数据报没有到达，则可能是超时。



# Socket套接字

。Socket可以通过进程或者线程进行维护，那么**C10K问题**就是讲的一台机器要维护1万个连接，就要创建1万个进程或者线程，那么操作系统是无法承受的。**解决这个问题可以使用IO多路复用技术。**一个线程维护多个Socket，使用**事件通知**的方式，epoll函数在内核中通过callback函数注册的方式实现通知，而不是轮询的方式。
。**epoll被称为解决C10K问题的利器。**epoll和IOCP是有本质区别的，**IOCP是封装了IO操作，而epoll只是一个事件通知机制**，这意味着IOCP的IO操作也可以由内核完成，因**此IOCP是异步IO，而基于epoll的仍然是同步IO，于IOCP相对应的不是epoll而是AIO**

。**select由文件描述fd_set限制，epoll 由文件描述符数量限制**，文件描述符可以存在很多，但是fd_set不会太大。

。由于Socket是文件描述符，因而某个线程盯的所有的Socket，都放在**一个文件描述符集合fd_set**中，这就是项目进度墙，然后调用select函数来监听文件描述符集合是否有变化。一旦有变化，就会依次查看每个文件描述符。那些发生变化的文件描述符在fd_set对应的位都设为1，表示Subkat可读或者可写，从而可以进行读写操作。然后再调用select，接着盯着下一轮的变化，

### **• epoll的两种触发模式是什么？**

epoll 的描述符事件有两种触发模式：**LT（level trigger）和 ET（edae trigger）。**
。 **LT 模式**：当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程**可以不立即处理**该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。
◇ **ET 模式**：与 LT 模式不同的是，通知之后进程**必须立即处理事件**，下次再调用 epoll_wait() 时不会再得到事件到达的通知。很大程度上减少了 epoll 事件被重复触发的次数，因此**效率要比 LT 模式高。**只支持 No-Blocking，以**避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。**

### **。 select、poll、epoll的应用场景是什么？**

。 **select 应用场景**：**select 的 timeout 参数精度为微秒，而 poll 和 epoll 为毫秒**，因此 select 更加适用于**实时性要求比较高**的场景，比如核反应堆的控制，医疗设备。select **可移植性更好**，几乎被所有主流平台所支持。
。poll 应用场景：**poll 没有最大描述符数量的限制**，如果平台支持并且**对实时性要求不高**，应该使用 poll 而不是 select
。epoll 应用场景：**只能运行在 Linux 平台上，有大量的描述符需要同时轮询**，并且这些连接**最好是长连接。**需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用epoll。因为 **epoll 中的所有描述符【内存里的数据结构】都存储在内核中**，造成每次需要对描述符的状态改变都需要**通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率**。并且 **epoll 的描述符存储在内核，不容易调试，**

Windows要求实时【select】，linux要求是并发【epoll】（轮询就是select，epoll是通知)，客户端要求睿频



### Unix的五种IO模型是什么？

。阻塞式IO

。非阻塞式IO

。信号驱动式IO

。IO多路复用

。异步AIO

## 流媒体

### （1）视频编码的三大流派

。ITU  侧重传输

。ISO   侧重存储但慢慢侧重传输

。ITU-T  国际电信联盟电信标准化部门

### （2）音视频直播

·。泛娱乐化直播：花椒、映客、斗鱼、YY。有**信令服务器集群**来负责创建房间、聊天、赠送礼物...，当直播端需要直播时直接向信令服务器发送请求，信令服务器向请求端返回推流的地址，然后**直播端开始向CDN网络推送数据流**（流媒体CDN与传统CDN有些不同），然后当观众需要观看直播时，使用同样的方式请求直播地址，然后在**流媒体客户端拉取CDN数据流**，
。 实时互动直播：思科、声网，一般情况下实时互动直播会与**PSTN网络相连**，所以实时互动直播必须达到电话级别的传输要求，一般不超过400ms。实时互动直播架构对传输效率要求高，因此客户端使用UDP协议向媒体服务器推流，由于要保证服务器7x24小时的服务，所以通过私有网络建立了
服务器集群，直播端向媒体服务器推流。由于使用了多个直播服务节点，所以需要控制中心来控制这些节点以达到负载均衡、健康评估等的目的。每个节点通过内总线向控制中心发送心跳包，控制中心通过心跳包来分析服务节点的健康状况来做出相应的决策。使用内总线的原因一是为了数据的
安全性，二是为了数据的时效性。那么有时候实时互动也需要多人观看，所以上面讲解的泛娱乐化直播架构与实时互动直播架构进行融合。在CDN流媒体网络与内总线之间有一层服务节点最重要的作用是将直播端的RTP转换为RTMP数据向CDN推流，由此得知内总线的主要作用就是提高数据吞
吐量和保证数据实时安全

![image-20221127232102176](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221127232102176.png)

**• 流媒体CDN网络与传统CDN网络的区别？**
。一般情况下，内容提供商有多个服务器来负载均衡，并且CDN提供区域的CDN边缘节点来提供服务，众多的边缘节点和源节点之间通过主干节点连接，主干节点之间一般通过光纤直接互联。
。传统CDN网络是客户端请求某一站点的数据，首先请求源站点的数据，如果源站点有数据就直接返回，如果没有就会直接通过主于节点请求源站点直接返问，并且边缘节点缓存该数据以便下一次客户端去请求加速，也就是说传统CDN网络有热点数据这一说，
。流媒体CDN网络采用的推送+拉取的数据分发策略，也就是内容提供商将数据推送到主干节点，然后边缘节点在主干节点拉取数据，用户请求边缘节点的数据拉取数据流。



## P2P 和 P2SP

### (1) 概述

• 种子（.torrent）文件的内容。

*  Tracker URL
。文件信息：INFO区、Name字段（指定顶层目录名字）、每个段的大小（把一个文件分成很多个小段，然后分段下载）和段Hash值（将整个种子中，每个段的SHA-1哈希值拼在一起）。（2）P2P下载过程
• 解析.torrent文件，获取Tracker地址，连接至Tracker。
• Tracker返回文件服务器的IP地址。
• 客户端连接文件服务器
• 根据.torrent文件，客户端与文件服务器互相告知已经有的数据块。
• 互相交换数据块就是下载的过程.
• 每下载一个块就计算校验Hash值与.torrent文件中的Hash值对比，
• 不一样则需要重新下载这个块，
（3）去中心化网络（DHT）
• 加入这个网络的每一个节点都需要承担存储任务，
• Kademlia协议

* ### （2）P2P下载过程

  • 解析.torrent文件，获取Tracker地址，连接至Tracker。
  • Tracker返回文件服务器的IP地址。
  • 客户端连接文件服务器
  • 根据.torrent文件，客户端与文件服务器互相告知已经有的数据块。
  • 互相交换数据块就是下载的过程.
  • 每下载一个块就计算校验Hash值与.torrent文件中的Hash值对比，
  • 不一样则需要重新下载这个块

  **本地有缓存下载上传就会很快了，因为本地内有镜像文件或者是种子【有数据块】**

  

  **P2SP其实就是本地没有去server那里拉取镜像**

  ### （3）去中心化网络（DHT）

  • 加入这个网络的每一个节点都需要承担存储任务，
  • Kademlia协议

* Peer角色、监听TCP端口，用来上传下载文件。

* Node角色，监听UDP端口，表明已经加入一个DHT网络，
。每一个DHT node都有一个ID。
。每个DHT Node都有责任掌握一些知识，也就是文件索引，
。当下载一个文件的时候需要先计算文件的ID，在众多DHT Node ID中找到与该ID机等或相近的Node下载
。 节点ID是一个随机选择的160bits空间，文件的哈希也使用这样的160bits空间。在Kademlia网络中，距离是通过异或计算的，
•为什么P2P下载会到Q0%就卡件？
**P2P开宗明义说的，把压力转嫁给client**，当cient流量压力过大而下线了，其他人就无法找到这个文件了，顶多DHT网络告诉每个client，漏失的文件在某个下线的人手上。你们就乖乖等他上线，并且把手上的99.99%分享给其他新来的新Node吧。为了解决这个问题，最早应该是迅雷，提供了
P2SP，长效种子，让Server也有义务承担一些压力。

## RSYNC缺点

同步大文件，只HASH数据的前后的一端进行判断，但难免会有差错！

# 数据中心

## （1）概述

•机架（Rack）：数据中心里面是服务器。服务器被放在一个个叫作机架（Rack）的架子上面
·边界路由器（Border Router）：数据中心的入口和出口也是路由器，由于在**数据中心的边界**，就像在一个国家的边境，称为边界路由器（Border Router）
• 自治区域（AS）：为了**高可用**，边界路由器会有多个。既然是**路由器，就需要跑路由协议**，数据中心往往就是路由协议中的自治区域（AS）。
•**多线BGP**：数据中心里面的机器要想访问外面的网站，数据中心里面也是有对外提供服务的机器，都可以**通过BGP协议，获取内外互通的路由信息。这就是我们常听到的多线BGP的概念。**
• TOR（Top Of Rack）交换机：交换机往往是放在**机架顶端**的，所以经常称为TOR（Top Of Rack）交换机。
• **接入层交换机**：TOR交换机所在的层经常称作接入层。
• **汇聚层交换机**：当一个机架放不下的时候，就需要多个机架，还需要有交换机将多个**机架连接在一起**。这些交换机对性能的要求更高，带宽也更大。这些交换机称为汇聚层交换机
·**网卡绑定（Bond）**： 数据中心里面的每一个连接都是需要考虑高可用的。这里首先要考虑的是，如果一台机器只有一个网卡，上面连着一个网线，接入到TOR交换机上。如果网卡坏了，或者不小心网线掉了，机器就上不去了。所以，需要至少两个网卡、两个网线插到TOR交换机上，但是**两个网卡要工作得像一张网卡一样**，这就是常说的网卡绑定（bond）。
• LACP（Link Aggregation Control Protocol）：它们互相通信，将多个网卡聚合称为一个网卡，多个网线聚合成一个网线，在**网线**之间可以进行**负载均衡**，也可以为了**高可用**作准备，这就需要服务器和交换机都支持一种协议lACP.
。主备交换机：交换机高可用最传统的方法，部署两个接入交换机、两个汇聚交换机。服务器和两个接入交换机都连接，接入交换机和两个汇聚都连接，当然这样会形成环，所以需要启用STP协议，去除环，但是这样两个汇聚就只能一主一备了。STP协议里我们学过，只有一条路会起作用。
。堆叠交换机：交换机有一种技术叫作堆叠，所以另一种方法是，将多个交换机形成一个逻辑的交换机，服务器通过多根线分配连到多个接入层交换机上，而接入层交换机多根线分别连接到多个交换机上，并且通过堆叠的私有协议，形成双活的连接方式。
• Pod、可用区：在这个集群里面，服务器之间通过二层互通，这个区域常称为一个Pod（Point Of Delivery），时候也称为一个**可用区（Available Zone）**
•集群：聚层将大量的计算节点相互连接在一起，形成一个集群，
•核心交换机：当节点数目再多的时候，一个可用区放不下，需要将多个可用区连在一起，**连接多个可用区的交换机称为核心交换机**

## （2）普通数据中心架构图

![image-20221127161753369](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221127161753369.png)



• 全互联模式：核心交换机吞吐量更大，高可用要求更高，肯定需要堆叠，但是往往仅仅堆叠，不足以满足吞吐量，因而还是需要部署多组核心交换机。**核心和汇聚交换机之间为了高可用，也是全互连模式的。**【都汇聚起来了】
• 对于全互联模式出现环路怎么办？不同的可用区都处于不同的二层网络，分配不同的网段，汇聚层交换机和核心层交换机通过三层互联。这样二层都不在一个广播域，三层出现环路通过OSPF路由协议选择最佳路径，通过ECMP等价路由协议进行负载均衡。
• **大二层**：随着数据中心里面的机器越来越多，尤其是有了云计算、大数据，集群规模非常大，而且都要求在一个二层网络里面。这就需要**二层互连从汇聚层上升为核心层，也即在核心以下，全部是二层互连，全部在一个广播域里面。**

• TRILL多链接透明互联协议：把三层的路由能力模拟在二层实现。运行TRILL协议的交换机称为RBridge，是具有路由转发特性的网桥设备，只不过这个路由是根据MAC地址来的，不是根据IP来的。Rbridage之间通过链路状态协议运作，
• TRILL多链接透明互联协议：把三层的路由能力模拟在二层实现。运行TRILL协议的交换机称为RBridge，是具有路由转发特性的网桥设备，只不过这个路由是根据MAC地址来的，不是根据IP来的。Rbridage之间通过链路状态协议运作。
• Egress RBridge和Ingress RBridge封装在TRILL Header中：



## （3）典型的三层网络结构

对于大二层的广播包，也需要通过分发树的技术来实现。我们知道STP是将一个有环的图，通过去掉边形成一棵树，而分发树是一个有环的图形成多棵树，不同的树有不同的VLAN，有的广播包从VLAN A广播。有的从VLAN B广播，实现负载均衡和高可用。在核心交换上面，往往会挂一些安全设备，例如入侵检测、DDoS防护等等。这是整个数据中心的屏障，防止来自外来的攻击。 

![image-20221127165924695](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221127165924695.png)

（4）叶脊网络

扁平的结构，应对数据中心的东西流量。

![image-20221127170443447](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221127170443447.png)

• 叶子交换机：直接连接物理服务器。L2/L3网络的分界点在叶子交换机上，叶子交换机之上是三层网络。
• 脊交换机：相当于核心交换机。叶脊之间通过ECMP动态选择多条路径。脊交换机现在只是为叶子交换机提供一个弹性的L3路由网络。南北流量可以不用直接从脊交换机发出，而是通过与leaf交换机并行的交换机，再接到边界路由器出去。
• 运维人员通过VPN连入机房网络，再通过堡垒机访问服务器或网络设备。当服务器系统不能启动时，远程访问需要用IPKVM（KVM over IP）。扁平的网络结构少了汇聚层，基本没有性能瓶颈。

在家办公：申请VPN权限，连接到VPN，再连接到公司的跳板机，再申请操作权限。

# 防火墙

表格类型：raw->mangle->nat >filter，优先级依次降低
**filter表处理过滤功能**
。**INPUT链**：过滤所有目标地址是本机的数据包
。**FORWARD链**：过滤所有路过本机的数据包
。**OUTPUT链**：过滤所有由本机产生的数据包
. **nat表**主要是处理**网络地址转换**，可以进行**Snat**（改变数据包的源地址）、**Dnat**（改变数据包的目标地址）
。**PREROUTING链**：可以在数据包到达防火墙时改变目标地址
。**OUTPUT链**：可以改变本地产生的数据包的目标地址
。**POSTROUTING链**：在数据包离开防火墙时改变数据包的源地址
**mangle表主要是修改数据包**
。PREROUTING链
。 INPUT链
。FORWARD链
。OUTPUT链
。 POSTROUTING链
•在云平台上，一般允许一个或者多个虚拟机属于某个**安全组**，而属于不同安全组的虚拟机之间的访问以及外网访问虚拟机，都需要通过安全组进行过滤。

**安全组其实就是通过iptable实现的** 

• **控制网络的QoS有哪些方式？** 在Linux下，可以通过TC控制网络的**QoS**，主要就是通过队列的方式，
。无类别排队规则
       • pfifo_fast：分为三个先入先出的队列，称为三个Band。其中Band 0优先级最高，发送完毕后才轮到Band 1发送，最后才是Band 2
       • 随机公平队列：会建立很多的FIFO的队列，TCP Session会计算hash值，通过hash值分配到某个队列。在队列的另一端，网络包会通过轮询策略从各个队列中取出发送。这样不会有一个Session占据所有的流量。当然如果两个Session的hash是一样的，会共享一个队列，也有可能
互相影响。hash函数会经常改变，从而session不会总是相互影响，
        •**令牌桶规则**_（TBF，Token Bucket Filte）：所有的网络包排成队列进行发送，但不是到了队头就能发送，而是需要拿到令牌才能发送。**令牌根据设定的速度生成**，所以即便队列很长，也是按照一定的速度进行发送的。当没有包在队列中的时候，令牌还是以既定的速度生成，但是不是无限累积的，而是放满了桶为止。设置桶的大小为了避免下面的情况：**当长时间没有网络包发送的时候，积累了大量的令牌，突然来了大量的网络包，每个都能得到令牌，造成瞬间流量大增。**
。有类别排队规则
        • **分层令牌桶规则**（HTB， Hierarchical Token Bucket）：HTB往往是一棵树，使用TC可以为某个网卡eth0创建一个HTB的队列规则。**解决了令牌桶的问题**

QoS是什么？

QoS（Quality of Service）是服务质量的简称。从传统意义上来讲，无非就是传输的带宽、传送的时延、数据的丢包率等，而提高服务质量无非也就是保证传输的带宽，降低传送的时延，降低数据的丢包率以及时延抖动等。

iptable的缺点：

链表，需要遍历，性能很低。

ipvs

# GRE 和 VXLAN

• **GRE隧道网络是一种IP over IP的隧道技术**，将IP数据包封装到GRE数据包中，外边加上IP头。Tunnel是一个虚拟的点对点连接。GRE很好的解决了VLAN ID数量不足的问题**（VLAN只有12位，共4096个**，主要是因为二层数据帧结构的原因，根据IEEE802.1q协议定义vlan在数据帧中是通过VID字段信息来标识，**VID是一个12位的二进制字段信**息，也就是最多可以标识2的12次方（4096）个vlan）。由于**Tunnel是点对点的，所以Tunnel的数量会指数型增**长。其次**GRE不支持组播**。还有就是**很多防火墙和三层网络设备不支持解析GRE数据。**

。VXLAN只是在二层协议外边制装了一个**VXLAN头**，**VXLAN是24位的**。VXLAN作为VLAN的扩展性协议，实现解析VXLAN功能的点称作VTEP（VXLAN Tunnel EndPoint）。**VXLAN不是点对点的，支持组播**的方式定位机器。当一个VTEP启动的时候需要使用IGMP协议加入一个组播组，每当一个虚拟机启动的时候，VTEP就会知道。OpenvSwitch支持三类隧道：GRE、VXLAN、IPsec_GRE。**在使用OpenvSwitch的时候，虚拟交换机就相当于GRE和VXLAN封装的端点。**

# 容器网络基础

## (1)   Network Namespace

Linux的namespace给里面的进程造成了两个错觉：**（1）它是系统里唯一的进程。（2）它独享系统的所有资源。**
默认情况下，Linux进程处在和宿主机相同的namespace，即初始的**根namespace**里，默认享有**全局系统资源。**和其他namespace一样，network namespace可以通过系统调用来创建，我们可以调用Linux的**clone(）**（其实是**UNIX系统调用fork()的延伸**）API创建一个通用的namespace，然后传入CLONE_NEWNET参数表面创建一个networknamespace。

**创建namespace的本质就是创建一个目录**

networknamespace的增删改查功能已经集成到**Linux的ip工具的netns子命令中**，因此大大降低了初学者的体验门槛。

当ip命令创建了一个network namespace时，系统会在**/var/run/netns路径下面生成一个挂载点。**挂载点的作用一方面是**方便对namespace的管理**，另一方面是**使namespace即使没有进程运行也能继续存在**。一个network namespace被创建出来后，可以使用ip netns exec命令进入，做一些网络查询/配置的工作。

一个全新的network namespace会附带创建一个本地回环地址。除此之外，没有任何其他的网络设备。network namespace自带的lo设备状态还是DOWN的。

如果我们想**与外界（比如主机上的网卡）进行通信**，就需要在namespace里再创建一对虚拟的以太网卡，即所谓的**veth pair**【虚拟网卡对】。顾名思义，**veth pair总是成对出现且相互连接**，它就像Linux的双向管道（pipe），报文从veth pair一端进去就会由另一端收到。
**不同network namespace之间的路由表和防火墙规则等也是隔离的**，因此我们刚刚创建的netns1 network namespace没法和主机共享路由表和防火墙。
用户可以随意将虚拟网络设备分配到自定义的network namespace里，而连接**真实硬件的物理设备则只能放在系统的根network namesapce中。**并且，任何一个网络设备最多只能存在于一个networknamespace中。
有两种途径索引network namespace：**名字（例如netns1）或者属于该namespace的进程PID。**

对namespace的root用户而言，他们都可以把其namespace里的虚拟网络设备移动到其他network namespace，甚至包括主机根network namespace！这就带来了潜在的安全风险。如果用户希望屏蔽这一行为，则需要**结合PID namespace和Mount namespace的隔真特性做到network namespace**
**之间的完全不可达。**如上面的情况一样，挂载能方便管理，还能使ns在没有进程运行的时候也能继续存在。
Linux的特权是将root的权限划分为各个小部分，使得一个进程只需要被授予刚刚好的权限来执行特定的任务。

在Linux内核3.8版本以前，/proc/PID/ns目录下的文件都是硬链接（hard link），而且只有ipc、net和uts这三个文件。从Linux内核3.8版本开始，每个文件都是一个特殊的符号链接文件。符号链接的其中一个用途是确定某两个进程是否属于同一个namespace**。如果两个进程在同一个namespace中，那么这两个进程/proc/PID/ns目景下对应符号链接文件的inode数字会是一样的。**
除此之外，**/proc/PID/ns目录下的文件还有一个作用**——当我们打开这些文件时，只要文件描述符保持open状态，对应的namespace就会一直存在，哪怕这个namespace里的所有进程都终止运行了。

execve()系列函数可以用来执行用户自定义的命令，一个常用的方法是调用/bin/sh运行一个shell。unshare()提供的功能其实很像clone()，区别在于unshare()作用在一个已存在的进程上，而clone()会创建一个新的进程。

## （2）虚拟网卡对

非常像Linux的**双向管道。**根据这一特性，veth pair常被用于跨network namespace之间的通信，即分别将veth pair的两端放在不同的namespace里。**经典容器组网模型就是veth pair+bridge的模式，**

**bridge就是docker0，一个网卡插容器上，一个网卡插docker0上，docker0绑定在宿主机的网卡上**



**如何获取虚拟网卡对与容器eth0的对应关系？**

首先，在目标容器里查看：**cat  /sys/class/net/ethθ/1flink。**

然后，在主机上**遍历/sys/claas/net**下面的全部目录，查看子目录ifindex的值和容器里查出来的iflink值相当的veth名字，这样就找到了容器和主机的vethpair关系。另一种方法是在
目标容器里执行ip  link  show  ethe命令。可以通过ethtool-S命令列出veth pair对端的网卡index，

## （3）Linux Bridge

Linux bridge【虚拟二层设备（低端交换机）】**不能跨机连接网络设备**。Linux bridge则有多个端口，数据可以从任何端口进来，进来之后从哪个口出去取决于目的MAC地址，原理和**物理交换机**差不多。
iproute2软件包里的ip命令可以创建bridge，然后通过brctI工具管理Bridge。
**虚拟机通过tun/tap或者其他类似的虚拟网络设备，将虚拟机内的网卡同br0连接起来，这样就达到和真实交换机一样的效果**，虚拟机发出去的数据包先到达br0，然后由br0交给eth0发送出去，**数据包都不需要经过host机器的协议栈。**
在虚拟机场景下，我们给主机物理网卡eth0分配了IP地址；而**在容器场景下，一般不会对宿主机eth0进行配置。**在虚拟机场景下，虚拟器一般会和主机在同一个网段；而**在容器场景下，容器和物理网络不在同一个网段内。**

使用了namespace隔离了所以不在一个网段。

## （4）TUN/TAP设备

从Linux文件系统的角度看，它是用户可以用**文件句柄操作的字符设备**（鼠标）；从网络虚拟化角度看，它是虚拟网卡，一端连着网络协议栈，另一端连着用户态程序。
**tun表示虚拟的是点对点设备，tap表示虚拟的是以太网设备，这两种设备针对网络包实施不同的封装。**tun/tap设备可以将TCP/IP协议栈处理好的网络包发送给任何一个使用tun/tap驱动的进程，由进程重新处理后发到物理链路中。tun/tap设备就像是埋在用户程序空间的一个钩子，我们可以很方便地将对网络包的处理程序挂在这个钩子上，**OpenVPN**、Vtun、flannel都是基于它实现隧道包封装的。**flannel的UDP模式的技术要点就是tun/tap设备，**
**所有对这个tap/tun文件的写操作会通过tun设备转换成一个数据包传送给内核网络协议栈。**
tap设备与tun设备的工作**原理完全相同**，区别在于：
• **tun设备的/dev/tunX文件收发的是IP包**，因此只能工作在**L3**，**无法与物理网卡做桥接，但可以通过三层交换（例如ip_forward）与物理网卡连通。**
**• tap设备（网卡）的/dev/tapX文件收发的是链路层数据包，可以与物理网卡做桥接。**

**docker0是个网桥**

**TUN是什么？它的另一端是什么？**
TUN是Linux内核的一种虚拟三层网络设备，纯软件实现，通过此设备可以处理来自网络层的数据。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9Gdzk1WmpjU0tlNmdSNnBLOEF6RklYNmppYjd2SmxPNTNuVjVPMTN0S2pNUjNhUks0dFNvSVVOQlFpYTVsM2NmVVJ5ZDBzanJtclZpYktxQmV0WUNOdmlhVGcvNjQwP3d4X2ZtdD1wbmcmdHA9d2VicCZ3eGZyb209NSZ3eF9sYXp5PTEmd3hfY289MQ?x-oss-process=image/format,png)

从上图可以看出TUN设备和物理设备eth0之间的差别，它们的一端虽然都连着协议栈，但另一端却不一样，eth0连接的是物理网络，而TUN设备的另一端是一个用户态程序，协议栈发给TUN设备的数据包能被这个应用程序读取到，并且应用程序能直接向TUN设备写数据。


## （5）Iptables

**iptables的底层实现是netfilter**。netfilter是**Linux内核2.4版引入的一个子系统**，最初由Linux内核防火墙和网络的维护者Rusty Russell提出。它作为一个**通用的、抽象的框架，提供一整套hook函数的管理机制。**netfilter的架构就是在整个网络流程的若干位置放置一些钩子，并在每个钩子上挂载一些处
理函数进行处理。netfilter是Linux内核网络模块的一个经典框架，毫不夸张地说，整个Linux系统的网络安全大厦都构建在netfilter之上，
IP层的5个钩子点的位置，对应**iptables就是5条内置链，**分别是**PREROUTING、POSTROUTING、INPUT、OUTPUT和FORWARD。**除了系统预定义的5条iptables链，用户还可以在表中定义自己的链。
iptables的5张表：
• filter表：用于控制到达某条链上的数据包是继续放行、直接丢弃（drop）或拒绝（reject）；
• nat表：用于修改数据包的源和目的地址；
• mangle表：用于修改数据包的IP头信息；
• raw表：iptables是有状态的，即iptables对数据包有连接追踪（connectiontracking）机制，而raw是用来去除这种追踪机制的；

* security表：最不常用的表（通常，我们说iptables只有4张表，security表是新加入的特性），用于在数据包上应用SELinux，
  
  这5张表的优先级从高到低是：raw、mangle、nat、filter、security。 需要注意的是，iptables不支持用户自定义表。iptables的表是来分类管理iptables规则（rule）的，系统所有的iptables规则都被划分到不同的表集合中。一条iptables规则包含两部分信息：匹配条件和动作。
  如果要匹配网卡，可以用-i eth0指定收到包的网卡（i是input的缩写）。需要注意的是，DNAT只发生在nat表的PREROUTING链，这也是我们要指定收到包的网卡而不是发出包的网卡的原因。SNAT策略只能发生在nat表的POSTROUTING链。至于网络地址伪装，其实就是一种特殊的源地址转换，报
  文从哪个网卡出就用该网卡上的IP地址替换该报文的源地址，具体用哪个IP地址由内核决定。

## （6)IPIP

  tun经常被用来做隧道通信（tunnel）。命令ip tunnel可以实现ipip的管理。Linux原生支持下列5种L3隧道
  • ipip：即IPv4 in IPv4，在IPv4报文的基础上封装一个IPv4报文：
  • GRE：即通用路由封装（Generic Routing Encapsulation），定义了在任意一种网络层协议上封装其他任意一种网络层协议的机制，适用于IPv4和IPv6；
  • sit：和ipip类似，不同的是sit用IPv4报文封装IPv6报文，即IPv6 over IPv4|\
  • ISATAP：即站内自动隧道寻址协议（Intra-Site Automatic Tunnel AddressingProtocol），与sit类似，也用于IPv6的隧道封装；
  • VTI：即虚拟隧道接口（Virtual Tunnel Interface），是思科提出的一种IPSec隧道技术。下面我们以ipip为例，介绍Linux隧道通信的基本原理。
  通过Ismodigrep ipip查看内核是否加载，若没有则用modprobe ipip加载。



## （7）VXLAN

**通过三层的网络搭建虚拟的二层网络。**VXLAN是在底层物理网络（underlay）之上使用隧道技术，依托UDP层构建的overlay的逻辑网络，使逻辑网络与物理网络解耦，实现灵活的组网需求。它不仅能适配虚拟机环境，还能用于容器环境。由此可见，**VXLAN这类隧道网络的一个特点是对原有的网络架构影响小，不需要对原网络做任何改动，就可在原网络的基础上架设一层新的网络。**

VXLAN是一个一对多的网络，并不仅是一对一的**隧道协议。**一个VXLAN设备能通过像网桥一样的**学习**方式学习到其他对端的IP地址，也可以直接配置静态转发表。

在VXLAN网络的**每个端点都有一个VTEP设备，负责VXLAN协议报文的封包和解包，**也就是在虚拟报文上封装**VTEP通信的报文头部**。物理网络上可以创建多个VXLAN网络，可以将这些VXLAN网络看作一个隧道，不同节点上的虚拟机/容器能够通过隧道直连。通**过VNI标识不同的VXLAN网络，使得不同的VXLAN可以相互隔离。**

* VTEP（VXLAN Tunnel Endpoints）：VXLAN网络的边缘设备，用来进行VXLAN报文的处理（封包和解包）。VTEP可以是网络设备（例如交换机），也可以是一台机器（例如虚拟化集群中的宿主机）；

* VNI（VXLAN Network Identifier）：**VNI是每个VXLAN的标识，是个24位整数**，因此最大值是2^24=16777216。如果一个VNI对应一个租户，那么理论上VXLAN可以支撑千万级别的租户。
  
  ![image-20221204121437689](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221204121437689.png)
  
  其实就是路由器作为一个中转记录MAC地址
  
  **VXLAN的报文就是MAC in UDP，即在三层网络的基础上构建一个虚拟的二层网络**。VXLAN报文比原始报文多出了50个字节，包括8个字节的VXLAN协议相关的部分，8个字节的UDP头部，20个字节的IP头部和14个字节的MAC头部。这降低了网络链路传输有效数据的比例，特别是对小包。**4789作为VXLAN的目的UDP端口。**
  多播组主要通过**ARP泛洪【广播收敛】**来**学习MAC地址**，即在VXLAN子网内广播ARP请求，然后对应节点进行响应。但多操不是VXLAN所必需的。

## （8）MACVLAN

  在Macvian出现之前，我们可以通过网卡别名（例如eth0:1）的方式为**一块以太网卡添加多个IP地址，却不能为其添加多个MAC地址。**原因是以太网卡是以MAC地址为唯一识别的，而网卡别名并没有改变这些网卡的MAC地址。
  Macvian接口可以看作是物理以太网接口的虚拟子接口。**Macvian允许用户在主机的一个网络接口上配置多个虚拟的网络接口【设置多个MAC】，每个Macvian接口都有自己的区别于父接口的MAC地址，并且可以像普通网络接口一样分配IP地址。**因此，使用Macvian技术带来的效果是一块物理网卡上可以绑定多个IP地址，每个IP地址都有自己的MAC地址。

**keepalive使用的就是MACVLAN**

 。 **用Macvlan虚拟出来的虚拟网卡，在逻辑上和物理网卡是对等的，**应用程序可以像使用物理网卡的IP地址那样使用Macvlan设备的IP地址。**Macvlan的主要用途是网络虚拟化（**包括容器和虚拟机）。

  。**keepalived使用虚拟MAC地址。**需要注意的是，使用Macvlan的虚拟机或者容器网络与主机在同一个网段，即同一个广播域中。**Macvlan支持5种模式，分别是bridge、VEPA、Private、Passthru和Source模式，**

  。**在bridge模式下，拥有相同父接口的两块Macvian虚拟网卡可以直接通信**，不需要把流量通过父接口发送到外部网络，广播帧将会被洪泛到连接在“网桥”上的所有其他子接口和物理接口。网桥带双引号是因为实际上并没有网桥实体的产生，而是指在这些网卡之间数据流可以实现直接转发，这有点类似于Linux网桥**。但Macvlan的bridge模式和Linux网桥不是一回事，它不需要学习MAC地址，也不需要生成树协议（STP），因此性能要优于Linux网桥。**

  。**bridge模式的缺点是如果父接口故障，所有Macvian子接口会跟着故障，子接口之间也将无法进行通信**。

 。VEPA（Virtual Ethernet Port Aggregator，虚拟以太网端口聚合）是**默认模式**。所有从Macvlan接口发出的流量，不管目的地址是什么，全部"一股脑”地**发送给父接口。**在二层网络下，**由于生成树协议的原因，两个Macvlan接口之间的通信会被阻塞，这时就需要接入的外部交换机支持**hairpin（**把自己的数据包发给自己**），把源和目的地址都是本地Macvlan接口地址的流量，发给相应的接口。**在VEPA模式下，从父接口收到的广播包会洪泛给所有的子接口。** 目前，大多数交换机都不支持hairpin模式，但Linux可以通过一种hairpin模式的网桥，让VEPA模式下的Macvian接口能够直接通信（前文已经提到，**我们可以把Linux网桥看作二层交换机**）。

**。Private模式类似于VEPA模式，但又增强了VEPA模式的隔离能力**，其完全阻止共享同一父接口的Macvlan虚拟网卡之间的通信。即使配置了hairpin，让从父接口发出的流量返回宿主机，相应的通信流量依然被丢弃。**Private的具体实现方式是丢弃广播/多播数据**，这就意味着以太网地址解析ARP将
无法工作。除非手工探测MAC地址，否则通信将无法在同一宿主机下的多个Macvlan网卡间进行。
。 **Passthru模式翻译过来就是直通模式。在这种模式下，每个父接口只能和一个Macvian网卡捆绑**，并且**Macvian网卡继承父接口的MAC地址**。在VEPA和Passthru模式下，两个Macvlan网卡之间的通信会经过父接口两次——第一次是发出的时候，第二次是返回的时候。 除了**限制了Macvian接口**
**之间的通信性能，还影响物理接口的宽带。**

。在**Source**这种模式下，寄生在物理设备上，**Macvlan设备只播收指定的源Mac地址的数据包，其他数据包一概丢弃。**
**一般情况下，Macvlan设备的MAC地址是Linux系统自动分配的，用户也可以自定义。在Macvlan虚拟网络世界中，物理网卡（父接口）相当于一个交换机，对于进出其于Macvlan网卡的数据包，物理网卡只转发数据包而不处理数据包，于是也就造成了使用本机Macvlan网卡的IP无法和物理网卡的IP通信**

。**overlay是全局作用范围类型的网络，而Macvlan的作用范围只是本地。全局类型的网络可以作用于一个Docker集群，而本地类型的网络只作用于一个Docker节点。** 每个宿主机创建的**Macvlan网络都是独立的，**一台机器上创建的Macvlan网络并**不影响**另一台机器上的网络。但这并**不意味着两台Macvlan的主机不能通信【只是不能跟本机物理网卡连】**，当同时**满足以下两个条件时，可以实现Macvlan网络的跨主机通信**
。通信两端的主机在网卡配置**混杂模式**
。**两台主机上的Macvlan子网IP段没有重叠**

## 混杂模式基本概念

一般情况下，网卡往往只会接收目的地址是它的数据包而不会接收目的地址不是它的数据包。

**混杂模式就是接收所有经过网卡的数据包，包括不是发给本机的包。**默认情况下，网卡只把发给本机的包（包括广播包）传递给上层程序，其他的包一律丢弃。

混杂模式就是指网卡能**接受所有通过它的数据流**，无论是什么模式、什么地址的。当网卡处于这种“混杂”模式时，它对所有遇到的每一个数据帧都产生一个硬件中断，以提醒操作系统处理流经该物理媒体上的每一个报文包。

## 网卡工作模式

广播模式：物理地址（MAC）是0Xffffff的帧为广播帧，工作在广播模式的网卡接收广播帧。
多播模式：如果将网卡设置为多播模式，它可以接收所有的多播传送帧，而不论他是不是组内成员。
直接模式：只接收目的地址是自己MAC地址的帧。
混杂模式：工作在混杂模式下的网卡接收所有流经网卡的帧。
网卡默认工作模式包括广播模式和直接模式，即它只接收广播帧和发给自己的帧。如果采用**混杂模式**，一个站点的网卡将接收同一网络内所有站点所发送的数据包，这样就可以达到对**网络信息监视捕获**的目的。

## （9）IPVLAN

**IPvlan所有的虚拟接口都有相同的MAC地址，而IP地址却各不相同。**因为所有的IPvlan虚拟接口共享MAC地址，所以**特别需要注意DHCP使用的场景。**DHCP分配IP地址的时候一般会用MAC地址作为机器的标识。因此，**在使用Macvlan的情况下，客户端动态获取IP的时候需要配置唯一的Client ID**，并
且DHCP服务器也要使用该字段作为机器标识，而不是使用MAC地址。

Linux内核3.19版本才开始支持IPvlan，Docker从4.2版本起能够稳定支持IPvlan。IPvlan有两种不同的模式，分别是**L2和L3**。一个父接口只能选择其中一种模式，依附于它的所有子虚拟接口都运行在该模式下。
• IPvlan L2模式和Macvlan bridge模式的工作原理很相似，**父接口作为交换机转发子接口的数据。**同一个网络的子接口可以通过父接口转发数据，如果想发送到其他网络，则报文会通过父接口的路由转发出去。
• L3模式下，IPvlan有点像路由器的功能**。只要父接口相同，即使虚拟机/容器不在同一个网络，也可以互相ping通对方，因为IPvlan会在中间做报文的转发工作。**
**L3模式下的虚拟接口不会接收多播或者广播的报文**，**原因是所有的网络都会发送给父接口，所有的ARP过程或者其他多播报文都是在底层的父接口完成的。**需要注意的是，外部网络默认情况下是不知道IPvian虚拟出来的网络的，如果不在外部路由器上配置好对应的路由规则，那么IPvlan的网络
是不能被外部直接访问的。

## （10）CNM

容器的网络方案可以分为三大部分：**单机的容器间通信；跨主机的容器间通信；容器与主机间通信，**
**围绕Docker生态，目前有两种主流的网络接口方案**，即Docker主导的**ContainerNetwork Model**（CNM）和Kubernetes社区主推的**Container NetworkInterface**（CNI），其中CNM相对CNI较早提出。

### **Docker的网络类型**

* **bridge：网桥网络**
  当Docker进程启动时，会在主机上创建一个名为**docker0的虚拟网桥**，此主机上启动的Docker容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样**主机上的所有容器就通过交换机连在了一个二层网络中。**
  • **host：主机网络**
  如果启动容器的时候使用host模式，那么这个**容器将不会获得一个独立的Network Namespace，而是和宿主机共用一个Network Namespace。**容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。但是，容器的其他方面，如文件系统、进程列表等还是和宿主机隔离
  的。

* **none：禁用容器网络，自定义网络**

* **container：容器网络**，**Kubernetes的Pod网络采用的就是Docker的container模式网络。**
  这个模式指定**新创建的容器和已经存在的一个容器共享一个 Network Namespace**，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的

  。Docker在1.9版本中（现在都1.17了）引入了一整套docker network子命令和跨主机网络支持。这允许用户可以根据他们应用的拓扑结构创建虚拟网络并将容器接入其所对应的网络。
  。其实，早在Docker1.7版本中，网络部分代码就已经被抽离并单独成为了**Docker的网络库，即libnetwork。**在此之后，容器的网络模式也被抽像变成了统一接口的驱动。
  。为了标准化网络的驱动开发步骤和支持多种网络驱动，**Docker公司在libnetwork中使用了CNM**（Container Network Model）。CNM定义了构建容器虚拟化网络的模型。同时还提供了可以用于开发多种网络驱动的标准化接口和组件。

  。libnetwork和Docker daemon及各个网络驱动的关系可以通过下面的图进行形象的表示。Docker daemon通过调用libnetwork对外提供的API完成网络的创建和管理等功能。**libnetwrok中则使用了CNM来完成网络功能的提供。而CNM中主要有 沙盒（sandbox）、端点（endpoint）、网络**
  **（netwark） 这3种组件**。libnetwork中内置的5种驱动则为libnetwork提供了不同类型的网络服务。
  1、**沙盒（sandbox）**     一个沙盒也包含了一个容器网络栈的信息。沙盒可以对容器的接口、路由和DNS设置等进行管理。沙盒的实现可以是Linux netwrok namespace、**FreeBSD jail**或者类似的机制。**一个沙盒可以有多个端点和多个网络。**
  2、**端点（endpoint）**    **一个端点可以加入一个沙盒和一个网络。**端点的实现可以是veth pair、Open vSwitch内部端口或者相似的设备。**一个端点只可以属于一个网络并且只属于一个沙盒，**
  3、**网络（network）**   一个网络是一组可以直接互相联通的端点。网络的实现可以是Linux bridge、VLAN等。**一个网络可以包含多个端点**

### **Libnetwork提供的驱动类型**

1、**bridge驱动** 此驱动为Docker的默认设置驱动，使用这个驱动的时候，libnetwork将创建出来的**Docker容器连接到Docker网桥上。作为最常规的模式**，bridge模式已经可以满足Docker容器最基本的使用需求了。然而其与外界通信使用NAT，增加了通信的复杂性，在复杂场景下使用会有诸多限制。
2、**host驱动** 使用这种驱动的时候，libnetwork将不为Docker容器创建网络协议栈，即不会创建独立的network namespace。Docker容器中的进程处于宿主机的网络环境中，**相当于Docker容器和宿主机共同用一个network namespace**，使用宿主机的网卡、IP和端口等信息。
但是，容器其他方面，如文件系统、进程列表等还是和宿主机隔离的。host模式很好地解决了容器与外界通信的地址转换问题，可以直接使用宿主机的IP进行通信，不存在虚拟化网络带来的额外性能负担。但是host驱动也降低了容器与容器之间、容器与宿主机之间网络层面的隔离性，引起网络资源的竞争与冲突，因此可以认为host驱动适合用于对容器集群不大的场景
3、**overlay驱动** 此驱动采用IETE标准的**VXLAN**方式，并且是VXLAN中被普遍认为最适合大规模的云计算虚拟化环境的SDN controller模式。在使用过程中，需要一个额外的配置存储服务，例如Consul、etcd和zookeeper。还需要在启动Docker daemon的时候额外添加参数来指定所使用的配置存储服务地址。
4、**remote驱动** 这个驱动实际上并未做真正的网络服务实现，而是调用了用户自行实现的网络驱动插件，使**libnetwork实现了驱动的可插件化**，更好地满足了用户的多种需求。用户只需要根据libnetwork提供的协议标准，实现其所要求的各个接口并向Docker daemon进行注册。
Remote Driver提供了自定义网络的可能。远程驱动作为服务端，Libnetwork作为客户端，两者通过一系列带JSON格式的HTTP POST请求进行交互。
5、**null驱动** 使用这种驱动的时候，Docker容器拥有自己的network namespace，但是并**不为Docker容器进行任何网络配置**。也就是说，这个Docker容器除了network namespace自带的loopback网卡名，没有其他任何网卡、IP、路由等信息，需要用户为Docker容器添加网卡、配置IP等。 这种模式如果不进行特定的配置是无法正常使用的，但是优点也非常明显，**它给了用户最大的自由度来自定义容器的网络环境。**

### **容器网络与虚拟机网络的对比**

。 虚拟机拥有较强的**隔离机制**
• 出于**安全**考虑，很多情况下容器会被部署在虚拟机内部，这种嵌套部署对应一个新的组网模型
• **原生Docker容器不解决跨主机通信问题**，而大规模的容器部署势必涉及不同主机上的网络通信？
• 容器相较虚拟机**生命周期更短**，重启更加频繁，重启后IP地址将发生变化，需要进行高效的网络地址管理，因此静态的IP地址分配或DHCP（耗费数秒才能生效）将不起作用
• 容器相较虚拟机发生**迁移的频率更高**，且原生的Docker容器不支持热迁移，迁移后的容器面临IP地址漂移，而且经常出现不在同一网段的情况，对应的网络策略的刷新要及时跟上
• 大规模跨机部署带来多主机间的**ARP洪泛**，造成大量的资源浪费
· 大部分的容器网络方案都会使用iptables和NAT，NAT的存在会造成通信两端看不到彼此的真实IP地址，并且**iptable和NAT的结合使用限制了可扩展性和性能。**
      。 避免NAT的基本思想是将容器和虚拟机、主机同等对待。
      。另一种方法是将主机变成全面的路由器，甚至是使用BGP的路由器。主机会将前缀路由到主机中的容器，每个容器会使用全球唯一的IP地址。尽管在IPv4地址空间已经耗尽的今天，给每个容器提供一个完全可路由的IPv4地址有些不太实际，但IPv6将使这种主机作为路由器的容器组网技术
变得可能，事实上很多公有云都已经支持IPv6。
。 **大规模部署使用veth设备会影响网络性能，最严重时甚至会比裸机降低50%**
。 **过多的MAC地址**。当MAC地址超过限制时，主机中的物理网络接口卡虽然可以切换到**混杂模式，但会导致性能下降**，而且**顶级机架（ToR）交换机可支持的MAC地址数量也有上限**

。**可以使用Macvian和IPvian替代veth，降低veth网络的性能开销。当**使用IPvlan驱动时，IPvlan工作在L3，而L3网络不会收到洪泛影响，因此只有主机的物理网卡MAC地址可见，容器MAC地址不会暴露在网络中，从而解决数据中心可见MAC地址过多给ToR交换机带来的影响。

**一些专业的容器网络插件，例如flannel、Weave、Calico**等也开始与各个容器编排平台进行集成，OpenStack社区也成立了专门的子项目Kuryr提供Neutron与容器的对接。

## (11) CNI

**CNI的优势是兼容其他容器技术（例如rkt）及上层编排系统，**

**集群内访问Pod，会经过Service【4层网络负载均衡】；集群外访问Pod，经过的是Ingress【7层网络负载均衡】。**Service和Ingress是Kubernetes专门为服务发现而抽象出来的相关概念，后面会做详细讨论。

Service能发现TCP、UDP,Ingress能发现HTTP，HTTPS。

实现CNI只要实现Add/Del两个接口即可。CNI的ADD/DELETE接口其实只是实现了**docker network connect和docker network disconnect两个命令。**
**CNI中的container应与CNM中的sandbox概念一致**，CNI中的network与CNM中的network一致。在CNI中，CNM中的Endpoint被隐含在了ADD/DELETE的操作中。

k8s是支持多容器的环境，docker只是容器。

Docker网络驱动的设计不具备良好的开放性和可扩展性。例如，Docker网络驱动使用了Docker内部分配的一个ID，而不是一个通用的网络名字来指向一个容器所属的网络。这样的设计导致一个被定义在外部系统中（例如Kubernetes）的网络很难被Docker的网络驱动理解和识别。**Kubernetes是一个支持多容器的运行环境，而Docker只是其中一个容器而已。Kubernetes永远不会使用Docker的Libnetwork，Docker的网络模型在设计上还做了很多和Kubernetes不兼容的假设。**



## （12）K8S中的pause容器

**pause是C写的。**

**Pod抽象基于Linux的namespace和cgroups**，为容器提供了隔离的环境。从网络的角度看，同一个Pod中的不同容器犹如运行在同一个主机上，可以通过localhost进行通信。

。Docker容器非常适合部署单个软件单元。但是当你想要一起运行多个软件时，尤其是在一个容器里管理多个进程时，这种模式会变得有点麻烦。Kubernetes非常不建议"富容器”这种方式，认为将这些应用程序部署在部分隔离并且部分共享资源的容器组中更为有用。为此，Kubernetes为这种使用场景提供了一个称为Pod的抽象。

Kubernetes中，**pause容器被当作Pod中所有容器的"父容器"**，并为每个业务容器提供以下功能：
• 在Pod中，它作为**共享Linux namespace（Network、UTS等）的基础；**
• 启用PID namespace共享，它为每个Pod提供**1号进程，并收集Pod内的僵尸进程。**

这个pause容器运行一个非常简单的进程，它不执行任何功能，一启动就永远把自己阻塞住了（见pause()系统调用）。正如你看到的，**它当然不会只知道"睡觉"。它执行另一个重要的功能——即它扮演PID 1的角色，并在子进程成为"孤儿进程"的时候，通过调用wait()收割这些僵尸子进程**。这样就不用担心我们的Pod的PID namespace里会堆满僵尸进程了。

在有些场景下，用户希望Pod内容器能够与其他容器隔离PIDnamespace
• PID namespace共享时，由于**pause容器成了PID=1**，其他用户容器就没有PID 1了。但像**systemd这代镜像要求获得PID 1，否则无法正常启动。**有些容器通过kill-HUP 1命令重启进程，然而在由pause容器托管init进程的Pod里，上面这条命令只会给pause容器发信号，
• PID namespace共享Pod内不同容器的进程对其他容器是可见的。这包括/proc中可见的所有信息，例如，作为参数或环境变量传递的密码，这将带来一定的安全风险。

## （13）K8S的DNS演进

**Kube-dns**架构历经两个较大的变化。**Kubernetes 1.3之前使用etcd+kube2sky+SkyDNS**的架构，**Kubernetes 1.3之后使用kubedns+dnsmasq+exechealthz的架构**，这两种架构都利用了**SkyDNS**的能力。SkyDNS支持正向查找（A记录）、服务查找（SRV记录）和反向IP地址查找（PTR记录）。下
面我们将分别详解Kube-dns的这两种架构。

。**etcd存储所有DNS查询所需的数据**。**kube2sky观察Kubernetes API Server处Service和Endpoints的变化**，然后同步状态到Kube-dns自己的etcd。**SkyDNS监听在53端口**，根据etcd中的数据对外提供DNS查询服务。
。**kubedns**从Kubernetes **API Server处观察Service和Endpoints**的变化并**调用SkyDNS的golang库**，在内存中维护DNS记录。kubedns作为dnsmasq的上游在dnsmasq cache未命中时提供DNS数据；**dnsmasq是DNS配置工具，监听53端口**，为集群提供DNS查询服务。**dnsmasq提供DNS缓存**，**降低了kubedns的查询压力，提升了DNS域名解析的整体性能；exechealthz用于健康检查，检查Kube-dns和dnsmasq的健康，对外提供/healthzHTTP接口以查询Kube-dns的健康状况。**

这个版本的Kube-dns和之前版本的区别在于：
• 从Kubernetes API Server那边观察（watch）到的Service和Endpoints对象**没有存在etcd**，而是缓放在内存中，既提高了查询性能，也省去了维护etcd存储的工作量；
• 引入了**dnsmasg容器**，由它接受Kubernetes集群中的DNS请求，目的就是**利用dnsmasq的cache模块，提高解析性能：**
• **没有直接部署SkyDNS，而是调用了SkyDNS的golang库，**相当于之前的SkyDNS和Kube2Sky整合到了一个进程中；
·。**增加了健康检查功能，**
从Kubernetes 1.12开始，**CoreDNS就成了Kubernetes的默认DNS服务器。**

## （14）KBS的网络插件

**Flannel仅仅作为单租户的容器互联方案是很不错的，但需要额外的组件实现更高级的功能，例如网络隔离、服务发现和负载均衡等。**
**Calico是一个基于BGP的纯三层的数据中心网络方案**（也支持overlay网络），并且与Kubernetes、OpenStack、AWS、GCE等laaS和容器平台有良好的集成。**Calico基于iptables实现了Kubernetes的网络策略，**通过在各个节点上应用ACL（访问控制列表）提供**工作负载的多租户隔离**、安全组及其他可达性限制等功能.

**Calico可以创建并管理一个3层平面网络，为每个工作负载分配一个完全可路由的IP地址**。 工作负载可以在没有IP封装或NAT的情况下进行通信，以**实现裸机性能，简化故障排除和提供更好的互操作性。**我们称这种网络管理模式为vRtouer模式。**vRouter模式直接使用物理机作为虚拟路由器，不再创建额外的隧道。**然而**在需要使用overlay网络的环境中，Calico也提供了IP-in-IP（简称ipip）的隧道技术。**

。Calico的核心设计思想是：使用通用的互联网工具和技术实现大规模网络互连结构。产生这种设计思想的主要原因是互联网行业在运营真正大型网络上已经积累了几十年的经验，使用的工具和技术（例如BGP）也已经过长时间的磨炼，如果把这些工作全部丢进垃圾桶，重新造轮子就不够明智了。

。Calico是一个比较有意思的虚拟网络解决方案，**完全利用路由规则实现动态组网，通过BGP通告路由。**由于Calico利用宿主机协议栈的三层确保容器之间跨主机的连通性，报文的流向完全通过路由规则控制，没有overlay，没有NAT，直接经过宿主机协议栈处理，因此我们称**Calico是一个纯三层的组网方案，转发效率也较高。**
。**Calico的核心设计思想就是Router**，它把每个操作系统的协议栈看成一个路由器，然后把所有的容器看成连在这个路由器上的网络终端，在路由器之间运行标准的BGP，并让节点自己学习这个网络拓扑该如何转发。然而，当**网络端点数量足够大时，自我学习和发现拓扑的收敛过程非常耗费资源和时间.**
。**Calico的缺点是网络规模会受到BGP网络规模的限制。**Calico路由的数目与容器数目相同，极易超过三层交换、路由器或节点的处理能力，从而限制了整个网络的扩张，因此**Calico网络的瓶颈在于路由信息的容量。Calico会在每个节点上设置大量的iptables规则和路由规则，这将带来极大的运维和故障排障难度。**
。**Calico的应用场景主要在IDC内部，Calico官方推荐将其部署在大二层网络上，这样所有路由器之间是互通的。**所谓大二层就是没有任何三层的网关，所有的机器、宿主机、物理机在二层是可达的。大二层主要的问题是弹性伸缩的问题。频繁开关机的时候，容器启停虽然不影响交换机，但容易**产生广播风暴。**

## （15）Istio初步

单体应用被分解为众多的微服务，服务之间的依赖和通信十分复杂，出现了Twitter开发的Finagle，Netflix开发的Hystrix和Google开发的Stubby这样的"胖客户端"库，这些就是早期的Service Mesh，但是它们都适用于特定的环境和特定的开发语言，并不能作为平台级的支持。

说到Isito，不得不提Envoy。Envoy对Service Mesh最大的贡献就是定义了xDS，Envoy虽然本质上是一个proxy，但是它的配置协议被众多开源软件支持，如Istio、Linkerd、AWS App Mesh、SOFA Mesh等。
。**sidecar模式一般有两种实现方式**
• 通过SDK的形式，在开发时引入该软件包依赖，使其与业务服务集成起来。这种方法可以与应用密切集成，提高资源利用率并且提高应用性能，但也对代码有侵入，受到编程语言和软件开发人员水平的限制
•Agent形式。服务所有的通信都是通过这个agent代理的，这个agent同服务一起部署，和服务一起有着相同的生命周期创建。这种方式对应用服务没有侵入性，不受编程语言和开发人员水平的限制，做到了控制与逻辑分开部署。但是会增加应用延迟，并且管理和部署的复杂度会增加。
**为什么要在Service Mesh中使用sidecar模式呢？**
•解决服务之间调用越来越复杂的问题
•控制与逻辑分离的问题

Service Mesh典型实现是Linkerd

* Linkerd的出现是为了解决像Twitter、Google这类超大规模生产系统的复杂性问题。Linkerd不是通过控制服务之间的通信机制来解决这个问题的，而是通过在服务实例之上添加一个抽象层来解决的。
  。 Linkerd负责跨服务通信中最困难、最易出错的部分，包括延迟感知、负载均衡、连接池、TLS、仪表盘、请求路由等，这些都会影响应用程序的伸缩性、性能和弹性。

**Linkerd的工作原理如下**
。Linkerd将服务请求路由到目的地址，根据请求的参数判断是到生产环境、测试环境还是staging环境中的服务（服务可能同时部署在这三个环境中），是路由到本地环境还是公有云环境？所有这些路由信息既可以动态配置，也可以是全局配置，甚至也支持为某些服务单独配置，
• **当Linkerd确认了目的地址后，将流量发送到相应服务发现端点，在Kubernetes中就是Service，然后Service会将服务转发给后端的实例。**
• Linkerd根据观测到最近请求的延迟时间，选择所有应用程序的实例中响应最快的实例.
• Linkerd将请求发送给该实例，同时记录响应类型和延迟数据
• 如果该实例挂了，则Linkerd将把请求发送到其他实例上重试，
。 如果该实例持续返回错误，则Linkerd会将该实例从负载均衡池中移除，稍后再周期性地重试
• 如果请求的截止时间已过，则Linkerd主动使该请求失败，而不是再次尝试添加负载，
• Linkerd以metric和分布式追踪的形式捕获上述行为的各个方面，这些追踪信息将被发送到集中metric系统
**Istio分为两个平面：数据平面和控制平面。**
•数据平面由一组sidecar的代理（Envoy）组成。这些代理调解和控制微服务之间的所有网络通信，并且与控制平面的Mixer通信，接受调度策略，
• 控制平面通过管理和配置Envoy管理流量。此外，控制平面配置Mixers来实施路由策略并收集检测到的监控数据。
Envoy是Lyft开源的一个用C++开发的高性能代理，用于管理Service Mesh中所有服务的所有入站和出站流量。Envoy从功能上看是一个类似于Nginx的七层代理，但更加贴近Service Mesh的使用场景。Istio利用了Envoy的许多内置功能

# 容器网络

一般会使用**Flannel作为网络，Calico作为网络策略**。或者**直接使用canel，其他的组件还有kebu-router**。无论是哪种插件，无非是使用了虚拟网桥、多路复用（MAC VLAN，为物理网卡配置多个MAC地址实现VLAN）、网卡硬件交换**SR-IOV**（单根IO虚拟化，虚拟出很多硬件网卡，实现网卡级别的交换）。
。Callico网络：大概思路是即不走Overlay网络，不引入另外的网络性能损耗，而是将**转发全部用三层网络的路由转发来实现**。Calico推荐使用**物理机作为路由器的模式**，这种模式没有虚拟化开销，性能比较高。Calico的主要组件包括路由、iptables的配置组件Felix、路由广播组件BGP Speaker，以及大规模场景下的BGP Route Reflector。为解决跨网段的问题，Calico还有一种IPIP模式，也即通过打隧道的方式，从隧道端点来看，将本来不是邻居的两台机器，变成相邻的机器。所谓**IPIP模式**就是两个物理机建立连接，对数据进行封装，看起来就像是处于一个网络。

。Flannel网络：是CoreOS团队针对Kubernetes设计的一个网络规划服务，简单地说，**它的功能是让集群中不同节点的主机创建Docker容器都具有全集群唯一的虚拟IP地址，而且Flannel还可以在这些IP地址之间建立一个覆盖网络，通过这个覆盖网络将数据包原封不动的传递到目标容器内。**Flannel支持多种后端实现，包括VXLAN、HostGW、UDP。

VXLAN有两种形式：**原生的VXLAN和直接路由型VXLAN**，

。 Flannel的跨主机通信机制：两个真实的主机，在同一个主机内的Docker容器互相通信**通过Docker0网桥**即可。但是跨主机通信通过Docker0网桥就无能为力了。当Docker容器启动的时候，Docker0网桥会为其分配一个IP地址，当在**宿主机上安装Flanneld的时候会创建FlannelQ网桥FlanneI0会监听Docker0的全部数据。**当宿主机中的一个Docker向另一个宿主机的Docker容器发起网络请求的时候，**数据包会被Flanneld截取，Flanneld将数据包进行封装**，发送至另一台主机，另一台主机的Flanneid程序解封装数据包，通过**Flannel0网桥**和**Docker0网桥分发数据到指定的容器**。

跨主机时的地址信息将以Key-Value的形式被存放在etcd中。

。Canel网络：

​    。Ingress用于控制入站容器网络的策略，Egress用于控制出战容器网络的策略。

​    。定义YAML的时候指定Kind类型为NetworkPolicy，通过spec。PodSelector和spec.PolicyTypes来制定POD和策略。

​    。策略一般是拒绝所有的出战和入站，然后放行所以的出战目标本名称空间内的所有POD。

![image-20221127212546001](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221127212546001.png)

![image-20221127212608065](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221127212608065.png)

# SDN、OVS

•特点：
。控制与转发分离
。控制平面与转发平面之间的开放接口
。逻辑上的集中控制
。OpenFlow和OpenvSwitch的关系：OpenFlow是SDN控制器和网络设备之间互通的南向接口协议，OpenvSwitch用于创建软件的虚拟交换机。OpenvSwitch是支持OpenFlow协议的，当然也有一些硬件交换机也支持OpenFlow协议。它们都可以被统一的SDN控制器管理，从而实现物理机和虚拟机的网络连通。
。**SDN控制器**是如何通过OpenFlow协议控制网络的呢？在OpenvSwitch里面，有一个流表规则，任何通过这个交换机的包，都会经过这些规则进行处理，从而接收、转发、放弃。**流表就是一个个表格**，每个表格好多行，**每行都是一条规则**。每条规则都有优先级，先看高优先级的规则，再看低优先级的规则。

![image-20221204134316349](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221204134316349.png)

# 网络安全

**跨站脚本攻击（Cross-Site Scripting, XSS），可以将代码注入到用户浏览的网页上，这种代码包括 HTML 和 JavaScript。**

解决手段
（1）**设置了 HttpOnly 的 Cookie** 可以防止 JavaScript 脚本调用，就无法通过 document.cookie 获取用户 Cookie 信息。
（2）**过滤特殊字符**，富文本编辑器通常采用 XSS filter 来防范 XSS 攻击，通过定义一些标签白名单或者黑名单，从而不允许有攻击性的 HTML 代码的输入。
**跨站请求伪造（Cross-site request forgery，CSRF）**，是攻击者通过一些技术手段欺骗用户的浏览器去访问一个自己曾经认证过的网站并执行一些操作（如发邮件，发消息，甚至财产操作如转账和购买商品）。由于浏览器曾经认证过，所以被访问的网站会认为是真正的用户操作而去执行。**XSS 利用的是用户对指定网站的信任、CSRF 利用的是网站对用户浏览器的信任，**
（1）**Referer 首部字段位于 HTTP 报文中，用于标识请求来源的地址。检查这个首部字段并要求请求来源的地址在同一个域名下，可以极大的防止 CSRF 攻击。**
（2）**添加校验 Token，**在访问敏感数据请求时，要求用户浏览器提供不保存在 Cookie 中，并且攻击者无法伪造的数据作为校验。例如服务器生成随机数并附加在表单中，并要求客户端传回这个随机数。
（3）因为 CSRF 攻击是在用户无意识的情况下发生的，所以要求用户输入**验证码**可以让用户知道自己正在做的操作，

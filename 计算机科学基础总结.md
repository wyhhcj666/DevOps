# **计算机科学基础总结**



# 进程与线程（考点）

![image-20221104233624770](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221104233624770.png)

**进程**是**资源**分配的基本单位，**线程**是**可执⾏的基本单位**，是进程的一个执行单元。 线程不可以⾃⼰拥有资源，**线程的执⾏必须依赖于所属进程中的资源**，**一个程序至少有一个进程,一个进程至少有一个线程.**

**协程：**

是一种比线程更加轻量级的存在。一个线程也可以拥有多个协程。

## 区别

**如何描述徐老师总结的话？**

1、一个程序至少有一个进程,**一个进程至少有一个线程.**

2、线程的划分尺度小于进程，使得**多线程程序的并发性高。**

3、另外，**进程在执行过程**中拥有**独立**的内存单元，而**多个线程共享内存**，从而极大地提高了程序的运行效率。

4、线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序出口。**但是线程不能够独立执行，**必须**依存**在应用程序中，由应用程序提供多个线程执行控制。

5、从逻辑角度来看，[多线程](https://so.csdn.net/so/search?q=多线程&spm=1001.2101.3001.7020)的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。**这就是进程和线程的重要区别。**

[再细化至举例以及关于python进程线程问题](https://zhuanlan.zhihu.com/p/114453309)



# 操作系统

**狭义**上的操作系统，通常指的是运⾏在**裸硬件**上的，⽤于抽象并管理硬件资源的软件。

操作系统提供一个操作界面让使⽤者能与系统互动，通常这个“操作界⾯”分为**图形化**操作界⾯和**终端**操作界⾯。

**⼴义**上的操作系统，Kubernetes 也算是操作系统的⼀员。操作系统的设计与实现是⼯业软件（AutoCAD、Maya、Matlab、MySQL）的基础和内核。通常我们认为，**操作系统指的是内核**，⽽类似于 Bash、Finder 等软件属于操作系统上提供的软件。

为了防止软件直接运行在内核上不安全。现代的内核通常提供两种模式：**内核模式和⽤户模式**。软件和⼀部分驱动⼯作在⽤户模式中，⼀些**必要的驱动**直接⼯作在**内核模式**。内核的设计从⼀开始的单任务发展到了多任务，例如 Linux 的内核提供了 task_struct 这个数据结构描述任务。但是创造内核任务是昂贵的，因为内核需要维护**上下⽂**并且负责任务的调度。现代软件通常是多个任务同时执⾏的，因此⽤户模式下的任务变得受欢迎。从此，进程变为⼀个划分资源的单位，例如⼀个 Bash 登录环境后就会创建⼀个进程，并为此分配内存和处理器资源。

在 **Linux 2.4 版本之前**，内核没有提供线程的概念。**由于各家针对的线程的实现⻛格迥异**，为了统一标准，**RedHat 和 IBM** 分别给出 了⽅案： 

1. RedHat 提供了 NPTL(Native POSIX Thread Library)项⽬。 

2. IBM 提供了 NGTP(Next Generation POSIX Threads)项⽬

   *后来由于各种原因，IBM 放弃了该项⽬。⾄此， RedHat NPTL 项⽬成为 Linux 默认的线程库。*

Linux 上常⻅的有 **C/C++ 线程库 —— Glibc**。Glibc 是 GNU 发 布的 C/C++ 运⾏时库，⼏乎任何库都依赖于 Glibc，⽐如 JVM 的线程通过 Native 的⽅式创建任务。⼈们通过 NPTL 调⽤创建线程的函数创造线程，这些线程是内核级别的线程。与进程⼀样，内核级别的线 程通常也是昂贵的。⾯对⾼并发和⼤量的客户端应⽤频繁的创建和销毁内核线程使得内核不堪重负。为了尽最⼤⼒度去复⽤内核线程，⼈们发明的⽤户线程。那么，这就产⽣了⼀个问题：⽤户线程使⽤怎样 的⽅式映射到内核线程？ 在现实世界中，⼈们提供了三种⽅式：

• **1:1（内核级线程模型）；**

 **• 1:N（⽤户级线程模型）；**

 **• M:N（混合式线程模型）**

### NTPL ：在内核里面线程仍然被当作是一个进程

### **KSE**

**注意: 内核线程通常称为 KSE(Kernel Scheduling Entity)，内核调度实体。这些 KSE 参与 CPU 时间⽚的⽠分，多个 KSE 在⼀个 CPU 核⼼上运⾏就是并发，多个 KSE 在 多个 CPU 核⼼上运⾏就是并⾏。**



# 常⻅线程模型（建议看图理解）

### 内核级线程模型

将⽤户线程以 1:1 的⽅式映射到内核线程上。⽤户线程阻塞之后不 会影响其他线程的执⾏，⽽且可以让多线程程序拥有更好的表现。许多 操作系统限制了内核线程的数量，所以间接导致⽤户线程受限。由于操作系统内核直接创建线程、销毁线程，并且还需要维护线程 的上下⽂信息，因此资源成本⼤幅度上升。内核级线程模型在多处理器 架构上，内核能够并⾏执⾏同⼀个进程中的多个线程，如果发⽣阻塞直 接切换同⼀个进程中的其他线程执⾏。该模型的另⼀个缺点在于所有阻 塞线程的操作都是以系统调⽤的形式进⾏的。

![image-20221105003425657](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221105003425657.png)

### 用户级线程模型

将⽤户线程以 N:1 的⽅式映射到内核线程上。语⾔运⾏时通常会实现⼀个线程调 度器，线程之间的切换由语⾔运⾏时实现，内核感受不到线程的切换和实现，内核的 所有调度都是基于⽤户进程的。该模型对 系统资源消耗较⼩，整体上来说较为轻量级。 最⼤的缺点在于不是真正意义上的并发。某个⽤户线程由于 I/O 阻塞或者系统调 ⽤阻塞会导致整个⽤户进程阻塞，因为⽤户进程中的线程没有接收CPU中断的能⼒， 属于⾃调度。 在⽤户级线程模型下，多处理器架构也只是⽤户进程关联到⼀个CPU，很多协程 库将⼀些阻塞的操作封装成⾮阻塞的，在阻塞代码段让出CPU时间⽚并通过某种⼿段 通知其他⽤户线程运⾏，避免内核调度器由于内核线程阻塞做上下⽂切换，解决整个 ⽤户进程阻塞问题。该模型解决了某些操作系统不⽀持线程的情况，⽤户线程的状态机切换和上下⽂ 托管都在⽤户进程中实现，调度算法不受操作系统限制。⽤户级线程模型能够利⽤较 多的堆栈空间，并且不需要系统调⽤和系统内核上下⽂切换，更不需要刷新内存⾼速 缓存，使得⽤户线程的调⽤速度很快。[⽤户级线程存在的意义是什么?](https://www.zhihu.com/question/307787570/answer/592442800)

![image-20221105005222275](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221105005222275.png)

### 混合式线程模型

将⽤户线程以 N:M 的⽅式映射到内核线程上。 语⾔运⾏时调度器和内核调度器都参与⼯作。

进程和线程的元数据维护在栈空间中，进程栈空间执⾏时是确定的，与编译 链接⽆关。**进程栈空间**的⼤⼩是**随机**的，并且要⽐**线程栈空间⾼出2倍。**

⼀般默 认情况下，线程栈在进程的堆中分配，每个线程拥有独⽴的栈空间，为了避免线 程之间的栈空间踩踏，线程栈之间还会有以⼩块 **Guard Size** ⽤来隔离保护各⾃ 的栈空间(4K⼤⼩的保护⻚，防⽌栈溢出)，⼀旦另⼀个线程踏⼊到这个隔离区， 就会引发段错误

![image-20221105005430287](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221105005430287.png)

#### Guard Size如何理解?

个人认为：是线程栈之间的’线‘，在栈与栈之间定义了一个值，一方面是为了隔离，另一方面，如果数据触碰到这个值，那么就会报错。

### 微内核和宏内核的区别是什么？

[知乎连接](https://zhuanlan.zhihu.com/p/53612117)

对于微内核，用户服务和内核服务分别运行在不同的地址空间中；对于宏内核不管是用户服务还是内核服务事实上都是内核在统一管理，它们是运行在同一地址空间中的。

![img](https://pic3.zhimg.com/80/v2-9988d404585168775f779194ec3a53a6_720w.webp)

### mysql四大线程

![image-20221105005919015](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221105005919015.png)

#### 1、Master thread

Master thread有四大循环，分别是loop,background loop，suspend loop，flush loop。且四大循环的作用如下:

loop: 是master thread的主循环， 用于将buffer pool的脏页刷新到磁盘,合并change buffer的脏页到辅助索引页面，清理undo log页。
background loop: 这是master thread的后台循环。当数据库还在运行，且没有用户运行事件，此时会进入background 循环。
flush loop: 刷新循环。一般是进入background loop后当服务器没有空闲状态了会进入flush loop.
suspend loop: 暂停循环，数据库处于恢复的状态，状态恢复后进入loop循环.

#### 2. io thread

​     在innodb 存储引擎中大量使用了AIO(Async IO)来处理io请求.共有4个IO thread，分别是 wirte io ,read io,insert buffer ,log io thread,但是在windows平台可以通过innodb_file_io_threads来增加IO thread。从InnoDB 1.0.X版本开始,read thread,write thread分别增加到了4个，并不再使用innodb_file_io_threads参数，而是使用innodb_read_io_threads,innodb_write_io_threads参数。


#### 3、purge thread

purge thread主要用于回收undo 页。在InnoDB 1.1版本之前主要由master thread回收undo 页，从innodb 1.1版本开始，将purge独立，从而提高cpu利用率。用户可以通过innodb_purge_threads参数设置purge 的线程，不过这一特性是从innodb 1.2开始支持的，一般就设置4吧，表示有4个purge thread并行清理undo页面。

#### 4、page Cleaner Thread

page Cleaner Thread 用于脏页刷新，这一功能是从innodb 1.2.x版本开始引入的。


## 用户级线程到底有什么用？

### 工程中的选择

当一个线程调用了某个会长期中断当前工作的api后，可能有几种方案：

**1. 让操作系统帮助挂起当前线程，切到别的线程去工作。**

**2.** **调用非阻塞的api，然后去干其他当时可以干的工作。非阻塞的api处理完成后会以回调的形式继续进行之后的工作**。典型的代表是nginx。

**3. 调用非阻塞的api，然后在用户态主动把控制权交给别的线程**。

**4. 调用的api被运行时包装，调用后由运行时决定最佳的切换方式**。

### 用户级线程的意义

那么，用户级线程到底有什么意义呢？主要有这么几点：

- 内存占用少，尤其是不用占用内核的内存资源；
- 切换时代价低，也更快；
- 对于2和3，开发者是可以手工控制切换时机的。对于某些特定的应用场景，可以手动控制也许会非常关键；
- 数据同步相对简单。使用内核级线程，因为**切换是“抢占”**的，所以无法预测两个线程执行的相对顺序，也就必须时时留意“线程安全”这件事；而对于用户级线程，切换是开发者自己控制的，所以这个线程安全的思维负担大大地减轻了。

但只靠用户级线程在很多场景下的的确确干不了活，需要操作系统其他方面的的支持才能形成完整方案。

所以，如果发现要解决的问题

- 恰好使用用户级线程就足够解决，不需要其他支持（即，题主提出的一个用户级线程调用阻塞api的情况不会发生）
- 或者，使用用户级线程，同时需要的配套的API/运行时等支持可以用（比如非阻塞IO api）

那么使用用户级别线程就很恰当。比如，web的代理、[api网关](https://www.zhihu.com/search?q=api网关&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A592442800})以及IM这样的场景就非常适合。



## 上下文

![img](https://img-blog.csdnimg.cn/20200927140933992.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NhaXppcjkxMw==,size_16,color_FFFFFF,t_70)

上下文，也就是执行任务所需要的相关信息。这个任务可以是一段代码，一个线程，一个进程，一个函数。当这个“任务”，相关信息需要保存下来，就可以使用Context来记录了。

个人理解：不好形容的一坨代码或其他内容的别称，且内容具有上下文关系的这么一个东西。





# SMP、NUMA 和 MPP

⽬前，商⽤服务器处理器架构有三种：SMP（Symmetric Multi-Processor，对称多处理器结构）、NUMA（Non-Uniform Memory Access，⾮⼀致存储访问结构）和 MPP（Massive Parallel Processing， 海量并⾏处理结构）。 为什么需要多处理器架构？**为了高效**（用最少的钱得到更强的性能）



主要在于三个优点: 

1. 增加吞吐量: 通过增加处理器数量，以期望在更短的时间内完成⼯作。采⽤N个处理器的加速并不等于N，⽽是接近于N。当多个处理器协同完成同⼀个任务时，会存在⼀定的额外 开销。
2. 规模经济: 多处理器系统的价格远低于相同负载的单处理器系统，多处理器系统可以共享⼤量的外设、⼤容量的存储和电源。如果多个程序同时操作⼀个数据集，那么将这些数据 放在同⼀个磁盘并让多处理器共享处理，这要⽐拷⻉副本更加节省。
3.  增加可靠性: 如果将功能分布在多个处理器上，那么单处理器的故障不会使得整个系统停⽌运⾏。单处理器系统崩溃对于数据中⼼是致命的

**为了高效**

## SMP**对称**多处理或**共享内存多处理**

**对称处理器中最广泛的是smp**

**SMP是相对于⾮对称多处理器技术应⽤最⼴泛的并⾏计算技术。**

在 SMP 中，所有处理器的地位都是平等的，通过**总线**连接到同⼀个共享的物理 内存，硬件系统中的所有资源都是共享的。SMP 应⽤⼴泛的主要原因在于⼤部分的 ⼿机、笔记本都在使⽤该架构，并且⼀些较为⽼旧的服务器也使⽤这种架构。对于 SMP 架构的服务器来说，每⼀个共享环节都并发的访问硬件资源，这就导致当 CPU 数量增加后，资源的抢占不断增加。

 实验证明：SMP 架构的服务器 CPU 利⽤率最好的情况是 2~4 个 CPU

![img](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/SMP_-_Symmetric_Multiprocessor_System.svg/440px-SMP_-_Symmetric_Multiprocessor_System.svg.png)

![img](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Shared_memory.svg/350px-Shared_memory.svg.png)

​                       典型 SMP 系统示意图。三个处理器通过[系统总线](https://en.wikipedia.org/wiki/System_bus)或[交叉开关](https://en.wikipedia.org/wiki/Crossbar_switch)连接到同一内存模块

### 可变SMP

可变对称多处理 （vSMP） 是由 NVIDIA 发起的一项特定移动用例技术。该技术在四核设备中包括一个额外的第五个内核，称为 Companion 内核，专为在移动活动待机模式、视频播放和音乐播放期间以较低频率执行任务而设计。

总体而言，该技术通过降低移动处理器的功耗，满足了在活动和待机使用期间提高电池寿命性能的需求。

此体系结构的优点：

- 缓存一致性：同步以不同频率运行的内核之间的缓存没有任何后果，因为 vSMP 不允许配套内核和主内核同时运行。
- 操作系统效率：当多个 CPU 内核以不同的异步频率运行时，效率低下，因为这可能会导致可能的调度问题。使用 vSMP，活动 CPU 内核将以类似的频率运行，以优化操作系统调度。
- 功耗优化：在基于异步时钟的架构中，每个内核位于不同的电源平面上，以处理不同工作频率的电压调整。其结果可能会影响性能。vSMP 技术能够动态启用和禁用某些内核以用于活动和备用使用，从而降低整体功耗。

这些优势使vSMP架构比其他使用异步时钟技术的架构受益匪浅。

## NUMA非一致性内存访问

**NUMA 的提出在于 SMP 扩展能⼒的限制。不过 NUMA 架构解决横向扩展能⼒的同时带来了访问延迟。**NUMA 将资源划 分，提供了 Node（节点）的概念。 NUMA 使⽤ Node 的概念将硬件资源进⾏分割，每个 Node 都有独有的处理器核⼼、内存和 I/O 资源。这样做的依据就是访 问本地资源的速度远远⾼于其他资源，但是同样的问题在于多个 Node 之间资源交互⾮常慢，当 CPU 增多的时候，性能提升幅 度并不是很⾼。 利⽤ NUMA 技术，可以较好地解决原来 SMP 系统的扩展问题，在⼀个物理服务器内可以⽀持上百个 CPU 

![image-20221105140942700](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221105140942700.png)

## MPP⼤规模并⾏处理系统

**⼤规模并⾏处理系统**，这样的系统是由许多松耦合的处理单元组成的，要注意的 是这⾥指的是处理单元⽽不是处理器。每个单元内的CPU都有⾃⼰私有的资源，如总 线，内存，硬盘等。在每个单元内都有操作系统和管理数据库的实例复本。这种结构 **最⼤的特点在于不共享资源。但受限于网络。**

⼤规模并⾏处理器阵列，也称为**多⽤途处理器阵列( MPPA )**，是⼀种具有数百或数 千个CPU和RAM存储器的⼤规模并⾏阵列的集成电路。这些处理器通过可重新配置的 通道互连将⼯作传递给彼此。通过利⽤⼤量并⾏⼯作的处理器，MPPA 芯⽚可以完成 ⽐传统芯⽚要求更⾼的任务。MPPA 是⼀种MIMD（多指令流，多数据）架构，具有本地访问的分布式内存，⽽ 不是全局共享的。每个处理器都被严格封装，只能访问⾃⼰的代码和内存。处理器之 间的点对点通信直接在可配置互连中实现。

MPPA ⽤于⾼性能嵌⼊式系统和台式计算机和服务器应⽤程序的硬件加速，例如 **视频压缩、图像处理、医学成像、⽹络处理**、

Flynn于1972年提出了计算平台的Flynn分类法，主要根据指令流和数据流来分类，共分为 四种类型

![image-20221106013256082](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20221106013256082.png)

SISD：指令部件只对一条指令处理，只控制一个操作部件操作。如一般的串行单处理机。

SIMD:由单一指令部件同时控制多个重复设置的处理单元，执行同一指令下不同数据的操作。如阵列处理机。

MISD：多个指令部件对同一数据的各个处理阶段进行操作。这种机器很少见。

MIMD：多个独立或相对独立的处理机分别执行各自的程序、作业或进程。例如多处理机。



三种多处理器架构的应⽤场景

• MPP系统**不共享资源**，因此对它⽽⾔，**资源⽐SMP要多**，当需要处理的事务达到⼀定规模时，MPP的效率要⽐SMP好。由于MPP系统因为要在不同处理单元之间传送信息，在通信时间少的 时候，那MPP系统可以充分发挥资源的优势，达到⾼效率。也就是说：操作相互之间没有什么关系，处理单元之间需要进⾏的通信⽐较少，那采⽤MPP系统就要好。因此，MPP系统在决策⽀ 持和数据挖掘⽅⾯显示了优势。

 • MPP系统因为**要在不同处理单元之间传送信息，所以它的效率要⽐SMP要差⼀点**。在通讯时间多的时候，那MPP系统可以充分发挥资源的优势。因此当前使⽤的OLTP程序中，⽤户访问⼀个 中⼼数据库，如果采⽤SMP系统结构，它的效率要⽐采⽤MPP结构要快得多。

 • **NUMA架构来看**，它可以在⼀个物理服务器内集成许多CPU，使系统具有较⾼的事务处理能⼒，由于远地内存**访问时延远⻓于本地内存访问，**因此需要尽量减少不同CPU模块之间的数据交 互。显然，NUMA架构更适⽤于OLTP事务处理环境，当⽤于数据仓库环境时，由于⼤量复杂的数据处理必然导致⼤量的数据交互，将使CPU的利⽤率⼤⼤降低。



# 缓存⼀致性协议 MESI（超级重点）

CPU 通常在内存存取数据，由于 CPU 的运算核⼼通常⽐内存速度⾼出⼏个数量级，那么 CPU 通常会在核⼼旁边设置⾼速缓存。 

缓存满足局部性原理。

## 局部性原理

: 在CPU访问存储设备时，⽆论是存取数据抑或存取指令，都趋于聚集在⼀⽚连续的区域中，这就被称为局部性原理。

 • **时间局部性:** 如果⼀个信息项正在被访问，那么在近期它很可能还会被再次访问。 

• **空间局部性**: 如果⼀个存储器的位置被引⽤，那么将来他附近的位置也会被引⽤。

 这些结论都是⼈们从⼤量的⽣产实践观察总结出来的。 

**比如：一个存储器的位置被用，这个存储器的附近的存储器也被使用！**

当 CPU 中设计了**⾼速缓存**，那么 CPU 执⾏指令的**流程**为: 程序以及数据加载到主内存，然后指令和数据加载到 CPU 的⾼速缓存；CPU 执⾏指令，把结果写到⾼速缓存中，然后⾼速缓存将数据落 实到内存。由于CPU的运算速度超越了1级缓存的数据I\O能⼒，CPU⼚商⼜引⼊了多级的缓存结构

![image-20221106151352308](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221106151352308.png)

![image-20221106153409012](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221106153409012.png)

![image-20221106153504493](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221106153504493.png)

**缓存的⼀致性消息传递是要时间的，这就使其切换时会产⽣延迟。**当⼀个 缓存被切换状态时其他缓存收到消息完成各⾃的切换并且发出回应消息这么⼀ ⻓串的时间中CPU都会等待所有缓存响应完成。可能出现的阻塞都会导致各种 各样的性能问题和稳定性问题。 ⼀次读写操作的演示：

![image-20221106153518591](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221106153518591.png)

如图：单处理器**读取**，cpu0为（E）独享、互斥状态——>**多**处理器**读取**cpu0跟cpu1处于（S）共享，cpu0转变为共享状态——>cpu0进行修改（S to M），cpu1（S to I）失效状态——>cpu0结束更改后，两cpu变回S状态。

cpu需要进行的操作都会被**监听，**会对动作变化前做出**升迁**。



## 阻塞状态：

监听信息的返回时间+升迁指令的传递时间   其中的状态就是阻塞状态

# 存储缓存（Store Buffer）⽤于CPU切换状态阻塞解决

⽐如你需要修改本地缓存中的⼀条信息，那么你必须将I（⽆效）状态通知到其他拥有该缓存数据的CPU缓存中，并且等待确认。等待确认的过程会阻塞处理器，这会降低处理器的性能。**因为这 个等待远远⽐⼀个指令的执⾏时间⻓的多。**为了避免这种CPU运算能⼒的浪费，**存储缓存被引⼊使⽤**。处理器把它想要写⼊到主存的值写到缓存，然后继续去处理其他事情。当所有失效确认 （Invalidate Acknowledge）都接收到时，数据才会最终被提交。但是该⽅案也存在两个⻛险：

 • 处理器会尝试从存储缓存中读取值，但它还没有进⾏提交。这个的解决⽅案称为 Store Forwarding，它使得加载的时候，如果存储缓存中存在，则进⾏返回。

 • 保存什么时候会完成，这个并没有任何保证。

**Store Buffer产生等待确认返回的问题。**

执⾏失效也不是⼀个简单的操作，它需要处理器去处理。另外，存储缓存并不是⽆穷⼤的，所以处理器有时需要等待失效确认的返回。这两个操作都会使得性能⼤幅降低。

为了应付这种情况， 引⼊了**失效队列**。它们的约定如下：

 • 对于所有的收到的 Invalidate 请求，Invalidate Acknowledge 消息**必须⽴刻发送。**

 • **Invalidate 并不真正执⾏**，⽽是被放在⼀个特殊的队列中，在⽅便的时候才会去执⾏。

 • 处理器不会发送任何消息给所处理的缓存条⽬，直到它处理 Invalidate。

 即便是这样处理器已然不知道什么时候优化是允许的，⽽什么时候并不允许。⼲**脆处理器将这个任务丢给了写代码的⼈。这就是内存屏障**（Memory Barriers）：

 • **写屏障** Store Memory Barrier (a.k.a. ST, SMB, smp_wmb) 是⼀条告诉处理器在执⾏这之后的指令之前，应⽤所有已经在存储缓存中的保存的指令。

如何理解写屏障：处理器在处理指令之前，要将store buffer里的**失效队列**（Invalidate Queue）消费完。

执行后需等待 Store Buffer 中的写入变更 flush 完全到缓存后，后续的写操作才能继续执行，保证执行前后的写操作对其他 CPU 而言是顺序执行的；



 • **读屏障** Load Memory Barrier (a.k.a. LD, RMB, smp_rmb) 是⼀条告诉处理器在执⾏任何的加载前，先应⽤所有已经在失效队列中的失效操作的指令。

如何理解：处理器执行加载前，要将storebuff里的失效指令消费完。

执行后需等待 **Invalidate Queue** 完全应用到缓存后，后续的读操作才能继续执行，保证执行前后的读操作对其他 CPU 而言是顺序执行的；

## Store Forwarding

引入store buffer之后又带了新的问题，单个 CPU 在顺序执行指令的过程中，有可能出现，前面的已经执行写入变更，但对后面的代码逻辑不可见。

对于同一个 CPU 而言，在读取 a 变量的时候，如若发现 Store Buffer 中有尚未写入到缓存的数据 a，则直接从 Store Buffer 中读取。这就保证了，逻辑上代码执行顺序，也保证了可见性

# ARM 处理器、新型的内存、⽹卡、硬盘与 FPGA 设备

百度百科：ARM处理器是英国Acorn有限公司设计的低功耗成本的第⼀款RISC微处理器。全称为 Advanced RISC Machine。ARM处理器本身是32位设计，但也配备16位指令集，⼀般来讲⽐等价32位代码节 省达35%，却能保留32位系统的所有优势。

CISC（Complex Instruction Set Computer，复杂指令集计算机） RISC（Reduced Instruction Set Computer，精简指令集计算机） ⼆⼋定律：在CISC指令集的各种指令中，⼤约有20%的指令会被反复使⽤，占整个程序代码的80%。⽽余下的指令却不经常使⽤，在程序设计中只占20%。

 RISC结构优先选取使⽤频最⾼的简单指令，避免复杂指令；将指令⻓度固定，指令格式和寻址⽅式种类减少；以控制逻辑为主，不⽤或少⽤微码控制等。

 Ampere® Altra® Max 全球唯⼀ 128 核云原⽣处理器，实现功耗新突破。

## Intel 傲腾持久内存

原⽣持久性——即使在断电情况下也可以存储数据。

操作模式——英特尔® 傲腾™ 持久内存具有两种操作模式：内存模式（内存模式⾮常适合⼤容量内存，并且由于该内存被视为易失 性内存，因此不需要更改应⽤程序）和 App Direct 模式（可以提供⼤容量内存，且被优化的应⽤可直接与作为第⼆层内存的 PMem 进⾏ 沟通）。

硬件加密——英特尔® 傲腾™ 持久内存配备⾏业标准的 256-AES 硬件加密功能



# 智能⽹卡

⽹卡是⼀块被设计⽤来允许计算机在计算机⽹络上进⾏通讯的计算机硬件。由于其拥有MAC地址，因此属于OSI模型的第1层和2层之间。它使得⽤户可以通过电缆或⽆线相互连接。每⼀个⽹ 卡都有⼀个被称为MAC地址的独⼀⽆⼆的48位串⾏号，它被写在卡上的⼀块ROM中。在⽹络上的每⼀个计算机都必须拥有⼀个ᇿ⼀⽆⼆的MAC地址。没有任何两块被⽣产出来的⽹卡拥有同样的 地址。这是因为电⽓电⼦⼯程师协会（IEEE）负责为⽹络接⼝控制器（⽹卡）销售商分配唯⼀的MAC地址。

![image-20221106172900326](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221106172900326.png)

网卡 **块设备**                          键盘鼠标**（tty设备）字符设备**

**TCP BBR算法，排满了就丢掉重发**   

# 存储

![image-20221106175120228](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221106175120228.png)

# 链表、树、图与字符串



# 常⻅数据结构

![image-20221106180755190](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221106180755190.png)

#### 数组 

数组支持随机访问，时间复杂度O（n）

数组从0开始，+2，便是取其第三个值   +2 -——offset 偏移量

内存也是随机的，磁盘是顺序访问

#### 链表

链表不支持随机访问，时间复杂度O（n）

链表一个节点中具有 elem（元素） ， prev （前向节点）， next（指针），以此类推。

树：子节点，左子树，右子树，最后的结点：叶子节点

raid在数据结构中就是树  B+树

## 循环语句的小tips

switch case是匹配    if是判断是预测     所以使用case更快

 局部性if语句先写可能性大的(A、B条件把条件优先级高的写前面)

for循环比while循环慢，for循环的汇编语句要比while多

# SQL、关系模型与数据库体系结构

## 范式

### 1NF

官方：定义：关系中每一分量不可再分。即不能以集合、序列等作为属性。（也就是不能表中套表，要保证数据的原子性。）

### 2NF

官方：在1NF基础上，消除非主属性对键的部分依赖，则称它符合2NF。

定义：在1NF基础上，候选码 与 某元素 存在一 一对应的关系

### 3NF

官方：在2NF基础上，消除非主属性对键的传递依赖，则称它符合3NF。

我：在2NF基础上，所以属性都没有传递依赖

 如  a依赖于b  b依赖于c  不能推出a依赖于c，依赖都是完全依赖（2NF）

### BCNF

官方：对于关系模式R，如果每一个函数依赖的决定因素都包含键，则R属于BCNF范式。

我：能决定关系的必须是候选码

## 常⽤的⾼级SQL与关系模型

![image-20221106180952438](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221106180952438.png)

**主键：唯一不可重复，不能为空**



数据库的基本抽象 

数据库系统的构建可以从上到下分为5个层次：

• 查询计划

 • 算⼦执⾏ 

• 访问⽅法 

• 缓冲池管理 

• 存储管理 

存内容到磁盘 慢 所以存到缓冲池  访问方法暂且为SQL    算子执行 join   查询计划（根据人类思维执行一个逻辑计划）



## 数据库引擎

MySQL5.5之前，默认引擎是“MyISAM”；从MySQL5.5版本开始，默认引擎是“InnoDB”

mysql两个引擎的区别：



mongodb 从MongoDB 3.2开始默认的存储引擎WiredTiger

redis -—— rdb

Oracle——没有引擎概念——OLTP跟OLAP



其中，存储管理中使⽤的存储器按照现有计算机架构进⾏排序（按照访问速度）：

• CPU寄存器 

• CPU缓存 

• 动态内存 

• 固态硬盘

 • 机械磁盘

 • ⽹络存储（光纤应该例外）



# 存储管理

**数据库系统的存储引擎就是存储管理系统。**

SQLite（单文件）：不需要服务，就是个文件+开发库

PostgreSQL（多文件）或是mysql

#### innodb的表的定义和数据存储是分开的吗？（面试题）

是。表结构与存储是分开的。

内存用**段**来表示数据块，段往下分是**页**

数据库拿“页”这种概念来表示数据块，并且数据库要求数据是“自托管的”，也就是说元数据和数据都应该被管理，每个数据也都会有全局唯一的PageID。

**数据库的元存储方式：**有的数据库的元数据被**单独存储到一个页**，如下图AB，B为A的元数据；而有的数据库数据和元数据都被**存储到同一个页**，如C，因为这有利于**灾备，例如Oracle**。

## **为何利于灾备？**

拷贝数据库时其实就是复制页，复制页时，迁移的时候数据内容能达成一致性。

![image-20221109232449436](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221109232449436.png)

**操作系统的mmap可能对于数据库来说是灾难**，例如MongoDB的第一版本使用了mmap，研发上做了很多无用功。





## mmap

一种内存映射文件的方法

用才加载，是惰性加载。



**Indirection 层** 用于实现数据页映射到某个集合中一个文件的具体位置。PagelD可以是数据页在对应文件的**相对位置**，那么知道整体文件的初始位置和数据页大小就可以知道具体的Offset值。
  优点：如果整体移动数据文件，例如更换硬盘，那么PagelD就可以保持不变了。
**页的三种概念：**
**硬件的页**： 硬件存储暴露的组织数据存储的概念，并且是 **原子读写** 的数据块大小，通常是4KB。
例如16KB，可能前8KB数据写入了，由于异常，剩余的8KB也写入了，但是不连续，导致是损坏的数据。
**操作系统的页**：从存储设备上取出数据放到内存中的表示， 通常是**4KB**。
**数据库系统的页**：通常是512B - 16KB。



**Indirection 层** 就是个表格，知道相对位置，通过查表找到绝对地址。思想是解耦，寻址是目标。可以使pageid不变

硬盘上的最少单位是页。

redis的存储引擎是个函数

**在存储引擎级别**，我们不关心**数据页中**到底有什么：
**堆文件，无序且随机 。**构建这种文件的方式：
数据页头（页的元数据区）中有 **两个指针** ，指向Free页链表和Data页链表。
使用 **Directory** 的概念包装数据页，这个Directory中包含Free页和Data页。
。顺序/排序文件
。哈希文件

* 数据页大小是固定的，并且要比操作系统和硬件的页更大一些，

* 。如果数据页较小，那么一个PagelD所表达的数据范围更小，**页表就会导致膨胀** ，那么就可能会产生缓存丢失， 类似于**TLB**。               

• 由于数据库的页一般要比操作系统和硬件存储的页大，那么就出现了一个数据库的页使用随机还是连续的方式落实到下游的页；并且多个下游的数据页如何安全的原子的保存，这样写入数据的代价就会变高，因此商用数据库 允许应用进行调整页的大小。
。对页的**灾备**可以使用**日志的方式实现**。  日志文件是给顺序文件（AOF），RDB是快照。WAF



  [行数据与列数据的优缺点以及应用场景](https://zhuanlan.zhihu.com/p/79320135)

  

  • 在数据页中存储元组，也就是数据库行记录，那么；可以采用顺序存储，但是存在的问题是删除元组会 **存储空洞** ，因此一个可行的方案是 **Slotted Pages** ，本质是在数据页头区域设置一个 **Slot Array** ，用来记录元组的偏移量。

  存储空洞——delect跟drop的区别  ——为了不删除后移到元组

  删表数据，和同时删除数据和表结构  。delect其实是标记数据没了，但数据还在占用空间，所以mysql用delect时不会释放空间



  **数据库存储空间不够了怎么办？**

答：重新插入新的硬盘，将数据重新导入排序。

  从头往下扫描如果，slot array在数据页的头设置0和1，在数据备份的时候，让计算机识别0和1来进行是否备份。

  

  。**Slotted Pages**方案 无法解决变长元组带来的空间损失 ，因此PostgreSQL提供了 **Vaccum操作** 用于处理这些空间。类似于GC（垃圾回收）。

  因为元组在边长，空间也是乱的，所以存在了空间碎片。PG这种操作在夜间进行扫描整理。

#### redis的aof自带裁剪功能吗？

![image-20221110133700971](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221110133700971.png)

**OLTP行存储**

**OLAP**
• 元组的布局方式也分为数据区和元数据区。元组中的数据无论是否对齐，数据都会连续存储，这种模型叫做 **N-ARY模型**。元组的DML速度很快，但是对于TB级别的数据分析通常只需要几列而不是整个元组读出，因此**OLAP数据库中有列式存储**。
  •  另一种存储方式是采用 **结构化日志** 存储数据而不是页，
  。优点是便于 **回滚** 且便于操作。
  。缺点是很 **难读** ，因为追加的是DML语句，也可以经过优化，然后存储被一个DML修改后的数据。
  如果不想丢失数据的精度，就需要使用 **固定的浮点** 表示数，但是这需要数据库系统去实现，

  * 对于大型的二进制数据（比如4k高刷小电影），可能的方式是 **Overflow Page** 或者 **外部文件**。
  
    Overflow page 如下图B为OP，外部文件同理。
  
  * 。对于移动应用来说，将文件存储到数据库效率更高，因为不需要获取文件描述符等其他指针。 

![image-20221110133943394](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221110133943394.png)

参考资料 https://en.wikipedia.org/wiki/Mmap 

https://man7.org/linux/man-pages/man2/mmap.2.html



# 缓冲池管理 

缓冲池用于存储磁盘加载到内存的数据，但是存储单位是**Frame** ；Frame对应磁盘上Slot的概念而不是页。 

•数据库系统必须通过一个 Page Table （实质上是哈希表结构）来维护Frame和Page的关系。

## Page Table和Page Directory的区别：

**哈希表**：通过哈希算法确定唯一值进行查找。

**页表**：

。 Page Table是内存中的结构，维护缓冲池与Page ID的映射关系；需要确保是**线程安全**的。

线程安全：多个线程去修改page table时，不会产生并发问题。

**页目录**：

。 Page Directory是数据库文件的存储结构。



## 元数据

数据的数据，用以描述数据的信息也是数据，被称为元数据

mysql存元数据的数据库：     **INFORMATION_SCHEMA数据库**

## **[MySQL]获取元数据的方法**

MySQL提供了以下三种方法用于获取数据库对象的元数据：

1）show语句

2）从INFORMATION_SCHEMA数据库里查询相关表（information_schema是一个虚拟数据库，并不物理存在，它储存数据的信息的数据库）

3）命令行程序，如mysqlshow, mysqldump

• 数据库系统通常维护一些元数据，例如：

。 Dirty Flag 用于表示缓冲池中的数据是否被修改过。
。 Pin/Ref Count 用于表示占用该Page的线程数量。





## • Lock和Latch的区别（重点）

。 Lock是数据库系统的**逻辑原语**，用于保护数据库的逻辑内容。 

。 Latch是一种**底层保护原语**，用于保护数据库系统物理结构的关键部分（数据结构或者内存中的数据），Latch一般会使用自旋锁。

**Latch只作用于内存中（一起读取内存），他只能被当前实例访问，而Lock作用于数据库对象**

**死锁就是Lock**，死锁基本都是人为的



。Lock的对象是 **事务**，Latch的对象是 **线程** 。**所以Lock保护的对象是 数据库数据，而Latch是 内存中的数据结构。**



。Lock发生在整个事务**过程**中，而Latch是产生**临界**资源（操作系统的资源）的时候。

。Lock主要的实现是行锁，表锁，意向锁；Latch的主要实现是操作系统级别的读写锁和互斥量。



。 Lock的死锁检测手段一般是 等待图，依赖图或者超时机制 ， Latch一般不存在死锁检测和处理机制，只是**通过应用程序加锁顺序保证没有死锁的情况发生**。

**死锁不需要解决，鸵鸟算法（狗头）**



。因此Lock被 **锁管理器**（可以实现为一个进程，从事务接收消息并反馈） 的**哈希表**所容纳，Latch则在数据库系统实现的代码中。

进程间通信：消息队列   RPC  TCP





## • 如何为缓冲池分配足够的内存空间？

。全局策略：针对整个系统来考虑，所做出的的解决会使得整个系统受益。
。局部策略：针对每个查询或者事务来考虑，但是对于整个系统可能是糟糕的。



• 多缓冲池、预读取、扫描共享、缓冲池旁路（bypass）：
。数据库可以存在**多个缓冲池**，每个缓冲池都有自己的Page Table维护一套Page ID到Frame的映射。这样做是为了 可以在**每个缓冲池上使用局部策略并且减少Latch争用**的出现。



• ObjectID：使用 (ObjectID, PageID, SlotNum) 三元组来确定加载哪些数据。这样可以通过ObjectID查询到数据。



•哈希表：通过Hash确定缓冲池中的位置，通过取模确定在哪个缓冲池里。、
。**预读取**用于减少查询线程的停顿，从而达到 减少最小化随机IO 。本质是**预测SQL的查询范围和动作意图。**     **DBtwo**



。**扫描共享**用于将一份数据尽可能多的用于多个查询线程，这不等同于**结果缓存**。实现上是将多个查询线程附加到当前的 游标 数据结构中。

将一份数据尽量用于多个SQL中

结果缓存：比如查询语句的结果的缓存





•当不同的线程计算相同的数据，那么这些数据可以横跨多个线程共享它们需要的结果，这叫做 **物化视图**。

• 完整的方案只有DB2和SQL Server支持，Oracle支持的基本扫描共享技术叫做 **游标共享技术** ，两个线程在同时执行时才会有效。

## 。缓冲池旁路

是从本地内存中查找一部分想要的数据并且不污染缓冲池的缓存规律 ，有的系统也叫做Buffer Cache旁路。（开辟一个特殊的空间记录）执行查询时从磁盘将数据 加载到本地内存而不是缓冲池 ，因为查询缓冲池需要Latch，存在一定的代价，但是这样做只能是 中间结果和扫描量比较小 的
时候用。

![image-20221110202203425](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221110202203425.png)

• 许多数据库系统使用Direct IO跳过操作系统页缓存（操作系统维护的文件系统缓存），



• 唯一利用操作系统页缓存的是PostgreSQL，并且为每个线程维护一个很小的缓冲池, 因为设计者从工程师的角度去考虑，但是会降低性能。



• PostgreSQL提供了pg_prewarm扩展程序实现当用户调用这个函数的时候就会将表的所有数据页放到缓冲池，
。 某些数据库系统不喜欢操作系统页缓存是由于 跨平台特性导致不同系统的策略不同，丧失一致性，

比如，MacOS跟windows，只能开发一个都能兼容的软件



• MySQL和Oracie会用所有的系统内存。（有多大占多大）

• **通过将 /proc/sys/vm/drop_caches 就可以强制让操作系统将操作系统页缓存持久化到磁盘，**



• 缓冲池替换策略     （以后会手撕LRU）
。LRU：实现方式是跟踪Paqe的访问时间戳。（访问过就更新时间去标记）

• LRU-K: 只有最近被**访问K次的**才可以在缓冲池中，

## LRU LFU （redis）

**LRU（Least Recently Used）缓存机制**

从数据集中，挑选最近最少使用的数据淘汰。
LFU和LRU的区别在于，**LRU淘汰的是最久未访问到的数据**，而**LFU是淘汰的是最不经常使用的数据**（若两个或多个数据的使用频率相同时，LFU会再选择最久未访问到的数据淘汰）。

## **LRU算法的缺点（面试题）**



。Clock, 与LRU类似,是一种最近未使用算法，即逐出的页面都是**最近没有使用的那个**。



• **解决了LRU需要跟踪每个Page的访问时间戳的问题，但是需要维护每个Page的标志位，**

• 需要将Page设置到 **环形的墨冲池** ，有一个旋转的指针来检查哪些Page需要移除
。不会精确的移除最近最少使用的Page。

![image-20221110195738769](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221110195738769.png)



名字，几月几号开始做的作业。


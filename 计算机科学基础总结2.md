# 计算机科学基础总结2

# 读写方法

按数据结构分类，索引有哈希索引、B+树索引、Full-text索引

## 哈希表

特性决定了只能用来做精确匹配查找。

f(x)=y   ，一对一的值

哈希函数要求：

1、performance

2、uniqe

哈希碰撞问题：若数据趋向于正无穷将会出现相同的key。

哈希Schema（方案/模式）是遇到哈希碰撞解决问题的机制。是为找不到完美的哈希函数的补救措施，所以

**哈希表由哈希Schema和哈希函数构成**

#### 静态哈希

#### **开放寻址法**

性能上依然碾压一切。当Value=Hash（key）时出现冲突，那么以Value为基础产生一个新的哈希值Value1，如再出现便重复操作。

**拉链法**：每个哈希桶下面都有一个链表（go使用）

![image-20221112181349853](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221112181349853.png)

**哈希桶**：哈希桶就是**盛放不同key链表的容器**（即是哈希表），我们可以把每个key的位置看作是一个指针，该指针所指向的位置里放了一个链表，可以认为是指针数组，故该方法也叫开链式。

**多重哈希法**

使用多给不同的哈希函数嵌套哈希计算

如：f(f(f(x)))

![image-20221112182206725](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221112182206725.png)

绿色强，但毛刺严重引起CPU负载不稳定，报警信息不好处理。

BENCHMARK基准测试是对计算机系统的性能的测试（压测）



#### 动态哈希

多哈希表：采用多个哈希表来扩展原来的哈希表，多哈希表公用一个哈希函数。质量不够数量凑。

桶慢时触发新的哈希表创建。



## B+树

特性决定支持范围查找和模糊匹配

通常Key和Value是分离的，因为便于利用CPU的缓存特性。

通常节点中有两个指针指向相邻的兄弟节点。

B+树可以根据层数估算存储的数据量：（（Page大小 - 元数据大小）/ 元组大小）^ 层数。  【公式背】

实际系统中需要将元组中的那个数据作为RecordID？

   指向索引项对应的元组位置的指针。

   元组的实际内容存储在叶节点中，二级索引必须将RecirdID存储为其值。

 B+ 树与 B 树相比，**B+ 树只能将Value存储到叶子节点。**
可以在多个列上定义复合索引，**定义顺序影响查找方式**。

ID放前或后可能会不一样



**变长字段**作为索引键的时候PostgreSQL会使用null或者0填充进行对齐

如果插入的数据超过varchar的长度，MySQL会默默的切掉后边的数据，而PostgreSQL会给出错误，

Sorted Key Map 是一种微优化，在内存中处理，将B+树中的节点中的每个元组的前一个字符提取出来使用数组保存，这样查询对比时， 如果第一个字符就不相等，那么可以直接跳过 ，这样可以避免加载很多数据导致缓存失效。如下图，找AC只需要找到第二个值就可以停止寻找了

![image-20221112185346934](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221112185346934.png)





**B+树上重复的Key如何处理？**
插入RecordID
使用溢出叶节点进行垂直扩展
**聚簇索引**: 让数据按照某种方式进行排序，例如**主键** 。数据库系统会保证索引会对Page中的元组的物理布局进行重新组织，

**如果没有定义主键，MySQL会自动定义一**个，对我们是透明的。（只是性能可能会不好）

PostgreSQL并不会按照主键的顺序来排序，如果主键是聚簇索引的排序方式。
也叫做聚集索引，缺点在于更新的代价高，因为需要将数据移动到指定的位置。插入速度严重依赖于插入顺序。更新时可能会导致页分裂问题。聚集索引也可能会导致全表扫描速度变慢，因为逻辑上连续的页在物理上可能相隔较远，产生大量的随机IO。

覆盖索引：查询的字段都是索引的字段，
 优化: 让B+树变得更快.
前缀压缩：多个排序的Kev具有相同的前缀可以进行压缩，使用**Trie树** 就是咱大学学的二叉树

批量插入：例如批量加载一个数据集，这样就会提前拥有全部的Key，可以 先进行排序然后再批量插入 。
指针混用：将B+树中的PagelD替换为缓冲池中的指针，这样避免访问缓冲池该Page是否存在，
 函数/表达式索引：用户不想通过Key来查找记录，而是某种方法。
 Trie树/基数树



# 读写方法话题：

### 关于ip地址

IP地址要存成128位的长度

ipv4 0.0.0.0 转成ipv6  啥也没有就是一堆冒号

### ES里面使用的是什么索引

和MySQL一样，ES索引的初衷也是为了快速检索到数据。对于mysql 来说使用就是 B+树 ，而ES 使用的就是倒排索引

**term**：在 ES 中，关键词被称为term。

![img](https://pic2.zhimg.com/v2-6f9d8c077c8265bf0bf3b153fd62b2f9_r.jpg)

### LK分词器

ElasticSearch 内置了分词器，如标准分词器、简单分词器、空白词器等。但这些分词器对我们最常使用的**中文**并不友好，不能按我们的语言习惯进行分词。

ik分词器就是一个标准的中文分词器。它可以根据定义的字典对域进行分词，并且支持用户配置自己的字典，所以它除了可以按通用的习惯分词外，我们还可以定制化分词。

ik分词器是一个插件包，我们可以用插件的方式将它接入到ES。



### MySql的InnoDB的三层B+树可以存储两千万左右条数据（面试）

`高度为3的B+树`可以存放：`1170*1170*16=21902400条`这样的记录。所以在InnoDB中`B+树高度一般为1-3层`，它就能`满足千万级的数据存储`。在查找数据时 **`一次页的查找代表一次IO`**， 所以通过主键索引查询通常 **`只需要1-3次IO操作`** 即可查找到数据。

### Mysql的联合主键（面试题）

mysql的联合主键：用2个字段(或者多个字段,后面具体都是用2个字段组合)来确定一条记录，说明，这2个字段都不是唯一的，2个字段可以分别重复，这么设置的好处，可以很直观的看到某个重复字段的记录条数。

### 自增主键会不会用完，用完怎么办（面试题）

会。受到Int整型的影响，大约为43亿。那解决方法也是很简单的，将Int类型改为BigInt类型，用到下辈子。

如何在线修改mysql 表结构

*方式一:使用mysql5.6+提供的在线修改功能*

*方式二:借助第三方工具*





### 自增主键与UUID的优缺点

#### 自增主键

**优点：**

1. 数据库自动编号，速度快，而且是增量增长，按顺序存放，对于检索非常有利；
2. 数字型，占用空间小，易排序，在程序中传递也方便；
3. 如果通过非系统增加记录时，可以不用指定该字段，不用担心主键重复问题。

**缺点：**

删除的时候计数器不会重置

因为自动增长，在手动要插入指定ID的记录时会显得麻烦，尤其是当系统与其它系统集成时，需要数据导入时，很难保证原系统的ID不发生主键冲突（前提是老系统也是数字型的）。特别是在新系统上线时，新旧系统并行存在，并且是异库异构的数据库的情况下，需要双向同步时，自增主键将是你的噩梦；

在系统集成或割接时，如果新旧系统主键不同是数字型就会导致修改主键数据类型，这也会导致其它有外键关联的表的修改，后果同样很严重；

若系统也是数字型的，在导入时，为了区分新老数据，可能想在老数据主键前统一加一个字符标识（例如“o”，old）来表示这是老数据，那么自动增长的数字型又面临一个挑战。



#### UUID

优点：

出现数据拆分、合并存储的时候，能达到全局的唯一性

缺点：

1. 影响插入速度， 并且造成硬盘使用率低
2. uuid之间比较大小相对数字慢不少， 影响查询速度。
3. uuid占空间大， 如果你建的索引越多， 影响越严重

### 字符串比较方式

用哈希是最快的。可以用相减判断是否相等。。



## 分布式ID服务有那些方案？（面试题）

ID全球唯一

### [Leaf——美团点评分布式ID生成系统](https://tech.meituan.com/2017/04/21/mt-leaf.html)



###  推特的Snow Flake

计算了一个64位的整形数据，就可以在两个指令（减法运算）内【一个指令周期内】计算完成。

Mysql集群。。。

其二者依赖于NTP服务。强依赖时钟，对时间的要求比较敏感，在机器工作时NTP同步也会造成秒级别的回退，建议可以直接关闭NTP同步。

。。。。





# 算子执行

**算子**：把算法实现了包装一下，作为一个模块【也可以说是多算法集合】

**连表算子较多**

### 排序和聚合

· 执行的逻辑计划产生的结果和中间结果可能无法完整的存储到内存，因此需要利用**缓冲池**，
• 每个数据库系统都应该支持外部归并排序，将数据集拆分成更小的数据集，然后使用 2 Way Merge Sort 进行处理，在处理时每两个小的数据集合并成一个数据集，一种**优化IO成本的方式是使用 Double Buffering** ，在排序第一个Page的时候使用另一个线程读取第二个Page。
更加复杂的算法是 **N Way Merge Sort** 。

[双缓冲(Double Buffer)原理和使用 - Smah - 博客园 (cnblogs.com)](https://www.cnblogs.com/still-smile/p/11691784.html)

• **局部的排序需要消耗内存，在PostgreSQL中叫做Working Memory，这个参数是可配置的**，
• 在排序过程中，如果排序的目标是聚簇素引，那么基于索引所在Key进行排序，如果是非聚簇索引，那么很少会这样。
•外部哈希聚合，类似于外部归并排序、思路是先分区再哈希。
• **Join算法**：大写字母表示Page的数量，小写字母表示Page中Tuple的数量。
• Simple Nested Loop Join：两个for循环嵌套，IO成本 M + m ± N . 读取M页的IO成本和M次读取N页的IO成本
· Block Nested Loop Join: 减少内层表数据的循环次数。设计了Join Buffer，将外层循环的结果分成一个个Block，然后内层循环的每一行数据与整个Block比较，这样可以减少内存循环的扫描次数。IO成本： l4+(M\ /\ Buffercem
• Index Nested Loop Join: 减少内层表数据的匹配次数。通过外层表匹配条件直接与内层表索引进行匹配，避免和内层表的每条记录进行比较， 从而利用索引的查询减少了对内层表的匹配次数。IO成本: M
》 Sort Merge Join ： 没有驱动表，排序后交替执行，解决的是Nested Loop Join在两个表都很大的情况下慢的问题，IO成本：如果两列都已经排序并且没有重复值，那么N+M，表示只需要对两个集合进行扫描就可以；如果两列都没有排序，并且所有的值都相同，那么 <tex>N\ *</tex>
loq N + M * log M + N * M.

按照Join的字段进行排序，如果排序的字段恰好是聚集索引，那么性能将会达到最高。

•对两组已排序集合进行 合并排序，从来源端各自取得数据列后加以比较，
•**合并排序是建立在归并操作上的一种有效的排序算法。**该算法是采用**分治法**的一个非常典型的应用
• 合并排序是将两个（或两个以上）有序表合并成一个新的有序表，即把待排序序列分为若干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列。
。Hash Join ：适用于一个大表一个小表。分为Build和Probe两个阶段， 只适用于等值Join，
• Build阶段：在优化器生成执行计划阶段会识别出哪是小表，扫描小表建立Hash表（Kev是Join属性采用Hash函数得到的值），数据量很大的情况下使用Bloom过滤器，
• Probe阶段：然后扫描大表的每一个元组计算Hash值，与小表对比，
• Grace Hash Join ：适用于内存不足的情况，核心逻辑在于分块处理，然后将Bucket写入到磁盘中，IO成本 3*(M+N) ,分块的过程中是 2\ *\ (M\ +\ N)，处理的过程中是 N + N M\ +\ N

### 处理模型

**迭代器模型**(iterator model、volcano model、pipeline model) 。

通过0peralori调用Nexl方法实现**从根节点到叶子节点的下推,然后每个节点返回元组**。

常见的数据库系统都支持此模型,但是 一些操作符(Join、子查询、OrderBy)不支持,因为它需要从子节点处获取更多的数据。

物化模型。

调用Next函数的时候不是只返回一个元组,而是返回全部的元组. 。

**对imit语句不友好**,很容易加载不必要的数据有时对于OLTP是友好的,因为通常OLTP聚要加载的数据量较少, 一般出现在特定的系统中,因为物化模型更活合面向内存的数据库。

**向量化模型**

调用Next函数的时候,操作符内部循环一次处理多个元组,个数取决于硬件和查询居性。

对于OLAP是友好的,因为通常OLAP需要加载大量的数据集. 

**是对迭代器模型的增强。**



### 访问模型

计划执行方向：
。自顶向下：适合面向磁盘的数据库，元组与函数调用一起传递。
. 自底向上：允许更严格的控制Pipeline中的CPU缓存和寄存器。
**• 顺序扫描**
Operator中的一大堆for循环。
优化手段:
预读取
缓冲池旁路
并行
Zone Maps：通过计算关于Page的信息来决定是否需要访问这些Page，例如MIN，MAX，COUNT，AVG，SUM等。SQL Server、Amazon RedShift使用了该方式。
延迟物化: 对于一个列式存储系统，可以将数据从一个Operator延迟传播到另一个Operator。
聚簇堆：允许我们从叶节点顺序获取数据。
. **索引扫描**：扫描索引而不是直接扫描数据节点避免不必要的IO开销。
。多索引扫描：指的是通过不同的索引进行多路查找。PostgreSQL称作Bitmap Scan。
。 索引扫描页排序：找出所需要的所有Page，然后根据某个属性进行排序。



### 进程模型

 每个进程负责一个Worker，DB2、Oracle和PostgreSQL使用这种方式。
。使用共享内存实现Buffer Pool共享，避免多个进程加载不同的Page。
。如果一个进程崩溃了不会影响另一个Worker。

每个线程负责一个Worker，MySQL实现了该模型，现代数据库系统一般会使用该模型。
  并行intra-query：MySQL 8才实现该方式，通过多个Worker去执行一些请求。
  水平的intra operator：将数据拆成若干段，然后每个Worker执行相同的任务，最后通过一个Exchange     Operator合并所有的结果。
  垂直的intra operator：一个Worker内的任务高内聚，多个Worker之间的任务低耦合。
  bushy：在同一时刻执行查询计划的不同部分。
  进程池/线程池，DB2和PostgreSQL实现了该模型。
。**一些高端的数据库系统可能会实现工作窃取机制**。   **现在数据库都有**

**后面会讲到，go会用到**

Exchange Operator的类型：
。 聚集：将多个Operator的数据流合并，然后将结果传递给下一个Operator。
  再分区：跨多个输出流重新组织多个输入流，
. 水平分区
· 垂直分区
。分布式的：将单个输入流拆分成多个输出流。



# 算子执行话题：

### Hadoop

Hadoop就是Map Reduce（计算框架）【map分离，reduce合并】 和 HDFS（分布式文件存储）。通过MR计算，HDFS存储，由网络连接。hadoop火的原因是资源节约了（老机子也能用上了）

![image-20221113164713841](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221113164713841.png)

这就是N Way Merge Sort

### 手写快排merge sort（一面面试题）【哈哈】

如何实时算出前三十名的玩家

单节点跑Top N【大根堆小根堆】（实时调整堆）就是给Heapify【堆化】的过程

[算法必学：经典的 Top K 问题 - 简书 (jianshu.com)](https://www.jianshu.com/p/a4a1984fc4ff)

redis5.0前为单线程、后支持多线程



## 查询计划

查询优化本质上有两种类型可以使用：
**条件规则触发**： 当执行查询的时候，触发了某些条件规则，然后对SQL进行改进或者重写。
**基于成本的搜索**：列出一堆查询计划供我们选择执行。我们 通过某种成本模型进行选择。

   基于成本模型可以在不用执行查询计划之前就可以知道不同查询计划的成本。
   但是没有成本模型的数据库系统可以同时执行多个查询计划，然后返回最快的查询计划返回的结果，MongoDB就是这样做的
   预估执行查询的成本是通过在数据库内部维护表的相关信息完成的。
**架构**：
   **应用【程序员写代码】通过发送SQL语句到SQL重写器，SQL重写器是可选的，然后SQL重写器输出SQL查询到解析器，解析器生成AST发送到绑定器，绑定器根据数据库中的定义去修改AST某些值为内部标识符，绑定器会生产逻辑计划送入Tree重写器，Tree重写器是可选的，Tree重写器再次输出逻辑计划到优化器，优化器通常基于成本模型，输出物理计划去执行。**
• **客户端->SQL重写器->SQL解析器->绑定器->Tree重写器->优化器->执行器**
物理计划中定义了如何使用这些Operator。
. 优化手段：一个关系代数产生的元组与另一个关系代数产生的元组相同，那么可以认为这两个关系代数是等价的。
条件规则触发：
•_谓词下推：例如在Join前，将等值语句下推到加载表数据的时候而不是Join后。
• 有时候会很糟糕，因为某些计算下推后成本更高，例如哈希计算。
•投影下推：将投影运算下推到加载表数据的时候。
0 成本模型：
选择统计：针对数据平衡的情况。数据库会有一个进程收集相关的统计信息。PostgreSQL和SQLite使用ANALYZE命令。Ora
选择基数：针对数据失衡的情况。需要将数据分桶，使得桶中的数据分布平衡。
统一数据：假设值的分布是相同的。
独立谓词：假设属性上的谓词是独立的。
嵌套原则：连接Key的域重叠，使得内部关系中的每个Key也存在于外部表中。表中的元组也在另一个表中对应。
相关属性
左深度连接树：System R的基本决策
● 可以最小化写入磁盘的数据量
动态编程：计算多个Join之间路径的成本，选择最小的那个。
遗传查询：PostgreSQL使用的方式，如果表的数量超过12个就会采用该算法，否则就会采用动态编程的方法。
嵌套子查询重写

[MySQL常用系统表汇总 - 月染霜华 - 博客园 (cnblogs.com)](https://www.cnblogs.com/shoshana-kong/p/11431489.html)



# 并发控制【面试重灾区】

# 数据库上：

## BASE理论

BA指的是 **基本业务可用性**，支持分区失败，**S表示柔性状态**，也就是允许短时间内不同步。 **E表示最终一致性，数据最终是一致的。**原子性和持久性必须从根本上保障，为了可用性、性能和服务降级的需要，只有降低一致性和隔离性的要求。

  不符合ACID的系统通常以BASE冠名。BASE唯一可以做的事情就是不承认ACID，此外没有任何保证。

## CAP定理

对于共享数据系统，最多只能同时拥有CAP其中的两个，任意两个都有其适应的场景，真是的业务系统中通常是ACID与CAP的混合体。分布式系统中最重要的是满足业务需求，而不是追求高度抽象，绝对的系统特性。一个分布式系统不可能同时满足C(一致性)、A(可用性)和P(分区容错性)。由于分区容错性在是分布式系统中必须要保证的，**因此我们只能在A和C之间进行权衡。**

 C：表示 **一致性。** 也就是所有用户看到的数据是一样的。CAP只是使用一致性来标识**线性化**。

 A:  表示**可用性**，是指总能找到一个可用的数据副本。

  P： 表示**分区容错性**，能够容忍网络中断等故障。

| Consistency一致性                 | 分布式系统各节点上在同一时间点看到的数据完全相同的（数据强一 致性）。 |
| --------------------------------- | ------------------------------------------------------------ |
| **Availability**可用性            | 每个请求无论成功还是失败，都会保证收到响应。                 |
| **Partition Tolerance**分区容忍性 | 系统部分功能失效 或 系统间部分数据 丢失，不影响整个分布式系统的操作（高容错性） |

CA without P
丢弃P：对于一个分布式系统，如果不能满足分区容错性，那么意味着集群的各个节点之间都保证相互之间的协调工作，
如果网络异常，那么和单个节点没有两样，也不能称之为分布式系统。因此分区容错性是必须要保证的。

CP without A
丢弃A：如果牺牲可用性，换来数据一致性。对于这种情况也有相应的应用场景，比如淘宝在双十一的高峰，
为了保证数据的一致性，在我们支付的时候，有时候会等待很久都不能支付成功。这是因为并发量太大，
必须要保证交易数据的一致性，即使要牺牲一点可用性。

AP wihtout C
丢弃C：如果牺牲一致性，换来可用性。对于这种情况，比较典型的就是火车订票系统，
我们常常会在抢票的时候发现系统显示还有剩余的票，但是当在下单付款的时候却已没有剩余的票。
这样虽然会降低用户的使用体验，但是也不至于大量用户请求阻塞服务器。

不同场景下，取舍的选取是不一样的：

1、分布式系统中，分区容忍性肯定是要满足，不然体现不出分布式的强项。所以必须在可用性和强一致性做出权衡。

2、对于大多数WEB应用，其实不需要强一致性。目前多数分布式应用通过牺牲强一致性来换取应用高可用性。

强一致性：任何时刻所有用户或进程查询到的都是最近一次成功更新的数据，RDBMS一般均是强一致性。

最终一致性：某一时刻用户或进程查询到的数据可能不同，但最终成功更新的数据都会被所有用户或进程查询到。目前主流的NoSQL数据库都是采用这种一致性策略。

### CAP例子【zookeeper、etcd】（面试题）

[(10条消息) ZooKeeper与CAP是什么关系？适用于哪些场景？_arno_wzk的博客-CSDN博客](https://blog.csdn.net/arno_wzkdhr/article/details/111033837)

**Zookeeper 保证的是CP,**即一致性(Consistency)和分区容错性(Partition-Tolerance)，牺牲了部分可用性(Available)。[Zookeeper使用的是ZAB算法](https://blog.csdn.net/qq_42253147/article/details/95029258)

在强一致性的条件下,必须先暂停服务,达成一致性再提供服务,这个同步过程中,请求得不到回应,降低了可用性（Zookeeper中明显不可用的时段只有Leader选举阶段,此时无法写入）



如果依据 CAP 理论来划分的话，**etcd 属于 CP 模型。**

而在 etcd 系统的实现中，如果网络没有出现分区，整个系统是 100% 可用的；就算网络出现分区了，也不会有整个 etcd 系统都不可用的情况。**etcd使用的算法是raft。**

raft 协议是一个一致性算法，解决多台机器之间数据一致的问题。

[etcd]是一个分布式的 key-value 存储组件，它通过 raft 算法保证多台机器数据的一致性。

ElasticSearch是一个高一致性，高可用，低分区容忍性的（CA）分布式系统。

- **BM25**：Okapi BM 25算法。**在Elasticsearch和Lucene中默认使用的算法。**
- **classic**： 在7.0.0中标记为过时。基于TF/IDF 算法，以前在Elasticsearch和Lucene中的默认值。

![image-20221113205255095](https://13922725630-1312891983.cos.ap-guangzhou.myqcloud.com/abc/image-20221113205255095.png)



• 事务：事务是由一组操作构成的可靠的独立的工作单元，**事务具备ACID的特性，即 原子性、一致性、隔离性和持久性 。**它不是天然存在的，目的是简化编程模型。

## 事务（Tx）的实现方式

●使用 **重做日志(redo log)** 保证原子性
• 使用 **影子分页** 保证原子性，使用指针指向新的Page副本。是System R发明的，现在CouchDB和LMDB(OpenLDAP) 在使用。

**重做日志**：**恢复操作的最关键结构是重做日志，它由两个或多个预先分配的文件组成，这些文件存储数据库发生的所有更改。 Oracle数据库的每个实例都有一个关联的重做日志，用于在发生实例故障时保护数据库。**

**影子分页**

开辟个新空间复制要修改的数据部分，修改完后确认正常再进行覆盖。简单但是浪费资源，难以运用到多并发的情况。

DAP服务：域控

LDAP 是轻量级目录访问协议的简称



•原子性：银行转账的例子
一致性：用于描述操作前后的 **预期状态** ，从一种状态转变为另一种状态，数据库的完整性约束没有被破坏。一般会通过**重做日志**来实现。



k8s的pod具备什么特性

实现方式：

sidecar【一主业务多从业务】

flat【多个业务】

opstack是命令式

k8s是声明式

• MySQL的重做日志分为Redo和Undo， **Redo具有内存缓冲区** ，Redo保证事务的持久性，是顺序写的。
■ Undo用来实现事务回滚和MVCC。

缓冲区是为了不让磁盘的IO读写变的很毛刺，尽量平滑【通过异步fsync】



## 数据库系统的一致性与分布式系统的一致性

• **数据库**的一致性在于**ACID的一致性**，也就是关乎操作的一致性，**分布式系统**的一致性更加注重**数据**的一致性。
• **数据库的一致性核心在于约束**，约束是由数据库的使用者告诉数据库系统的。【设置键】
• 外部一致性的核心是并发控制，实现外部一致性的核心是可串行化和可线性化【一致性】，

  数据库承载了业务系统的并发，APP产生的并发。业务系统解决并发使用锁。

• 数据库系统存在事务的并发控制问题，并且ACID的隔离性受到并发控制的影响。



。隔离性：要求每个读写事务的对象对其他事务的操作对象互相分离开。事务提交前对其他事务是不可见的，
• **也叫做并发控制，本质是假装并发没有发生。**



##  SQL标准定义的四个隔离级别

• **读未提交**： 可以读取其它事务修改但未提交的数据，但是会导致“脏读"、"幻读”和“不可重复读"。
■ **脏读**： 所谓的脏读，其实就是读到了别的事务回滚前的脏数据。比如**事务B执行过程中修改了数据X，在未提交前，事务A读取了X，而事务B却回滚了，这样事务A就形成了脏读。**
• 脏读的实现方式可以使用锁，但是读锁并不可行：运行时间较长的写事务会导致读事务等待时间过长。读锁的任何局部性能都会扩散到整个应用。
• 大部分数据库使用对于每个待更新的对象，数据库会维护其旧值和当前持有锁的事务的新值两个版本。事务提交之前，只读事务能看到的只有旧值。

* **幻读**： 事务A 按照一定条件进行数据读取， 期间事务B **插入**了相同搜索条件的新数据，事务A再次按照原先条件进行读取时，发现了事务B 新插入的数据称为幻读。

*  **不可重复读**： 如果事务A 按一定条件搜索， 期间事务B **删除**了符合条件的某一条数据，导致事务A 再次读取时数据少了一条。这种情况称为**不可重复读。也叫做 读倾斜。**
   • 还有 写倾斜 的概念：是一种广义的更新丢失，本质是两个事务更新了两个不同的对象，但是这两个对象又存在关系，写倾斜导致业务上的错误。如果无法使用**可串行化的隔离级别，那么应用程序可以显式使用FOR UPDATE加锁。**

* 一些场景无法容忍不可重复读取：备份场景、分析查询（通常需要扫描大半个表）、定期完整性检查。因此通常使用快照隔离级别来解决。

* **读已提交**： 只能读取其它事务修改并已经提交的数据。避免了“脏读”，但不能避免“幻读”和“不可重复读”。读已提交是大多数主流数据库的默认事务等级。

    读数据库时，事务只能看到已经提交成功的数据，避免脏读。
  写数据库时，事务只能看到已经提交成功的数据，避免脏写。数据库通常使用行级锁实现。

*  **可重复读**： 锁定已经读取的数据，当前事务提交前其它事务不允许修改。避免了“脏读"和“不可重复读”的情况，但不能避免"幻读”，但是带来了更多的性能损失。
• Oracle称为可串行化，PostgreSQL和MySQL称为可重复读取。

* **可串行化**： 读取前锁定所有要读取的数据，当前事务提交前，其它事务不允许修改。**最严格的级别**，事务串行执行，资源消耗最大。
• **解决并发问题的最直接原因是避免并发**，在一个线程上顺序执行事务，但是这在2007年才被认可。
• **内存变得便宜。**

​       • OLTP事务通常很快且以读为主

● 数据库系统的可串行化和分布式系统的可线性化：
• 可串行化保证的是编程模型中的一些约束，这些约束是人为规定的。
• 可线性化保证的是分布式系统中操作与操作产生的**记录**是确定**一致的，那么就称为可线性化的。**

在线备份：本质上都是在线加个锁再离线备份。

xtrabackup备份工具  也就是将redo文件写入xtrabackup_log中，然后直接赋值数据库的数据文件跟表结构到指定的备份目录，然后加锁，离线备份再解锁释放资源。

btrfs在linux上开源，别用！容易丢数据，会蹲局子，工具少难以找回数据。

zfs 在nuix上使用，巨占内存，跑在大型机上。



## SQL标准不存在但是很实用的隔离级别

·**快照隔离级别: 通常采用写锁方式避免脏写的出现。实现快照隔离级别的这种技术也叫做MVCC**。
·快照隔离级别的实现过程中需要事务ID，通常事务ID的实现是32位整数，大约在40亿次后出现溢出，因此**PostgreSQL提供了类似于垃圾回收的vacum进程实现清理**
更新事务的有效性检查:
更新丢失:两个事务所拥有的快照是独立的
先提交者获胜
先更新者获胜
应用层使用FOR UPDATE显式加锁。
如果不支持内置的原子操作，那么就需要通过读取-修改-写回来避免。内置的原子操作通常使用独占锁实现。

**可串行化的快照隔离:**SS算法在2008年才提出。与2L相比，它是一种乐观的并发控制机制，当事务提交时数据库才会检查是否发生冲突，如果是那么终止并重启。为什么要等到提交:·数据库无法预知当前事务是只读事务还是读写事务。
·参与同时执行的事务可能发生终止，因此MVCC机制中读取的值并非一定是旧值。
·参与同时执行的读事务在提交时才会通知数据发生了变化。
·这样做就不需要等待其他事务所持有的锁。
，可串行化隔离突破了单核心CPU的限制。但是事务终止比例仍旧影响SSI算法的表现。
。持久性:事务一旦提交，就是永久性的修改。
原子性:银行转账的例子。

## 事务的分类

**扁平事务:最常见的事务**，所有的操作都处于同一个层次。

带保存点的扁平事务:允许在事务执行过程中回滚到同一个事务的较早状态。当系统发生崩溃时，所有的保存点会丢失，然后需要进行整个事务的重新执行链事务:保存点的一个变种，提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式的传递给下一个要开始的事务。带有保存点的事务可以回滚到任意保存点，链事务不行。

嵌套事务:顶层事务下面有许多子事务，是一棵树。

分布式事务:在分布式环境下运行的扁平事务。允许多个独立的事务资源参与到一个全局的事务中





## 基于锁的协议

**锁类型:**为了提高并发能力才将锁划分不同的类型
共享锁:用来处理读请求。允许升级为独占锁

独占锁:用来处理写请求。允许降级为共享锁

意向锁:支持更细粒度的锁请求。
共享意向锁:事务想要若干行的速请求。

独占意向锁:事务想要若干行的读/写请求。

共享独占意向锁:在以当前节点为根的子树加共享锁，子节点加独占锁。

**死锁检测:等待图法、依赖图法、超时机制。**
。等待图需要定期构建。

### 2PL

。**2PL(两阶段锁协议): 分为 生长和衰退 两个阶段**。悲观的。先取到所有的锁，然后问资源再释放所有的锁。
。生长:允许事务向锁管理器申请锁
。衰退:释放锁，然后不允许申请锁
。从时间与锁数量的图形关系来看，**本质是将锁的释放和申请集中**到一段小的时间内完成·优点在于 **足以保证可串行化**，**并且生成的前趋图是无环的**，缺点在于容易出现 **级联终止**，也就是当一个事务需要回滚，需要回滚其他事务，。**级联终止本身就是终止**，终止事务造成的影响:
。事务已经执行成功，但是返回客户端失败，那么重试就会造成重复执行。
。系统负荷导致重试导致更高的系统负荷，那么需要指数回退等。
·临时性故障，例如死锁、网络不稳定、节点切换、隔离违背导致重试，像隔离违背这张永久性故障导致无意义重试
。客户端进行失败导致重试。
**严格两阶段锁:区别就是在衰退阶段可以保持锁(排他锁)的数量，在事务完成后释放锁。**·如果出现事务写入的值在当前事务完成之前没有被其他事务读取或者覆盖。那么事务调度器实现的2PL是严格的2PL
。**强两阶段锁:衰退阶段不允许释放锁。**



### 时间戳排序协议

另一种决定事务可申行化次序的方式是 **事先选定事务的次序**，该协议就是这样的。
。时间戳的产生:
     。系统时钟:集群内可能不同步，**NTP存在时间差。**
     。逻辑时钟(逻辑计数器):存储时钟的寄存器超过最大位数后港出导致重置
     。混合方式
。不使用锁但是增加了元组的元数据维护工作。
   。每个元组**必须维护最近的写时间戳和读时间戳**，以方便与事务的时间戳进行比较
   。必须**拷贝**一份原来的数据以支持可重复读。
。优化:防止出现一个事务在另一个事务之前更新相同的值
托马斯写入规则:
。如果Timestamp(tx) < ReadTimestamp(value) 那么tx终止并回滚
·如果Timestamp(tx)< WriteTimestamp(value) 那么tx针对value的写操作不执行并继续处理



### 基于有效性检测的协议

。出现该协议的背景是大部分事务都是只读事务，事务冲突发生的频率较低，属于乐观的并发协议。
。在生命周期中执行2或3个阶段: 取决于是只读事务还是更新事务。
。读阶段:保存在事务线程的局部变量中。
。有效性检查阶段:执行有效性测试。记录了三个时间戳
Start
Validation
Finish
。写阶段:局部变量回写到数据库。

。避免了级联回滚:只有写操作的事务实际提交后写操作才发生。

。**可能产生长事务饿死的现象:一系列短事务不断的发生冲突，长事务反复重启**
。事务出现冲突后应该添加暂时的阻塞。



# MVCC【重点】

**多版本并发控制(MVCC):**需要通过事务ID决定哪些对象可见，因此实现MVCC的过程中需要精心定义规则。
   。每一个数据项的旧值拷贝保存在系统中，这些问题就可以避免。
   。每一个写操作都会创建数据的新版本。
支持**Time-Trave**l查询操作，特别适用于金融行业。
。这个想法是PostgreSQL提出的，但是很快被PostgreSQL移除，**因为这样会导致磁盘爆满，用于不做垃圾回收**





**版本存储:**
。仅**追加存储**:新版本被追加到同一个表空间中
。**时间序列存储**:旧版本被复制到单独的表空间
。**增量(Delta)存储**: 修改后的属性的原始值被复制到单独的增量记录空间中，类似于git diff
**垃圾回收**:定期做全表扫描。

**多版本时间戳排序:**
。读请求从来不失败且不用等待，典型的数据库系统读多写少。
。潜在的操作放大问题:一次操作产生多次磁盘访问操作。



。**多版本两阶段锁:分为只读事务和更新事务。**
。**更新事务执行强两阶段锁协议。**
。**只读事务执行多版本时间戳排序协议。**

。**如何实现支持MVCC的索引?**
1、索引直接指向对象的所有版本，想办法过滤掉对当前事务ID不可见的数据。随之而来的问题在于**删除数据需要设计一个垃圾回收进行索引清理操作。**

2、采用B+ Tree的追加/写时复制技术，当更新是不会修改现有的Page而是创建一个新的修改副本，拷贝必要的内容，然后让父节点或者递归向上，知道树的根节点指向新创建的节点。这样那些不受更新影响的页面都不需要复制。

3、在写入事务中，每个时刻都会创建一个新的B+ Tree，代表着这一时刻数据库的一致性快照，这样就无须事务ID了。不过这种方式依然需要设计一个垃圾回收进程实现压缩和GC（垃圾回收）。



# 业务上：

下面为扩展知识，业务系统上的事务支持。

### 本地事务

当事务 **由资源管理器本地管理时** 被称作本地事务
**本地事务的优点就是 支持严格的ACID特性**，高效，可靠，状态可以只在资源管理器中维护，而且应用编程模型简单

本**地事务不县备分布式事务的处理能力， 隔离的最小单位受限于资源管理器。**

### 全局事务

当事务**由全局事务管理器进行全局管理**时 成为全局事务，事务管理器负责管理全局的事务状态和参与的资源，协同资源的一致提交回滚。

TX协议:应用或者应用服务器与事务管理器的接口。
XA协议：全局事务管理器与事务管理器的接口。
AP:应用程序，可以理解为使用DTP (Data Tools Platform) 的程序。
**RM:资源管理**，这里可以是一个DMS或者消息服务管理系统应用程序通过资源管理器对资源进行控制资源必须实现XA定义的接口资源管理器负责控制和管理实际的资源，
**TM:事务管理器**，负责协调和管理事务，提供给AP编程接口以及管理资源管理器。事务管理器控制着全局事务，管理事务的生命周期，并且协调资源。

### 2PC（两阶段提交协议）

**XA**用于在全局事务中协调多个资源的机制。TM和RM之间采取两阶段提交的方案来解决一致性问题。两阶段提交需要一个协调者（TM）来掌控所有参与者（RM）节点的操作结果并指引这些节点是否需要最终提交。说白了技术引入了协调者这个角色保证数据的强一致性。

1、两阶段提交的局限在于协议成本，准备阶段的持久成本，全局事务状态的持久成本，潜在故障点多带来的脆弱性。准备后、提交的的故障引发一系列因察与饰复难题

2、缺点:参与的节点都是同步阻塞的，协调者存在单点故障，Commit时协调者故障导致数据不一致。

### 3PC

比2PC多了一个预提交

**3PC(三阶段提交协议):将提交事务请求的过程分成canCommit和preCommit两个过程。**

preCommit可能的情况为执行事务提交进入doCommit阶段和中断事务。

。进入doCommit之后可能存在协调者出现问题或者网络问题，这样只能设计一个超时机制。

。优点:降低了2PC参与者的阻塞范围，单点故障后继续可以达成一致。

。缺点:参与者接收到preCommit消息之后，如果出现网络分区，此时事务依然会提交，这种情况下出现不一致。

其实pre提交已经落盘但是会跟master申请do



## **业务系统中柔性事务的服务模式**

**可查询操作;**服务操作具有全局唯一的标识，操作唯一的确定的时间。

**幂等操作**:调用多次产生的业结果与调用-次产结相同。一是通过业条提作现等件，二是系存所有请或与外理的结、最后是检测到重复请求后，自动返回之前的结果。

幂等:f(x)=x  : 进行一堆操作之后,结果还是跟一开始一样.

###  **TCC操作**

。Try阶段，**尝试执行**业务，完成所有业务的检查，实现一致性;**预留**必须的业务资源，实现准隔离性。

。Confirm阶段:**真正的去执行业务**，不做任何检查，仅适用Try阶段预留的业务资源，Confirm操作还要满足幂等性。

。Cancel阶段: 取消执行业务，释放Try阶段预留的业务资源，Cancel操作要满足幂等性

这里的幂等性我认为就是得到想要的结果便可



**TCC与2PC(两阶段提交)协议的区别:**
1、TCC位于业务服务层而不是资源层，**TCC没有单独准备阶段，Trv操作兼备资源操作与准备的能力。**

2、TCC中Try操作可以灵活的选择业务资源，锁定粒度。
2、TCC的开发成本比2PC高。实际上TCC也属于两阶段操作，但是TCC不等同于2PC操作

TCC对业务服务代码侵入性较高，维护成本也随之上去了。try/confirm/cancel必须实现幂等性。事务管理器的实现需要日志，拉长了TCC整个过程



### 可补偿操作

。Do阶段:真正的执行业务处理，业务处理结果外部可见。

。Compensate阶段: 抵消或者部分撤销正向业务操作的业务结果，补偿操作满足幂等性 [可以直接报错说不够资源即可,有资源就不报错]

。约束:补偿操作在业务上可行，由于业务执行结果未隔离或者补偿不完整带来的风险与成本可控。实际上，TCC的Confirm和Cancel操作可以看做是补偿操作

**Saga操作**

Saga在1987年提出，由一系列本地事务构成，从架构上讲分为中心化的(基于事件)和去中心化的(基于命)·事件模式一个本地事务执行完成之后发出命令，挂载该事件的本地事务执行，回流的实现需要业务提供补偿口。但是参与的业务方较多的时候会导致失控，大家随意挂载事件，还可能引发**环形事件**，

。命令模式:定义一个与业务无关的服务作为事务的协调者。解决了事件模式的缺点带来的问题是需要维护一个协调中心 

类似saga[阿里]





# 日志崩溃与恢复

## 故障分类

**事务故障**
。逻辑错误:例如事务违反了完整性约束导致无法完成。
。内部状态错误:例如死锁。
**系统故障**
**存储故障**

## **缓冲池策略**

如何使用Undo和Redo取决于我们如何管理Buffer Pool中的脏页
。缓冲池是按照**页**来从磁盘加载数据的，因此回写的时候也需要**按照页为单位落盘**
。Steal:**允许将未提交的页持久化到磁盘**。对应的还有No Steal.
。Force:**允许事务提交之后立即持久化到磁盘**。对应的还有No Force。
。No Steal + Force:多个事务修改同一个元组的不同列，当一个事务需要Commit，那么就贝该元组并落盘。

并发协议中的CPU成本
更新多个Page，硬件上无法保证原子性。
频繁的IO读写，导致SSD报废更快。
缓冲池的频繁拷贝导致内存不足，然后产生更多的IO读写

## 影子分页

**将未提交的修改保存到临时空间**，当系统崩溃后只需要忽略临时Buffer中的修改即可。
。复制的成本太高。
。IBM和SQLite都在后来放弃了该方式。

cp需要修改的东西,并在这个空间内修改,如果确定修改就覆盖,不修改就没事了

**预写日志(WAL)**

使用**Steal + No Force的缓冲池策略**
。任何修改都保证在修改之前先记录到WAL并落盘
    只是追加，所以是顺序I0。
。WAL保存到Page中而不是单独的文件，否则操作的成本会变高
。LevelDB、RocksDB、Cassandra使用这种日志存储
。WAL刷完磁盘的时机就是Commit被提交到磁盘的时机。
 .会一直变大。

## 日志方案

**逻辑日志**
需要在每个日志记录中写入更少的数据。
如果有并发事务，很难使用逻辑日志实现恢复.。很难确定数据库哪些部分可能在崩溃前被查询修改过

恢复时间长，必须重新执行每个事务。
**物理日志**: 例如 git diff
**混合日志**: 允许高层操作，但是也可以记录一些底层信息。。检查点:对WAL的垃圾回收

IBM发布的ARIES是一篇关于崩溃恢复的论文
. WAL
。重做时重复历史
。撒销时使用日志记录变化		



























